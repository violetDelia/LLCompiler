# 前言

    hi，大家好，笔者是一位Ai编译器领域的从业者，同时个人也很喜欢写代码，有一天突发奇想想自己实现一个Ai编译器，但是呢毕竟编译器系统十分复杂，并且很多细节都是和硬件关系十分密切的，一个人是几乎不可能做出一个工业级别的Ai编译器的。因此该系列实现的编译器我会尽可能精简自己的实现方案，同时不多关注于过于琐碎的优化细节，但是同时希望它能够功能齐全。
    这个系列我会将我在开发过程中遇到的问题以及解决方案分享给大家，记录自己的学习体会，如果你有更好的思路欢迎与我讨论，如果我这个系列能够对你有所帮助的话，我也会十分开心的。

## 项目概述

    这个项目的前端是python，理论上可以接torch、onnx、tf、飞浆等神经网络框架，当然也可以支持自定义自定义DSL，但是笔者精力有限，目前只专注于对接torch。
    整体实现已先实现编译后进行优化的思路进行，主要内容在MLIR框架进行图优化、动态shape和符号表达、模型的量化、混精、算子融合、代码生成，内存优化、暂时不太会涉及后端指令集、寄存器等在LLVM上和汇编的优化，至于其他的功能和特性暂时不考虑。
    这个项目我会持续更新，开源地址在：https://github.com/violetDelia/LLCompiler。

## 开发记录

先画个饼吧，有时间再补吧~

- xdsl
- dynamo 如何自定义pytorch - compiler后端
- fx-graph
- 从xdsl接入mlir
- mlir的pass管理和pipeline
- 执行引擎与Jit：
- 模型优化 - 常量折叠与mlir：
- 模型优化 - 动态shape与符号表达：
- 模型优化 - 数据布局优化：
- 模型优化 - 算子分解与图变换：
- 模型优化 - 算子融合：
- 模型优化 - 模型量化与quant dialect：
- 模型优化 - 混合精度：
- 编译优化 - 代码生成与linalg dialect：
- 编译优化 - 缓存分块与auto tilling：
- 编译优化 - 内存优化与dma
- Aot算子接入：
- 项目构建-cmake与setup.py(pybind11)：

## 相关链接
