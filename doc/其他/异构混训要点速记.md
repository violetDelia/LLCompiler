# 异构混合训练速记

某家厂商的的卡供应(英伟达)因为各种原因[不可描述]不满足大模型训练任务的算力需求。因此需要多种不同类型的芯片组成集群来进行大模型的训练。

## 难点

1. 多种类型的卡由于架构设计不同，计算性能各不相同。  
    通常来说，训练任务会被性能最差的卡拖累。  
    解决方案：负载均衡  
2. 多卡之间通信困难。  
    芯片厂商的通讯库各不相同且不透明。导致无法实现不同芯片的通讯。  
    解决方案：  
        1. 不同芯片组成各自的小集群。小集群内部用芯片自己的通信协议，小集群与小集群之间用标准通用通信协议。[小集群之间如何配比？]  
        2. 借助CPU作为中间节点来进行通讯。[引入太多CPU与设备的数据拷贝]  
        3. 将某一个通讯库作为通信协议插入卡与卡之间进行通讯。[需要各个厂商认可、适配和优化] (无问芯穹 IHCCM)  
3. 精度问题且难以定位  
    芯片厂商的内部计算单元对精度的支持度和实现不一致，导致模型训练精度有偏差。尤其是用fp16混精计算。  
    解决方案：用bf16 或者 精度敏感的计算用f32  
4. 不同芯片算力不同，如何进行高效的配比  
    根据实际运行时间[芯片算力计算标准不一致，内部优化不一样，导致实际计算和理论值差距大]，进行配比。  
    配比方法: 根据经验暴力搜。。。。。

## 训练方式

1. 流水线并行 （模型分层切）[好像更好一点]  
   1. 不同的卡计算的时候对形状敏感，所以从芯片A传输到芯片B时候如果能够支持Slice操作能够加快训练速度。
2. 数据并行 （batch维度切） [容易被性能最差的卡拖累.]  

## 评价指标
    吞吐(A,B)/吞吐(A)+吞吐(B) 

