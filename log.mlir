Args: /home/lfr/LLCompiler/build/bin/llc-opt --dump-pass-pipeline /home/lfr/LLCompiler/ir_tree/inference/fx/resnet18/builtin_module_no-symbol-name/0_operation-legalization.mlir --debug -basic-pipeline 
Load new dialect in Context builtin
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ShapedType)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::MemRefLayoutAttrInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::TypedAttr)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ElementsAttr)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DistinctAttr)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::BytecodeOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SymbolOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpAsmOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::RegionKindInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ConditionallySpeculatable)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::MemoryEffectOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ResourceBlobManagerDialectInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpAsmDialectInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::BytecodeDialectInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::AffineBinaryOpExprStorage)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::AffineConstantExprStorage)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::AffineDimExprStorage)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::AffineMapStorage)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::IntegerSetStorage)
Load new dialect in Context builtin
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::ZeroOperands<mlir::TypeID::get<mlir::OpTrait::ZeroOperands>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneRegion<mlir::TypeID::get<mlir::OpTrait::OneRegion>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::ZeroResults<mlir::TypeID::get<mlir::OpTrait::ZeroResults>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::ZeroSuccessors<mlir::TypeID::get<mlir::OpTrait::ZeroSuccessors>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::NoRegionArguments<mlir::TypeID::get<mlir::OpTrait::NoRegionArguments>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::NoTerminator<mlir::TypeID::get<mlir::OpTrait::NoTerminator>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SingleBlock<mlir::TypeID::get<mlir::OpTrait::SingleBlock>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OpInvariants<mlir::TypeID::get<mlir::OpTrait::OpInvariants>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::BytecodeOpInterface::Trait<mlir::TypeID::get<mlir::BytecodeOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::AffineScope<mlir::TypeID::get<mlir::OpTrait::AffineScope>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::IsIsolatedFromAbove<mlir::TypeID::get<mlir::OpTrait::IsIsolatedFromAbove>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SymbolTable<mlir::TypeID::get<mlir::OpTrait::SymbolTable>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SymbolOpInterface::Trait<mlir::TypeID::get<mlir::SymbolOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpAsmOpInterface::Trait<mlir::TypeID::get<mlir::OpAsmOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::RegionKindInterface::Trait<mlir::TypeID::get<mlir::RegionKindInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::HasOnlyGraphRegion<mlir::TypeID::get<mlir::OpTrait::HasOnlyGraphRegion>()::Empty>)
Load new dialect in Context func
ImplicitTypeIDRegistry::lookupOrInsert(mlir::CallOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SymbolUserOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::CallableOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::FunctionOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::RegionBranchTerminatorOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DialectInlinerInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ConvertToLLVMPatternInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::bufferization::BufferizableOpInterface)
Load new dialect in Context cf
Load new dialect in Context arith
ImplicitTypeIDRegistry::lookupOrInsert(mlir::arith::ArithFastMathInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::VectorUnrollOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::InferTypeOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::InferIntRangeInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::arith::ArithIntegerOverflowFlagsInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::CastOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::arith::ArithRoundingModeInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SelectLikeOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::bufferization::BufferDeallocationOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ValueBoundsOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::BranchOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::AutomaticAllocationScope<mlir::TypeID::get<mlir::OpTrait::AutomaticAllocationScope>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::CallableOpInterface::Trait<mlir::TypeID::get<mlir::CallableOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::FunctionOpInterface::Trait<mlir::TypeID::get<mlir::FunctionOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::VerifiableTensorEncoding)
Load new dialect in Context llh
Load new dialect in Context mlir_ex
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SymbolicInferShapeOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::BraodcastableOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::LLVMTranslationDialectInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::ZeroRegions<mlir::TypeID::get<mlir::OpTrait::ZeroRegions>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneResult<mlir::TypeID::get<mlir::OpTrait::OneResult>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneTypedResult<mlir::Type>::Impl<mlir::TypeID::get<mlir::OpTrait::OneTypedResult<mlir::Type>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::ConstantLike<mlir::TypeID::get<mlir::OpTrait::ConstantLike>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SymbolicInferShapeOpInterface::Trait<mlir::TypeID::get<mlir::SymbolicInferShapeOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneTypedResult<mlir::IntegerType>::Impl<mlir::TypeID::get<mlir::OpTrait::OneTypedResult<mlir::IntegerType>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::InferTypeOpInterface::Trait<mlir::TypeID::get<mlir::InferTypeOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::VariadicOperands<mlir::TypeID::get<mlir::OpTrait::VariadicOperands>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::HasParent<mlir::func::FuncOp>::Impl<mlir::TypeID::get<mlir::OpTrait::HasParent<mlir::func::FuncOp>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ConditionallySpeculatable::Trait<mlir::TypeID::get<mlir::ConditionallySpeculatable::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::AlwaysSpeculatableImplTrait<mlir::TypeID::get<mlir::OpTrait::AlwaysSpeculatableImplTrait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::MemoryEffectOpInterface::Trait<mlir::TypeID::get<mlir::MemoryEffectOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::MemRefsNormalizable<mlir::TypeID::get<mlir::OpTrait::MemRefsNormalizable>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::RegionBranchTerminatorOpInterface::Trait<mlir::TypeID::get<mlir::RegionBranchTerminatorOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::ReturnLike<mlir::TypeID::get<mlir::OpTrait::ReturnLike>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::IsTerminator<mlir::TypeID::get<mlir::OpTrait::IsTerminator>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DataLayoutSpecInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::AtLeastNOperands<1>::Impl<mlir::TypeID::get<mlir::OpTrait::AtLeastNOperands<1>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::NOperands<2>::Impl<mlir::TypeID::get<mlir::OpTrait::NOperands<2>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::NOperands<5>::Impl<mlir::TypeID::get<mlir::OpTrait::NOperands<5>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneOperand<mlir::TypeID::get<mlir::OpTrait::OneOperand>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SameOperandsAndResultType<mlir::TypeID::get<mlir::OpTrait::SameOperandsAndResultType>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SameOperandsAndResultRank<mlir::TypeID::get<mlir::OpTrait::SameOperandsAndResultRank>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::ResultsBroadcastableShape<mlir::TypeID::get<mlir::OpTrait::ResultsBroadcastableShape>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::BraodcastableOpInterface::Trait<mlir::TypeID::get<mlir::BraodcastableOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::OpToOpPassAdaptor)
Pass Manager with 105 passes:
builtin.module(operation-legalization,remove-redundant-ops,inline{default-pipeline=canonicalize inlining-threshold=4294967295 max-iterations=4 },infer-symbol-shape,canonicalize{  max-iterations=10 max-num-rewrites=-1 region-simplify=normal test-convergence=false top-down=true},reshape-before-braodcast,insert-broadcast,mark-aot,load-weight,canonicalize{  max-iterations=10 max-num-rewrites=-1 region-simplify=normal test-convergence=false top-down=true},transform-layout-to-nhwc,unload-and-bind-encoding,convert-llh-to-arith,convert-llh-to-tensor,convert-llh-to-hlo,convert-llh-to-tosa,canonicalize{  max-iterations=10 max-num-rewrites=-1 region-simplify=normal test-convergence=false top-down=true},fold-index-cast,func.func(stablehlo-aggressive-folder{fold-float=true}),func.func(stablehlo-aggressive-simplification),func.func(stablehlo-canonicalize-dynamism),func.func(stablehlo-compatibility-expander{target=}),func.func(stablehlo-legalize-deprecated-ops{fail-on-unused=true}),stablehlo-convert-to-signless,stablehlo-legalize-to-linalg{enable-primitive-ops=false enable-sparse-ops=false},func.func(stablehlo-prepare-for-tosa),func.func(stablehlo-legalize-to-tosa),func.func(stablehlo-quant-legalize-to-tosa-rescale),func.func(tosa-layerwise-constant-fold{aggressive-reduce-constant=true}),func.func(tosa-optional-decompositions),func.func(tosa-reduce-transposes),canonicalize{  max-iterations=10 max-num-rewrites=-1 region-simplify=normal test-convergence=false top-down=true},func.func(tosa-to-linalg-named{prefer-conv2d-kernel-layout-hwcf=false}),func.func(tosa-to-linalg{aggressive-reduce-constant=false disable-tosa-decompositions=false}),tosa-to-arith{include-apply-rescale=true use-32-bit=false},fold-tensor-subset-ops,cse,convert-tensor-to-linalg,linalg-generalize-named-ops,convert-elementwise-to-linalg,linalg-fuse-elementwise-ops,canonicalize{  max-iterations=10 max-num-rewrites=-1 region-simplify=normal test-convergence=false top-down=true},eliminate-empty-tensors,empty-tensor-to-alloc-tensor,remove-symbol,func-bufferize,one-shot-bufferize{allow-return-allocs-from-loops=false allow-unknown-ops=false analysis-fuzzer-seed=0 analysis-heuristic=bottom-up bufferize-function-boundaries=false check-parallel-regions=true copy-before-write=false  dump-alias-sets=false function-boundary-type-conversion=infer-layout-map must-infer-memory-space=false  print-conflicts=false test-analysis-only=false unknown-type-conversion=fully-dynamic-layout-map},drop-equivalent-buffer-results,func.func(finalizing-bufferize),canonicalize{  max-iterations=10 max-num-rewrites=-1 region-simplify=normal test-convergence=false top-down=true},buffer-results-to-out-params{add-result-attr=false hoist-static-allocs=false},func.func(buffer-hoisting),func.func(buffer-loop-hoisting),convert-linalg-to-affine-loops,cse,resolve-shaped-type-result-dims,resolve-ranked-shaped-type-result-dims,func.func(affine-simplify-structures),func.func(affine-pipeline-data-transfer),affine-loop-fusion{fusion-compute-tolerance=3.000000e-01 fusion-fast-mem-space=0 fusion-local-buf-threshold=1 fusion-maximal=false mode=greedy},func.func(affine-scalrep),func.func(affine-loop-unroll-jam{unroll-jam-factor=4}),func.func(affine-loop-coalescing),lower-affine,arith-emulate-unsupported-floats{ target-type=f32},arith-unsigned-when-equivalent,int-range-optimizations,canonicalize{  max-iterations=10 max-num-rewrites=-1 region-simplify=normal test-convergence=false top-down=true},arith-expand{include-bf16=false},loop-invariant-code-motion,loop-invariant-subset-hoisting,scf-for-loop-peeling{peel-front=false skip-partial=true},scf-for-loop-range-folding,control-flow-sink,scf-parallel-loop-fusion,scf-for-loop-canonicalization,sccp,canonicalize{  max-iterations=10 max-num-rewrites=-1 region-simplify=normal test-convergence=false top-down=true},resolve-shaped-type-result-dims,resolve-ranked-shaped-type-result-dims,expand-strided-metadata,func.func(buffer-hoisting),func.func(buffer-loop-hoisting),expand-realloc{emit-deallocs=true},fold-memref-alias-ops,normalize-memrefs,func.func(buffer-deallocation),func.func(optimize-allocation-liveness),canonicalize{  max-iterations=10 max-num-rewrites=-1 region-simplify=normal test-convergence=false top-down=true},memref-expand,convert-bufferization-to-memref,duplicate-function-elimination,convert-scf-to-cf,convert-func-to-llvm{index-bitwidth=32 use-bare-ptr-memref-call-conv=false},convert-cf-to-llvm{index-bitwidth=32},convert-index-to-llvm{index-bitwidth=32},convert-arith-to-llvm{index-bitwidth=32},finalize-memref-to-llvm{index-bitwidth=32 use-aligned-alloc=false use-generic-functions=false},adapt-entry-parms-for-engine,llvm-legalize-for-export,mem2reg{region-simplify=true},cse,symbol-dce,canonicalize{  max-iterations=10 max-num-rewrites=-1 region-simplify=normal test-convergence=false top-down=true},reconcile-unrealized-casts)

ImplicitTypeIDRegistry::lookupOrInsert(mlir::chlo::ChloDialect)
Load new dialect in Context affine
Load new dialect in Context ub
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ub::PoisonAttrInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::affine::AffineMapAccessInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::affine::AffineDmaStartOp)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::affine::AffineDmaWaitOp)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::LoopLikeOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::RegionBranchOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::affine::AffineReadOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::affine::AffineWriteOpInterface)
Load new dialect in Context bufferization
Load new dialect in Context memref
ImplicitTypeIDRegistry::lookupOrInsert(mlir::CopyOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::PromotableMemOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DestructurableAccessorOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::PromotableAllocationOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DestructurableAllocationOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ViewLikeOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ShapedDimOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ReifyRankedShapedTypeOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OffsetSizeAndStrideOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::bufferization::AllocationOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::RuntimeVerifiableOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DestructurableTypeInterface)
Load new dialect in Context tensor
Load new dialect in Context complex
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DestinationStyleOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::transform::FindPayloadReplacementOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SubsetOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SubsetInsertionOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SubsetExtractionOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::TilingInterface)
Load new dialect in Context linalg
Load new dialect in Context math
ImplicitTypeIDRegistry::lookupOrInsert(mlir::linalg::AggregatedOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::linalg::LinalgOp)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::linalg::ContractionOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::linalg::ConvolutionOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::linalg::FillOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::mesh::ShardingInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::PartialReductionOpInterface)
Load new dialect in Context chlo
ImplicitTypeIDRegistry::lookupOrInsert(mlir::InferShapedTypeOpInterface)
Load new dialect in Context index
Load new dialect in Context llvm
ImplicitTypeIDRegistry::lookupOrInsert(mlir::LLVM::DIRecursiveTypeAttrInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::LLVM::LLVMVoidType)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::LLVM::LLVMPPCFP128Type)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::LLVM::LLVMTokenType)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::LLVM::LLVMLabelType)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::LLVM::LLVMMetadataType)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::LLVM::LLVMStructType)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DataLayoutTypeInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::LLVM::IntegerOverflowFlagsInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::PromotableOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::LLVM::AccessGroupOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::LLVM::AliasAnalysisOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::LLVM::FastmathFlagsInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::LLVM::BranchWeightOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SafeMemorySlotAccessOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::LLVM::FPExceptionBehaviorOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::LLVM::RoundingModeOpInterface)
Load new dialect in Context pdl
Load new dialect in Context pdl_interp
Load new dialect in Context scf
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ParallelCombiningOpInterface)
Load new dialect in Context shape
Load new dialect in Context sparse_tensor
ImplicitTypeIDRegistry::lookupOrInsert(mlir::sparse_tensor::StageWithSortSparseOp)
Load new dialect in Context stablehlo
ImplicitTypeIDRegistry::lookupOrInsert(mlir::hlo::HloDialectInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::hlo::BoundedAttrInterface)
Load new dialect in Context tosa
Load new dialect in Context quant
ImplicitTypeIDRegistry::lookupOrInsert(mlir::quant::AnyQuantizedType)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::quant::CalibratedQuantizedType)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::quant::UniformQuantizedType)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::quant::UniformQuantizedPerAxisType)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::tosa::TosaOp)
Load new dialect in Context vector
ImplicitTypeIDRegistry::lookupOrInsert(mlir::vector::MaskableOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::vector::MaskingOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::VectorTransferOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::Elementwise<mlir::TypeID::get<mlir::OpTrait::Elementwise>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::VariadicResults<mlir::TypeID::get<mlir::OpTrait::VariadicResults>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SingleBlockImplicitTerminator<mlir::vector::YieldOp>::Impl<mlir::TypeID::get<mlir::OpTrait::SingleBlockImplicitTerminator<mlir::vector::YieldOp>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::RegionBranchOpInterface::Trait<mlir::TypeID::get<mlir::RegionBranchOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::HasRecursiveMemoryEffects<mlir::TypeID::get<mlir::OpTrait::HasRecursiveMemoryEffects>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneTypedResult<mlir::MemRefType>::Impl<mlir::TypeID::get<mlir::OpTrait::OneTypedResult<mlir::MemRefType>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ViewLikeOpInterface::Trait<mlir::TypeID::get<mlir::ViewLikeOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneTypedResult<mlir::VectorType>::Impl<mlir::TypeID::get<mlir::OpTrait::OneTypedResult<mlir::VectorType>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::VectorUnrollOpInterface::Trait<mlir::TypeID::get<mlir::VectorUnrollOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::AtLeastNOperands<2>::Impl<mlir::TypeID::get<mlir::OpTrait::AtLeastNOperands<2>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::AttrSizedOperandSegments<mlir::TypeID::get<mlir::OpTrait::AttrSizedOperandSegments>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::VectorTransferOpInterface::Trait<mlir::TypeID::get<mlir::VectorTransferOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::vector::MaskableOpInterface::Trait<mlir::TypeID::get<mlir::vector::MaskableOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DestinationStyleOpInterface::Trait<mlir::TypeID::get<mlir::DestinationStyleOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::InferTypeOpAdaptor<mlir::TypeID::get<mlir::OpTrait::InferTypeOpAdaptor>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::AtLeastNOperands<4>::Impl<mlir::TypeID::get<mlir::OpTrait::AtLeastNOperands<4>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::NResults<2>::Impl<mlir::TypeID::get<mlir::OpTrait::NResults<2>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::arith::ArithFastMathInterface::Trait<mlir::TypeID::get<mlir::arith::ArithFastMathInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::AtLeastNOperands<3>::Impl<mlir::TypeID::get<mlir::OpTrait::AtLeastNOperands<3>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::vector::MaskingOpInterface::Trait<mlir::TypeID::get<mlir::vector::MaskingOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::NOperands<3>::Impl<mlir::TypeID::get<mlir::OpTrait::NOperands<3>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::Scalarizable<mlir::TypeID::get<mlir::OpTrait::Scalarizable>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::Vectorizable<mlir::TypeID::get<mlir::OpTrait::Vectorizable>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::Tensorizable<mlir::TypeID::get<mlir::OpTrait::Tensorizable>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneTypedResult<mlir::IndexType>::Impl<mlir::TypeID::get<mlir::OpTrait::OneTypedResult<mlir::IndexType>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::tosa::TosaOp::Trait<mlir::TypeID::get<mlir::tosa::TosaOp::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::NRegions<2>::Impl<mlir::TypeID::get<mlir::OpTrait::NRegions<2>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SingleBlockImplicitTerminator<mlir::tosa::YieldOp>::Impl<mlir::TypeID::get<mlir::OpTrait::SingleBlockImplicitTerminator<mlir::tosa::YieldOp>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::LoopLikeOpInterface::Trait<mlir::TypeID::get<mlir::LoopLikeOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::InferShapedTypeOpInterface::Trait<mlir::TypeID::get<mlir::InferShapedTypeOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::InferShapedTypeOpAdaptor<mlir::TypeID::get<mlir::OpTrait::InferShapedTypeOpAdaptor>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneTypedResult<mlir::TensorType>::Impl<mlir::TypeID::get<mlir::OpTrait::OneTypedResult<mlir::TensorType>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ReifyRankedShapedTypeOpInterface::Trait<mlir::TypeID::get<mlir::ReifyRankedShapedTypeOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SameOperandsAndResultElementType<mlir::TypeID::get<mlir::OpTrait::SameOperandsAndResultElementType>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::tosa::TosaElementwiseOperator<mlir::TypeID::get<mlir::OpTrait::tosa::TosaElementwiseOperator>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl<mlir::TypeID::get<mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::InferTensorType<mlir::TypeID::get<mlir::OpTrait::InferTensorType>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::IsCommutative<mlir::TypeID::get<mlir::OpTrait::IsCommutative>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::tosa::MulOperandsAndResultElementType<mlir::TypeID::get<mlir::OpTrait::tosa::MulOperandsAndResultElementType>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SameOperandsElementType<mlir::TypeID::get<mlir::OpTrait::SameOperandsElementType>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::hlo::OpTrait::IsCommutative<mlir::TypeID::get<mlir::hlo::OpTrait::IsCommutative>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::hlo::OpTrait::CompatibleOperandsAndResultType<mlir::TypeID::get<mlir::hlo::OpTrait::CompatibleOperandsAndResultType>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::hlo::OpTrait::SpeculatableIfAllInputsStaticImplTrait<mlir::TypeID::get<mlir::hlo::OpTrait::SpeculatableIfAllInputsStaticImplTrait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SameOperandsAndResultShape<mlir::TypeID::get<mlir::OpTrait::SameOperandsAndResultShape>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SingleBlockImplicitTerminator<mlir::stablehlo::ReturnOp>::Impl<mlir::TypeID::get<mlir::OpTrait::SingleBlockImplicitTerminator<mlir::stablehlo::ReturnOp>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::RecursivelySpeculatableImplTrait<mlir::TypeID::get<mlir::OpTrait::RecursivelySpeculatableImplTrait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::hlo::OpTrait::SpeculatableIfStaticDimInOutputIsStaticInInputImplTrait<mlir::TypeID::get<mlir::hlo::OpTrait::SpeculatableIfStaticDimInOutputIsStaticInInputImplTrait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::hlo::OpTrait::CompatibleOperandsAndResultElementType<mlir::TypeID::get<mlir::hlo::OpTrait::CompatibleOperandsAndResultElementType>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::hlo::OpTrait::RecursivelySpeculatableIfAllInputsStaticImplTrait<mlir::TypeID::get<mlir::hlo::OpTrait::RecursivelySpeculatableIfAllInputsStaticImplTrait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::hlo::OpTrait::BroadcastingElementwise<mlir::TypeID::get<mlir::hlo::OpTrait::BroadcastingElementwise>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::hlo::OpTrait::RecursivelySpeculatableIfStaticDimInOutputIsStaticInInputImplTrait<mlir::TypeID::get<mlir::hlo::OpTrait::RecursivelySpeculatableIfStaticDimInOutputIsStaticInInputImplTrait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::NOperands<4>::Impl<mlir::TypeID::get<mlir::OpTrait::NOperands<4>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::hlo::OpTrait::PairwiseSameOperandAndResultType<mlir::TypeID::get<mlir::hlo::OpTrait::PairwiseSameOperandAndResultType>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::hlo::OpTrait::SpeculatableIfAllInputsStaticAndShapeConstantImplTrait<mlir::TypeID::get<mlir::hlo::OpTrait::SpeculatableIfAllInputsStaticAndShapeConstantImplTrait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SymbolUserOpInterface::Trait<mlir::TypeID::get<mlir::SymbolUserOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::hlo::OpTrait::CompatibleOperandsElementType<mlir::TypeID::get<mlir::hlo::OpTrait::CompatibleOperandsElementType>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::VariadicRegions<mlir::TypeID::get<mlir::OpTrait::VariadicRegions>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::NResults<3>::Impl<mlir::TypeID::get<mlir::OpTrait::NResults<3>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::hlo::OpTrait::PairwiseSameOperandAndResultElementType<mlir::TypeID::get<mlir::hlo::OpTrait::PairwiseSameOperandAndResultElementType>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::HasParent<mlir::sparse_tensor::BinaryOp, mlir::sparse_tensor::UnaryOp, mlir::sparse_tensor::ReduceOp, mlir::sparse_tensor::SelectOp, mlir::sparse_tensor::ForeachOp, mlir::sparse_tensor::IterateOp, mlir::sparse_tensor::CoIterateOp>::Impl<mlir::TypeID::get<mlir::OpTrait::HasParent<mlir::sparse_tensor::BinaryOp, mlir::sparse_tensor::UnaryOp, mlir::sparse_tensor::ReduceOp, mlir::sparse_tensor::SelectOp, mlir::sparse_tensor::ForeachOp, mlir::sparse_tensor::IterateOp, mlir::sparse_tensor::CoIterateOp>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneTypedResult<mlir::sparse_tensor::StorageSpecifierType>::Impl<mlir::TypeID::get<mlir::OpTrait::OneTypedResult<mlir::sparse_tensor::StorageSpecifierType>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SingleBlockImplicitTerminator<mlir::sparse_tensor::YieldOp>::Impl<mlir::TypeID::get<mlir::OpTrait::SingleBlockImplicitTerminator<mlir::sparse_tensor::YieldOp>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::NResults<4>::Impl<mlir::TypeID::get<mlir::OpTrait::NResults<4>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::AtLeastNResults<2>::Impl<mlir::TypeID::get<mlir::OpTrait::AtLeastNResults<2>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::sparse_tensor::StageWithSortSparseOp::Trait<mlir::TypeID::get<mlir::sparse_tensor::StageWithSortSparseOp::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::AtLeastNOperands<5>::Impl<mlir::TypeID::get<mlir::OpTrait::AtLeastNOperands<5>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::NRegions<3>::Impl<mlir::TypeID::get<mlir::OpTrait::NRegions<3>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneTypedResult<mlir::sparse_tensor::IterSpaceType>::Impl<mlir::TypeID::get<mlir::OpTrait::OneTypedResult<mlir::sparse_tensor::IterSpaceType>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::HasParent<mlir::shape::ReduceOp, mlir::shape::FunctionLibraryOp>::Impl<mlir::TypeID::get<mlir::OpTrait::HasParent<mlir::shape::ReduceOp, mlir::shape::FunctionLibraryOp>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneTypedResult<mlir::shape::ValueShapeType>::Impl<mlir::TypeID::get<mlir::OpTrait::OneTypedResult<mlir::shape::ValueShapeType>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneTypedResult<mlir::ShapedType>::Impl<mlir::TypeID::get<mlir::OpTrait::OneTypedResult<mlir::ShapedType>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::CastOpInterface::Trait<mlir::TypeID::get<mlir::CastOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::HasParent<mlir::shape::FuncOp>::Impl<mlir::TypeID::get<mlir::OpTrait::HasParent<mlir::shape::FuncOp>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SingleBlockImplicitTerminator<mlir::shape::YieldOp>::Impl<mlir::TypeID::get<mlir::OpTrait::SingleBlockImplicitTerminator<mlir::shape::YieldOp>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneTypedResult<mlir::shape::SizeType>::Impl<mlir::TypeID::get<mlir::OpTrait::OneTypedResult<mlir::shape::SizeType>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneTypedResult<mlir::shape::ShapeType>::Impl<mlir::TypeID::get<mlir::OpTrait::OneTypedResult<mlir::shape::ShapeType>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneTypedResult<mlir::shape::WitnessType>::Impl<mlir::TypeID::get<mlir::OpTrait::OneTypedResult<mlir::shape::WitnessType>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::HasParent<mlir::shape::AssumingOp>::Impl<mlir::TypeID::get<mlir::OpTrait::HasParent<mlir::shape::AssumingOp>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SingleBlockImplicitTerminator<mlir::shape::AssumingYieldOp>::Impl<mlir::TypeID::get<mlir::OpTrait::SingleBlockImplicitTerminator<mlir::shape::AssumingYieldOp>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::HasParent<mlir::scf::ExecuteRegionOp, mlir::scf::ForOp, mlir::scf::IfOp, mlir::scf::IndexSwitchOp, mlir::scf::WhileOp>::Impl<mlir::TypeID::get<mlir::OpTrait::HasParent<mlir::scf::ExecuteRegionOp, mlir::scf::ForOp, mlir::scf::IfOp, mlir::scf::IndexSwitchOp, mlir::scf::WhileOp>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::HasParent<mlir::scf::ReduceOp>::Impl<mlir::TypeID::get<mlir::OpTrait::HasParent<mlir::scf::ReduceOp>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::HasParent<mlir::scf::ParallelOp>::Impl<mlir::TypeID::get<mlir::OpTrait::HasParent<mlir::scf::ParallelOp>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SingleBlockImplicitTerminator<mlir::scf::ReduceOp>::Impl<mlir::TypeID::get<mlir::OpTrait::SingleBlockImplicitTerminator<mlir::scf::ReduceOp>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::HasParallelRegion<mlir::TypeID::get<mlir::OpTrait::HasParallelRegion>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::AtLeastNRegions<1>::Impl<mlir::TypeID::get<mlir::OpTrait::AtLeastNRegions<1>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SingleBlockImplicitTerminator<mlir::scf::YieldOp>::Impl<mlir::TypeID::get<mlir::OpTrait::SingleBlockImplicitTerminator<mlir::scf::YieldOp>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::HasParent<mlir::scf::ForallOp>::Impl<mlir::TypeID::get<mlir::OpTrait::HasParent<mlir::scf::ForallOp>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ParallelCombiningOpInterface::Trait<mlir::TypeID::get<mlir::ParallelCombiningOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SingleBlockImplicitTerminator<mlir::scf::InParallelOp>::Impl<mlir::TypeID::get<mlir::OpTrait::SingleBlockImplicitTerminator<mlir::scf::InParallelOp>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::HasParent<mlir::scf::WhileOp>::Impl<mlir::TypeID::get<mlir::OpTrait::HasParent<mlir::scf::WhileOp>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::AtLeastNSuccessors<1>::Impl<mlir::TypeID::get<mlir::OpTrait::AtLeastNSuccessors<1>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneSuccessor<mlir::TypeID::get<mlir::OpTrait::OneSuccessor>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::NSuccessors<2>::Impl<mlir::TypeID::get<mlir::OpTrait::NSuccessors<2>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneTypedResult<mlir::pdl::PDLType>::Impl<mlir::TypeID::get<mlir::OpTrait::OneTypedResult<mlir::pdl::PDLType>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneTypedResult<mlir::pdl::RangeType>::Impl<mlir::TypeID::get<mlir::OpTrait::OneTypedResult<mlir::pdl::RangeType>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneTypedResult<mlir::pdl::ValueType>::Impl<mlir::TypeID::get<mlir::OpTrait::OneTypedResult<mlir::pdl::ValueType>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneTypedResult<mlir::pdl::OperationType>::Impl<mlir::TypeID::get<mlir::OpTrait::OneTypedResult<mlir::pdl::OperationType>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneTypedResult<mlir::pdl::TypeType>::Impl<mlir::TypeID::get<mlir::OpTrait::OneTypedResult<mlir::pdl::TypeType>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneTypedResult<mlir::pdl::AttributeType>::Impl<mlir::TypeID::get<mlir::OpTrait::OneTypedResult<mlir::pdl::AttributeType>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::HasParent<mlir::pdl_interp::ForEachOp>::Impl<mlir::TypeID::get<mlir::OpTrait::HasParent<mlir::pdl_interp::ForEachOp>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SameTypeOperands<mlir::TypeID::get<mlir::OpTrait::SameTypeOperands>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::HasParent<mlir::pdl::PatternOp>::Impl<mlir::TypeID::get<mlir::OpTrait::HasParent<mlir::pdl::PatternOp>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::HasParent<mlir::pdl::RewriteOp>::Impl<mlir::TypeID::get<mlir::OpTrait::HasParent<mlir::pdl::RewriteOp>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::LLVM::FastmathFlagsInterface::Trait<mlir::TypeID::get<mlir::LLVM::FastmathFlagsInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneTypedResult<mlir::LLVM::LLVMPointerType>::Impl<mlir::TypeID::get<mlir::OpTrait::OneTypedResult<mlir::LLVM::LLVMPointerType>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::LLVM::AccessGroupOpInterface::Trait<mlir::TypeID::get<mlir::LLVM::AccessGroupOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::LLVM::AliasAnalysisOpInterface::Trait<mlir::TypeID::get<mlir::LLVM::AliasAnalysisOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::PromotableMemOpInterface::Trait<mlir::TypeID::get<mlir::PromotableMemOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DestructurableAccessorOpInterface::Trait<mlir::TypeID::get<mlir::DestructurableAccessorOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SafeMemorySlotAccessOpInterface::Trait<mlir::TypeID::get<mlir::SafeMemorySlotAccessOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::PromotableOpInterface::Trait<mlir::TypeID::get<mlir::PromotableOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::LLVM::FPExceptionBehaviorOpInterface::Trait<mlir::TypeID::get<mlir::LLVM::FPExceptionBehaviorOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::LLVM::RoundingModeOpInterface::Trait<mlir::TypeID::get<mlir::LLVM::RoundingModeOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::BranchOpInterface::Trait<mlir::TypeID::get<mlir::BranchOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::LLVM::BranchWeightOpInterface::Trait<mlir::TypeID::get<mlir::LLVM::BranchWeightOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::LLVM::IntegerOverflowFlagsInterface::Trait<mlir::TypeID::get<mlir::LLVM::IntegerOverflowFlagsInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SelectLikeOpInterface::Trait<mlir::TypeID::get<mlir::SelectLikeOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::CallOpInterface::Trait<mlir::TypeID::get<mlir::CallOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SingleBlockImplicitTerminator<mlir::LLVM::ReturnOp>::Impl<mlir::TypeID::get<mlir::OpTrait::SingleBlockImplicitTerminator<mlir::LLVM::ReturnOp>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::PromotableAllocationOpInterface::Trait<mlir::TypeID::get<mlir::PromotableAllocationOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DestructurableAllocationOpInterface::Trait<mlir::TypeID::get<mlir::DestructurableAllocationOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::InferIntRangeInterface::Trait<mlir::TypeID::get<mlir::InferIntRangeInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::chlo::OpTrait::Broadcasting<mlir::TypeID::get<mlir::chlo::OpTrait::Broadcasting>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::bufferization::BufferizableOpInterface::Trait<mlir::TypeID::get<mlir::bufferization::BufferizableOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneTypedResult<mlir::BaseMemRefType>::Impl<mlir::TypeID::get<mlir::OpTrait::OneTypedResult<mlir::BaseMemRefType>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SubsetOpInterface::Trait<mlir::TypeID::get<mlir::SubsetOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SubsetInsertionOpInterface::Trait<mlir::TypeID::get<mlir::SubsetInsertionOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::CopyOpInterface::Trait<mlir::TypeID::get<mlir::CopyOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::bufferization::AllocationOpInterface::Trait<mlir::TypeID::get<mlir::bufferization::AllocationOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SingleBlockImplicitTerminator<mlir::linalg::YieldOp>::Impl<mlir::TypeID::get<mlir::OpTrait::SingleBlockImplicitTerminator<mlir::linalg::YieldOp>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::linalg::LinalgOp::Trait<mlir::TypeID::get<mlir::linalg::LinalgOp::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::linalg::ContractionOpInterface::Trait<mlir::TypeID::get<mlir::linalg::ContractionOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::linalg::ConvolutionOpInterface::Trait<mlir::TypeID::get<mlir::linalg::ConvolutionOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::linalg::FillOpInterface::Trait<mlir::TypeID::get<mlir::linalg::FillOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::TilingInterface::Trait<mlir::TypeID::get<mlir::TilingInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::linalg::AggregatedOpInterface::Trait<mlir::TypeID::get<mlir::linalg::AggregatedOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::HasParent<mlir::tensor::GenerateOp, mlir::tensor::PadOp>::Impl<mlir::TypeID::get<mlir::OpTrait::HasParent<mlir::tensor::GenerateOp, mlir::tensor::PadOp>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OffsetSizeAndStrideOpInterface::Trait<mlir::TypeID::get<mlir::OffsetSizeAndStrideOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SingleBlockImplicitTerminator<mlir::tensor::YieldOp>::Impl<mlir::TypeID::get<mlir::OpTrait::SingleBlockImplicitTerminator<mlir::tensor::YieldOp>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ShapedDimOpInterface::Trait<mlir::TypeID::get<mlir::ShapedDimOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneTypedResult<mlir::ComplexType>::Impl<mlir::TypeID::get<mlir::OpTrait::OneTypedResult<mlir::ComplexType>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneTypedResult<mlir::FloatType>::Impl<mlir::TypeID::get<mlir::OpTrait::OneTypedResult<mlir::FloatType>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::HasParent<mlir::memref::AllocaScopeOp>::Impl<mlir::TypeID::get<mlir::OpTrait::HasParent<mlir::memref::AllocaScopeOp>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SingleBlockImplicitTerminator<mlir::memref::AllocaScopeReturnOp>::Impl<mlir::TypeID::get<mlir::OpTrait::SingleBlockImplicitTerminator<mlir::memref::AllocaScopeReturnOp>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SingleBlockImplicitTerminator<mlir::memref::AtomicYieldOp>::Impl<mlir::TypeID::get<mlir::OpTrait::SingleBlockImplicitTerminator<mlir::memref::AtomicYieldOp>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SameOperandsShape<mlir::TypeID::get<mlir::OpTrait::SameOperandsShape>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::HasParent<mlir::memref::GenericAtomicRMWOp>::Impl<mlir::TypeID::get<mlir::OpTrait::HasParent<mlir::memref::GenericAtomicRMWOp>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::affine::AffineWriteOpInterface::Trait<mlir::TypeID::get<mlir::affine::AffineWriteOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::affine::AffineMapAccessInterface::Trait<mlir::TypeID::get<mlir::affine::AffineMapAccessInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::affine::AffineReadOpInterface::Trait<mlir::TypeID::get<mlir::affine::AffineReadOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SingleBlockImplicitTerminator<mlir::affine::AffineYieldOp>::Impl<mlir::TypeID::get<mlir::OpTrait::SingleBlockImplicitTerminator<mlir::affine::AffineYieldOp>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::arith::ArithRoundingModeInterface::Trait<mlir::TypeID::get<mlir::arith::ArithRoundingModeInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::arith::ArithIntegerOverflowFlagsInterface::Trait<mlir::TypeID::get<mlir::arith::ArithIntegerOverflowFlagsInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::IsIdempotent<mlir::TypeID::get<mlir::OpTrait::IsIdempotent>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::pdl::detail::PatternOpGenericAdaptorBase::Properties)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::pdl::detail::ApplyNativeConstraintOpGenericAdaptorBase::Properties)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::pdl::detail::OperationOpGenericAdaptorBase::Properties)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::pdl::detail::ReplaceOpGenericAdaptorBase::Properties)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::pdl::detail::RewriteOpGenericAdaptorBase::Properties)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::pdl::detail::ApplyNativeRewriteOpGenericAdaptorBase::Properties)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::pdl::detail::ResultOpGenericAdaptorBase::Properties)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::pdl::detail::AttributeOpGenericAdaptorBase::Properties)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::pdl_to_pdl_interp::AttributePosition)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::pdl_to_pdl_interp::AttributeLiteralPosition)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::pdl_to_pdl_interp::ConstraintPosition)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::pdl_to_pdl_interp::ForEachPosition)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::pdl_to_pdl_interp::OperandPosition)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::pdl_to_pdl_interp::OperandGroupPosition)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::pdl_to_pdl_interp::OperationPosition)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::pdl_to_pdl_interp::ResultPosition)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::pdl_to_pdl_interp::ResultGroupPosition)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::pdl_to_pdl_interp::TypePosition)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::pdl_to_pdl_interp::TypeLiteralPosition)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::pdl_to_pdl_interp::UsersPosition)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::pdl_to_pdl_interp::AttributeAnswer)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::pdl_to_pdl_interp::OperationNameAnswer)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::pdl_to_pdl_interp::TypeAnswer)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::pdl_to_pdl_interp::UnsignedAnswer)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::pdl_to_pdl_interp::FalseAnswer)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::pdl_to_pdl_interp::TrueAnswer)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::pdl_to_pdl_interp::ConstraintQuestion)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::pdl_to_pdl_interp::EqualToQuestion)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::pdl_to_pdl_interp::AttributeQuestion)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::pdl_to_pdl_interp::IsNotNullQuestion)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::pdl_to_pdl_interp::OperandCountQuestion)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::pdl_to_pdl_interp::OperandCountAtLeastQuestion)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::pdl_to_pdl_interp::OperationNameQuestion)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::pdl_to_pdl_interp::ResultCountQuestion)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::pdl_to_pdl_interp::ResultCountAtLeastQuestion)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::pdl_to_pdl_interp::TypeQuestion)
Graph:
Best tree:
  * empty block: expect at least a terminator
mlir-asm-printer: 'builtin.module' failed to verify and will be printed in generic form
%168 = "pdl.operation"(%164, %166, %167) <{attributeValueNames = ["value"], opName = "stablehlo.constant", operandSegmentSizes = array<i32: 1, 1, 1>}> : (!pdl.range<value>, !pdl.attribute, !pdl.range<type>) -> !pdl.operation
Calling key getTreePredicates:
  * Value: empty block: expect at least a terminator
mlir-asm-printer: 'builtin.module' failed to verify and will be printed in generic form
%168 = "pdl.operation"(%164, %166, %167) <{attributeValueNames = ["value"], opName = "stablehlo.constant", operandSegmentSizes = array<i32: 1, 1, 1>}> : (!pdl.range<value>, !pdl.attribute, !pdl.range<type>) -> !pdl.operation
Graph:
Best tree:
  * empty block: expect at least a terminator
mlir-asm-printer: 'builtin.module' failed to verify and will be printed in generic form
%162 = "pdl.operation"(%160, %161) <{attributeValueNames = [], opName = "stablehlo.abs", operandSegmentSizes = array<i32: 1, 0, 1>}> : (!pdl.value, !pdl.range<type>) -> !pdl.operation
Calling key getTreePredicates:
  * Value: empty block: expect at least a terminator
mlir-asm-printer: 'builtin.module' failed to verify and will be printed in generic form
%162 = "pdl.operation"(%160, %161) <{attributeValueNames = [], opName = "stablehlo.abs", operandSegmentSizes = array<i32: 1, 0, 1>}> : (!pdl.value, !pdl.range<type>) -> !pdl.operation
Graph:
Best tree:
  * empty block: expect at least a terminator
mlir-asm-printer: 'builtin.module' failed to verify and will be printed in generic form
%157 = "pdl.operation"(%155, %156) <{attributeValueNames = [], opName = "stablehlo.ceil", operandSegmentSizes = array<i32: 1, 0, 1>}> : (!pdl.value, !pdl.range<type>) -> !pdl.operation
Calling key getTreePredicates:
  * Value: empty block: expect at least a terminator
mlir-asm-printer: 'builtin.module' failed to verify and will be printed in generic form
%157 = "pdl.operation"(%155, %156) <{attributeValueNames = [], opName = "stablehlo.ceil", operandSegmentSizes = array<i32: 1, 0, 1>}> : (!pdl.value, !pdl.range<type>) -> !pdl.operation
Graph:
Best tree:
  * empty block: expect at least a terminator
mlir-asm-printer: 'builtin.module' failed to verify and will be printed in generic form
%152 = "pdl.operation"(%150, %151) <{attributeValueNames = [], opName = "stablehlo.convert", operandSegmentSizes = array<i32: 1, 0, 1>}> : (!pdl.value, !pdl.range<type>) -> !pdl.operation
Calling key getTreePredicates:
  * Value: empty block: expect at least a terminator
mlir-asm-printer: 'builtin.module' failed to verify and will be printed in generic form
%152 = "pdl.operation"(%150, %151) <{attributeValueNames = [], opName = "stablehlo.convert", operandSegmentSizes = array<i32: 1, 0, 1>}> : (!pdl.value, !pdl.range<type>) -> !pdl.operation
Graph:
Best tree:
  * empty block: expect at least a terminator
mlir-asm-printer: 'builtin.module' failed to verify and will be printed in generic form
%147 = "pdl.operation"(%145, %146) <{attributeValueNames = [], opName = "stablehlo.exponential", operandSegmentSizes = array<i32: 1, 0, 1>}> : (!pdl.value, !pdl.range<type>) -> !pdl.operation
Calling key getTreePredicates:
  * Value: empty block: expect at least a terminator
mlir-asm-printer: 'builtin.module' failed to verify and will be printed in generic form
%147 = "pdl.operation"(%145, %146) <{attributeValueNames = [], opName = "stablehlo.exponential", operandSegmentSizes = array<i32: 1, 0, 1>}> : (!pdl.value, !pdl.range<type>) -> !pdl.operation
Graph:
Best tree:
  * empty block: expect at least a terminator
mlir-asm-printer: 'builtin.module' failed to verify and will be printed in generic form
%138 = "pdl.operation"(%136, %137) <{attributeValueNames = [], opName = "stablehlo.exponential_minus_one", operandSegmentSizes = array<i32: 1, 0, 1>}> : (!pdl.value, !pdl.range<type>) -> !pdl.operation
Calling key getTreePredicates:
  * Value: empty block: expect at least a terminator
mlir-asm-printer: 'builtin.module' failed to verify and will be printed in generic form
%138 = "pdl.operation"(%136, %137) <{attributeValueNames = [], opName = "stablehlo.exponential_minus_one", operandSegmentSizes = array<i32: 1, 0, 1>}> : (!pdl.value, !pdl.range<type>) -> !pdl.operation
Graph:
Best tree:
  * empty block: expect at least a terminator
mlir-asm-printer: 'builtin.module' failed to verify and will be printed in generic form
%133 = "pdl.operation"(%131, %132) <{attributeValueNames = [], opName = "stablehlo.floor", operandSegmentSizes = array<i32: 1, 0, 1>}> : (!pdl.value, !pdl.range<type>) -> !pdl.operation
Calling key getTreePredicates:
  * Value: empty block: expect at least a terminator
mlir-asm-printer: 'builtin.module' failed to verify and will be printed in generic form
%133 = "pdl.operation"(%131, %132) <{attributeValueNames = [], opName = "stablehlo.floor", operandSegmentSizes = array<i32: 1, 0, 1>}> : (!pdl.value, !pdl.range<type>) -> !pdl.operation
Graph:
Best tree:
  * empty block: expect at least a terminator
mlir-asm-printer: 'builtin.module' failed to verify and will be printed in generic form
%121 = "pdl.operation"(%119, %120) <{attributeValueNames = [], opName = "stablehlo.is_finite", operandSegmentSizes = array<i32: 1, 0, 1>}> : (!pdl.value, !pdl.range<type>) -> !pdl.operation
Calling key getTreePredicates:
  * Value: empty block: expect at least a terminator
mlir-asm-printer: 'builtin.module' failed to verify and will be printed in generic form
%121 = "pdl.operation"(%119, %120) <{attributeValueNames = [], opName = "stablehlo.is_finite", operandSegmentSizes = array<i32: 1, 0, 1>}> : (!pdl.value, !pdl.range<type>) -> !pdl.operation
Graph:
Best tree:
  * empty block: expect at least a terminator
mlir-asm-printer: 'builtin.module' failed to verify and will be printed in generic form
%116 = "pdl.operation"(%114, %115) <{attributeValueNames = [], opName = "stablehlo.log", operandSegmentSizes = array<i32: 1, 0, 1>}> : (!pdl.value, !pdl.range<type>) -> !pdl.operation
Calling key getTreePredicates:
  * Value: empty block: expect at least a terminator
mlir-asm-printer: 'builtin.module' failed to verify and will be printed in generic form
%116 = "pdl.operation"(%114, %115) <{attributeValueNames = [], opName = "stablehlo.log", operandSegmentSizes = array<i32: 1, 0, 1>}> : (!pdl.value, !pdl.range<type>) -> !pdl.operation
Graph:
Best tree:
  * empty block: expect at least a terminator
mlir-asm-printer: 'builtin.module' failed to verify and will be printed in generic form
%107 = "pdl.operation"(%105, %106) <{attributeValueNames = [], opName = "stablehlo.log_plus_one", operandSegmentSizes = array<i32: 1, 0, 1>}> : (!pdl.value, !pdl.range<type>) -> !pdl.operation
Calling key getTreePredicates:
  * Value: empty block: expect at least a terminator
mlir-asm-printer: 'builtin.module' failed to verify and will be printed in generic form
%107 = "pdl.operation"(%105, %106) <{attributeValueNames = [], opName = "stablehlo.log_plus_one", operandSegmentSizes = array<i32: 1, 0, 1>}> : (!pdl.value, !pdl.range<type>) -> !pdl.operation
Graph:
Best tree:
  * empty block: expect at least a terminator
mlir-asm-printer: 'builtin.module' failed to verify and will be printed in generic form
%102 = "pdl.operation"(%100, %101) <{attributeValueNames = [], opName = "stablehlo.negate", operandSegmentSizes = array<i32: 1, 0, 1>}> : (!pdl.value, !pdl.range<type>) -> !pdl.operation
Calling key getTreePredicates:
  * Value: empty block: expect at least a terminator
mlir-asm-printer: 'builtin.module' failed to verify and will be printed in generic form
%102 = "pdl.operation"(%100, %101) <{attributeValueNames = [], opName = "stablehlo.negate", operandSegmentSizes = array<i32: 1, 0, 1>}> : (!pdl.value, !pdl.range<type>) -> !pdl.operation
Graph:
Best tree:
  * empty block: expect at least a terminator
mlir-asm-printer: 'builtin.module' failed to verify and will be printed in generic form
%97 = "pdl.operation"(%95, %96) <{attributeValueNames = [], opName = "stablehlo.tanh", operandSegmentSizes = array<i32: 1, 0, 1>}> : (!pdl.value, !pdl.range<type>) -> !pdl.operation
Calling key getTreePredicates:
  * Value: empty block: expect at least a terminator
mlir-asm-printer: 'builtin.module' failed to verify and will be printed in generic form
%97 = "pdl.operation"(%95, %96) <{attributeValueNames = [], opName = "stablehlo.tanh", operandSegmentSizes = array<i32: 1, 0, 1>}> : (!pdl.value, !pdl.range<type>) -> !pdl.operation
Graph:
Best tree:
  * empty block: expect at least a terminator
mlir-asm-printer: 'builtin.module' failed to verify and will be printed in generic form
%92 = "pdl.operation"(%88, %90, %91) <{attributeValueNames = [], opName = "stablehlo.add", operandSegmentSizes = array<i32: 2, 0, 1>}> : (!pdl.value, !pdl.value, !pdl.range<type>) -> !pdl.operation
Calling key getTreePredicates:
  * Value: empty block: expect at least a terminator
mlir-asm-printer: 'builtin.module' failed to verify and will be printed in generic form
%92 = "pdl.operation"(%88, %90, %91) <{attributeValueNames = [], opName = "stablehlo.add", operandSegmentSizes = array<i32: 2, 0, 1>}> : (!pdl.value, !pdl.value, !pdl.range<type>) -> !pdl.operation
Graph:
Best tree:
  * empty block: expect at least a terminator
mlir-asm-printer: 'builtin.module' failed to verify and will be printed in generic form
%85 = "pdl.operation"(%81, %83, %84) <{attributeValueNames = [], opName = "stablehlo.and", operandSegmentSizes = array<i32: 2, 0, 1>}> : (!pdl.value, !pdl.value, !pdl.range<type>) -> !pdl.operation
Calling key getTreePredicates:
  * Value: empty block: expect at least a terminator
mlir-asm-printer: 'builtin.module' failed to verify and will be printed in generic form
%85 = "pdl.operation"(%81, %83, %84) <{attributeValueNames = [], opName = "stablehlo.and", operandSegmentSizes = array<i32: 2, 0, 1>}> : (!pdl.value, !pdl.value, !pdl.range<type>) -> !pdl.operation
Graph:
Best tree:
  * empty block: expect at least a terminator
mlir-asm-printer: 'builtin.module' failed to verify and will be printed in generic form
%78 = "pdl.operation"(%74, %76, %77) <{attributeValueNames = [], opName = "stablehlo.divide", operandSegmentSizes = array<i32: 2, 0, 1>}> : (!pdl.value, !pdl.value, !pdl.range<type>) -> !pdl.operation
Calling key getTreePredicates:
  * Value: empty block: expect at least a terminator
mlir-asm-printer: 'builtin.module' failed to verify and will be printed in generic form
%78 = "pdl.operation"(%74, %76, %77) <{attributeValueNames = [], opName = "stablehlo.divide", operandSegmentSizes = array<i32: 2, 0, 1>}> : (!pdl.value, !pdl.value, !pdl.range<type>) -> !pdl.operation
Graph:
Best tree:
  * empty block: expect at least a terminator
mlir-asm-printer: 'builtin.module' failed to verify and will be printed in generic form
%71 = "pdl.operation"(%67, %69, %70) <{attributeValueNames = [], opName = "stablehlo.maximum", operandSegmentSizes = array<i32: 2, 0, 1>}> : (!pdl.value, !pdl.value, !pdl.range<type>) -> !pdl.operation
Calling key getTreePredicates:
  * Value: empty block: expect at least a terminator
mlir-asm-printer: 'builtin.module' failed to verify and will be printed in generic form
%71 = "pdl.operation"(%67, %69, %70) <{attributeValueNames = [], opName = "stablehlo.maximum", operandSegmentSizes = array<i32: 2, 0, 1>}> : (!pdl.value, !pdl.value, !pdl.range<type>) -> !pdl.operation
Graph:
Best tree:
  * empty block: expect at least a terminator
mlir-asm-printer: 'builtin.module' failed to verify and will be printed in generic form
%64 = "pdl.operation"(%60, %62, %63) <{attributeValueNames = [], opName = "stablehlo.minimum", operandSegmentSizes = array<i32: 2, 0, 1>}> : (!pdl.value, !pdl.value, !pdl.range<type>) -> !pdl.operation
Calling key getTreePredicates:
  * Value: empty block: expect at least a terminator
mlir-asm-printer: 'builtin.module' failed to verify and will be printed in generic form
%64 = "pdl.operation"(%60, %62, %63) <{attributeValueNames = [], opName = "stablehlo.minimum", operandSegmentSizes = array<i32: 2, 0, 1>}> : (!pdl.value, !pdl.value, !pdl.range<type>) -> !pdl.operation
Graph:
Best tree:
  * empty block: expect at least a terminator
mlir-asm-printer: 'builtin.module' failed to verify and will be printed in generic form
%56 = "pdl.operation"(%52, %54, %55) <{attributeValueNames = [], opName = "stablehlo.multiply", operandSegmentSizes = array<i32: 2, 0, 1>}> : (!pdl.value, !pdl.value, !pdl.range<type>) -> !pdl.operation
Calling key getTreePredicates:
  * Value: empty block: expect at least a terminator
mlir-asm-printer: 'builtin.module' failed to verify and will be printed in generic form
%56 = "pdl.operation"(%52, %54, %55) <{attributeValueNames = [], opName = "stablehlo.multiply", operandSegmentSizes = array<i32: 2, 0, 1>}> : (!pdl.value, !pdl.value, !pdl.range<type>) -> !pdl.operation
Graph:
Best tree:
  * empty block: expect at least a terminator
mlir-asm-printer: 'builtin.module' failed to verify and will be printed in generic form
%49 = "pdl.operation"(%45, %47, %48) <{attributeValueNames = [], opName = "stablehlo.or", operandSegmentSizes = array<i32: 2, 0, 1>}> : (!pdl.value, !pdl.value, !pdl.range<type>) -> !pdl.operation
Calling key getTreePredicates:
  * Value: empty block: expect at least a terminator
mlir-asm-printer: 'builtin.module' failed to verify and will be printed in generic form
%49 = "pdl.operation"(%45, %47, %48) <{attributeValueNames = [], opName = "stablehlo.or", operandSegmentSizes = array<i32: 2, 0, 1>}> : (!pdl.value, !pdl.value, !pdl.range<type>) -> !pdl.operation
Graph:
Best tree:
  * empty block: expect at least a terminator
mlir-asm-printer: 'builtin.module' failed to verify and will be printed in generic form
%42 = "pdl.operation"(%38, %40, %41) <{attributeValueNames = [], opName = "stablehlo.power", operandSegmentSizes = array<i32: 2, 0, 1>}> : (!pdl.value, !pdl.value, !pdl.range<type>) -> !pdl.operation
Calling key getTreePredicates:
  * Value: empty block: expect at least a terminator
mlir-asm-printer: 'builtin.module' failed to verify and will be printed in generic form
%42 = "pdl.operation"(%38, %40, %41) <{attributeValueNames = [], opName = "stablehlo.power", operandSegmentSizes = array<i32: 2, 0, 1>}> : (!pdl.value, !pdl.value, !pdl.range<type>) -> !pdl.operation
Graph:
Best tree:
  * empty block: expect at least a terminator
mlir-asm-printer: 'builtin.module' failed to verify and will be printed in generic form
%35 = "pdl.operation"(%31, %33, %34) <{attributeValueNames = [], opName = "stablehlo.shift_left", operandSegmentSizes = array<i32: 2, 0, 1>}> : (!pdl.value, !pdl.value, !pdl.range<type>) -> !pdl.operation
Calling key getTreePredicates:
  * Value: empty block: expect at least a terminator
mlir-asm-printer: 'builtin.module' failed to verify and will be printed in generic form
%35 = "pdl.operation"(%31, %33, %34) <{attributeValueNames = [], opName = "stablehlo.shift_left", operandSegmentSizes = array<i32: 2, 0, 1>}> : (!pdl.value, !pdl.value, !pdl.range<type>) -> !pdl.operation
Graph:
Best tree:
  * empty block: expect at least a terminator
mlir-asm-printer: 'builtin.module' failed to verify and will be printed in generic form
%28 = "pdl.operation"(%24, %26, %27) <{attributeValueNames = [], opName = "stablehlo.shift_right_logical", operandSegmentSizes = array<i32: 2, 0, 1>}> : (!pdl.value, !pdl.value, !pdl.range<type>) -> !pdl.operation
Calling key getTreePredicates:
  * Value: empty block: expect at least a terminator
mlir-asm-printer: 'builtin.module' failed to verify and will be printed in generic form
%28 = "pdl.operation"(%24, %26, %27) <{attributeValueNames = [], opName = "stablehlo.shift_right_logical", operandSegmentSizes = array<i32: 2, 0, 1>}> : (!pdl.value, !pdl.value, !pdl.range<type>) -> !pdl.operation
Graph:
Best tree:
  * empty block: expect at least a terminator
mlir-asm-printer: 'builtin.module' failed to verify and will be printed in generic form
%21 = "pdl.operation"(%17, %19, %20) <{attributeValueNames = [], opName = "stablehlo.subtract", operandSegmentSizes = array<i32: 2, 0, 1>}> : (!pdl.value, !pdl.value, !pdl.range<type>) -> !pdl.operation
Calling key getTreePredicates:
  * Value: empty block: expect at least a terminator
mlir-asm-printer: 'builtin.module' failed to verify and will be printed in generic form
%21 = "pdl.operation"(%17, %19, %20) <{attributeValueNames = [], opName = "stablehlo.subtract", operandSegmentSizes = array<i32: 2, 0, 1>}> : (!pdl.value, !pdl.value, !pdl.range<type>) -> !pdl.operation
Graph:
Best tree:
  * empty block: expect at least a terminator
mlir-asm-printer: 'builtin.module' failed to verify and will be printed in generic form
%14 = "pdl.operation"(%10, %12, %13) <{attributeValueNames = [], opName = "stablehlo.xor", operandSegmentSizes = array<i32: 2, 0, 1>}> : (!pdl.value, !pdl.value, !pdl.range<type>) -> !pdl.operation
Calling key getTreePredicates:
  * Value: empty block: expect at least a terminator
mlir-asm-printer: 'builtin.module' failed to verify and will be printed in generic form
%14 = "pdl.operation"(%10, %12, %13) <{attributeValueNames = [], opName = "stablehlo.xor", operandSegmentSizes = array<i32: 2, 0, 1>}> : (!pdl.value, !pdl.value, !pdl.range<type>) -> !pdl.operation
Graph:
Best tree:
  * empty block: expect at least a terminator
mlir-asm-printer: 'builtin.module' failed to verify and will be printed in generic form
%7 = "pdl.operation"(%1, %3, %5, %6) <{attributeValueNames = [], opName = "stablehlo.select", operandSegmentSizes = array<i32: 3, 0, 1>}> : (!pdl.value, !pdl.value, !pdl.value, !pdl.range<type>) -> !pdl.operation
Calling key getTreePredicates:
  * Value: empty block: expect at least a terminator
mlir-asm-printer: 'builtin.module' failed to verify and will be printed in generic form
%7 = "pdl.operation"(%1, %3, %5, %6) <{attributeValueNames = [], opName = "stablehlo.select", operandSegmentSizes = array<i32: 3, 0, 1>}> : (!pdl.value, !pdl.value, !pdl.value, !pdl.range<type>) -> !pdl.operation
ImplicitTypeIDRegistry::lookupOrInsert(mlir::pdl_to_pdl_interp::SwitchNode)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::pdl_to_pdl_interp::SuccessNode)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::pdl_to_pdl_interp::BoolNode)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::pdl_to_pdl_interp::ExitNode)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::pdl_interp::detail::GetAttributeOpGenericAdaptorBase::Properties)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::pdl_interp::detail::ApplyConstraintOpGenericAdaptorBase::Properties)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::pdl_interp::detail::CreateOperationOpGenericAdaptorBase::Properties)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::pdl_interp::detail::RecordMatchOpGenericAdaptorBase::Properties)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::pdl_interp::detail::CheckOperandCountOpGenericAdaptorBase::Properties)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::pdl_interp::detail::GetOperandOpGenericAdaptorBase::Properties)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::pdl_interp::detail::ApplyRewriteOpGenericAdaptorBase::Properties)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::pdl_interp::detail::GetResultOpGenericAdaptorBase::Properties)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::pdl_interp::detail::CreateAttributeOpGenericAdaptorBase::Properties)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::pdl_interp::detail::SwitchOperationNameOpGenericAdaptorBase::Properties)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::PreservedAnalyses::AllAnalysesType)
Allocated 4 indices (down from initial 78).
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DialectFoldInterface)

//===-------------------------------------------===//
Processing operation : 'func.return'(0x556256ded7d0) {
  "func.return"(%195) : (tensor<?x1000xf32>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256ded730) {
  "llh.symbolic_bind"(%195, %123) <{expressions = affine_map<()[s0, s1] -> (s0, 1000)>}> : (tensor<?x1000xf32>, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256ded630) {
  %195 = "llh.add"(%194, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.matmul'(0x556256ded540) {
  %194 = "llh.matmul"(%192, %193) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.transpose'(0x556256ded470) {
  %193 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dec370) {
  "llh.symbolic_bind"(%192, %123) <{expressions = affine_map<()[s0, s1] -> (s0, 512)>}> : (tensor<?x512xf32>, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.flatten'(0x556256dec290) {
  %192 = "llh.flatten"(%191, %0) : (tensor<?x512x1x1xf32>, i64) -> tensor<?x512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256ddb060) {
  "llh.symbolic_bind"(%191, %123) <{expressions = affine_map<()[s0, s1] -> (s0, 512, 1, 1)>}> : (tensor<?x512x1x1xf32>, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.adaptive_average_pool'(0x556256dfffd0) {
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dffec0) {
  "llh.symbolic_bind"(%190, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256dffde0) {
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dffd10) {
  "llh.symbolic_bind"(%189, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256dffc10) {
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dffb40) {
  "llh.symbolic_bind"(%188, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dff9f0) {
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dff920) {
  "llh.symbolic_bind"(%187, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dff810) {
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dff700) {
  "llh.symbolic_bind"(%186, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256dff620) {
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dff550) {
  "llh.symbolic_bind"(%185, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dfebf0) {
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dfeb20) {
  "llh.symbolic_bind"(%184, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dfea10) {
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dfe900) {
  "llh.symbolic_bind"(%183, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256dfe820) {
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dfe750) {
  "llh.symbolic_bind"(%182, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256dfe650) {
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dfe580) {
  "llh.symbolic_bind"(%181, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dfe430) {
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dfe360) {
  "llh.symbolic_bind"(%180, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dfe250) {
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dfe140) {
  "llh.symbolic_bind"(%179, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dfdff0) {
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dfdf20) {
  "llh.symbolic_bind"(%178, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dfde10) {
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dfdd00) {
  "llh.symbolic_bind"(%177, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256dfdc20) {
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dfdb50) {
  "llh.symbolic_bind"(%176, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dfda00) {
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dfd930) {
  "llh.symbolic_bind"(%175, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dfc810) {
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dfc690) {
  "llh.symbolic_bind"(%174, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256dfc5b0) {
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dfc4e0) {
  "llh.symbolic_bind"(%173, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256dfc3e0) {
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dfc310) {
  "llh.symbolic_bind"(%172, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dfc1c0) {
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dfc0f0) {
  "llh.symbolic_bind"(%171, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dfbfe0) {
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dfbed0) {
  "llh.symbolic_bind"(%170, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256dfbdf0) {
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dfbd20) {
  "llh.symbolic_bind"(%169, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dfbbd0) {
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dfbb00) {
  "llh.symbolic_bind"(%168, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dfb9f0) {
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dfb8e0) {
  "llh.symbolic_bind"(%167, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256dfb800) {
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dfb730) {
  "llh.symbolic_bind"(%166, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256dfb630) {
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dfb560) {
  "llh.symbolic_bind"(%165, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dfb410) {
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dfb340) {
  "llh.symbolic_bind"(%164, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dfb230) {
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dfb120) {
  "llh.symbolic_bind"(%163, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dfafd0) {
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dfa6f0) {
  "llh.symbolic_bind"(%162, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dfa5e0) {
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df9cc0) {
  "llh.symbolic_bind"(%161, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df9be0) {
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df9b10) {
  "llh.symbolic_bind"(%160, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df99c0) {
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df98f0) {
  "llh.symbolic_bind"(%159, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256df97e0) {
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df96d0) {
  "llh.symbolic_bind"(%158, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df95f0) {
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df9520) {
  "llh.symbolic_bind"(%157, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256df9420) {
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df9350) {
  "llh.symbolic_bind"(%156, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df9200) {
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df9130) {
  "llh.symbolic_bind"(%155, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256df8810) {
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df8700) {
  "llh.symbolic_bind"(%154, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df8620) {
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df8550) {
  "llh.symbolic_bind"(%153, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df8400) {
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df7b20) {
  "llh.symbolic_bind"(%152, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256df7a10) {
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df7900) {
  "llh.symbolic_bind"(%151, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df7820) {
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df7750) {
  "llh.symbolic_bind"(%150, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256df7650) {
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df7580) {
  "llh.symbolic_bind"(%149, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df7430) {
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df7360) {
  "llh.symbolic_bind"(%148, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256df6a40) {
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df68c0) {
  "llh.symbolic_bind"(%147, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df5f60) {
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df5e90) {
  "llh.symbolic_bind"(%146, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256d6b1a0) {
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df5d50) {
  "llh.symbolic_bind"(%145, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df5c70) {
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df5ba0) {
  "llh.symbolic_bind"(%144, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df5a50) {
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df5980) {
  "llh.symbolic_bind"(%143, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256d6f0a0) {
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df5840) {
  "llh.symbolic_bind"(%142, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df5760) {
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df5690) {
  "llh.symbolic_bind"(%141, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256df5590) {
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df54c0) {
  "llh.symbolic_bind"(%140, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df5370) {
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df52a0) {
  "llh.symbolic_bind"(%139, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256d6f2a0) {
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df5160) {
  "llh.symbolic_bind"(%138, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df5080) {
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df4fb0) {
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df3640) {
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df3570) {
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256d71db0) {
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df3430) {
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df3350) {
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df3280) {
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256de84d0) {
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df3160) {
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df3010) {
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df2f40) {
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256db4320) {
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df2e00) {
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df2d20) {
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df2c50) {
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df2b00) {
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df2a30) {
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256db4840) {
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df2910) {
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.max_pool'(0x556256df2820) {
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df2290) {
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256dd8f40) {
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df2170) {
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256d7a010) {
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df1770) {
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dc82f0) {
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df0c50) {
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.torch_symbolic_int'(0x556256df0ba0) {
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.torch_symbolic_int'(0x556256df0ae0) {
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256df09f0) {
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256df0930) {
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256df0870) {
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256df07b0) {
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256df06f0) {
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256df0630) {
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256def560) {
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256def4a0) {
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256def3e0) {
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256def320) {
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256def260) {
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256deeae0) {
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5440) {
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5380) {
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de52c0) {
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5200) {
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5140) {
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5080) {
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4fc0) {
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4f20) {
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4d80) {
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4cc0) {
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4c00) {
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4b40) {
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4a80) {
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de49c0) {
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4900) {
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dec1f0) {
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dec130) {
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dec070) {
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256debfb0) {
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256debef0) {
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256debe30) {
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256debd70) {
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256deaca0) {
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256deabe0) {
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256deab20) {
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256deaa60) {
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea9a0) {
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea8e0) {
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea820) {
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea760) {
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea6a0) {
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea5e0) {
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea520) {
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea460) {
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea3a0) {
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de9ad0) {
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de9a10) {
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de8940) {
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de8880) {
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de87c0) {
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de8700) {
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de8640) {
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de8580) {
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de8410) {
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de8350) {
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de7a80) {
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de79c0) {
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de7900) {
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de7840) {
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de7780) {
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de76c0) {
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de7600) {
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de6530) {
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de6470) {
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de63b0) {
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5f70) {
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5eb0) {
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5df0) {
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5d30) {
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de57f0) {
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5730) {
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5670) {
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5540) {
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4840) {
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4780) {
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de46c0) {
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4600) {
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de3530) {
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de3470) {
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de2ba0) {
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de2ae0) {
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de2a20) {
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de2960) {
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de28a0) {
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de27e0) {
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de22a0) {
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de21e0) {
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de2120) {
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de2060) {
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de1fa0) {
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de1ee0) {
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de1e40) {
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddcb80) {
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de0b60) {
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de0aa0) {
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de09e0) {
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de0920) {
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddfda0) {
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddfce0) {
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddf320) {
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddf260) {
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddf1a0) {
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddec60) {
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddeba0) {
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dde660) {
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dddd10) {
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddcc60) {
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dd2fa0) {
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dd2ea0) {
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddc7a0) {
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddc6e0) {
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddc620) {
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddc560) {
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddc4a0) {
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256da6a00) {
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dc3ed0) {
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dc58c0) {
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dc5a90) {
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dd3680) {
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dd3850) {
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>


  * Pattern {anonymous}::WeightOpRefine : 'llh.weight -> ()' {
Trying to match "{anonymous}::WeightOpRefine"
"{anonymous}::WeightOpRefine" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'func.func'(0x556256de5490) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.constant'(0x556256dd8e70) {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64


  * Pattern {anonymous}::BraodcastableScalarToTensor : 'llh.constant -> ()' {
Trying to match "{anonymous}::BraodcastableScalarToTensor"
"{anonymous}::BraodcastableScalarToTensor" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'func.return'(0x556256ded7d0) {
  "func.return"(%195) : (tensor<?x1000xf32>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256ded730) {
  "llh.symbolic_bind"(%195, %123) <{expressions = affine_map<()[s0, s1] -> (s0, 1000)>}> : (tensor<?x1000xf32>, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%138, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%139, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%140, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%141, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%142, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%143, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%144, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%145, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%146, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%147, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%148, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%149, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%150, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%151, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%152, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%153, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%154, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%155, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%156, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%157, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%158, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%159, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%160, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%161, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%162, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%163, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%164, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%165, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%166, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%167, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%168, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%169, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%170, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%171, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%172, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%173, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%174, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%175, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%176, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%177, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%178, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%179, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%180, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%181, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%182, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%183, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%184, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%185, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%186, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%187, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%188, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%189, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%190, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  "llh.symbolic_bind"(%191, %123) <{expressions = affine_map<()[s0, s1] -> (s0, 512, 1, 1)>}> : (tensor<?x512x1x1xf32>, i64) -> ()
  %192 = "llh.flatten"(%191, %0) : (tensor<?x512x1x1xf32>, i64) -> tensor<?x512xf32>
  "llh.symbolic_bind"(%192, %123) <{expressions = affine_map<()[s0, s1] -> (s0, 512)>}> : (tensor<?x512xf32>, i64) -> ()
  %193 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %194 = "llh.matmul"(%192, %193) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %195 = "llh.add"(%194, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %195 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256ded630) {
  %195 = "llh.add"(%194, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.matmul'(0x556256ded540) {
  %194 = "llh.matmul"(%192, %193) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.transpose'(0x556256ded470) {
  %193 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dec370) {
  "llh.symbolic_bind"(%192, %123) <{expressions = affine_map<()[s0, s1] -> (s0, 512)>}> : (tensor<?x512xf32>, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%138, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%139, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%140, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%141, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%142, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%143, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%144, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%145, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%146, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%147, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%148, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%149, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%150, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%151, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%152, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%153, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%154, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%155, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%156, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%157, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%158, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%159, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%160, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%161, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%162, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%163, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%164, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%165, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%166, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%167, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%168, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%169, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%170, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%171, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%172, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%173, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%174, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%175, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%176, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%177, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%178, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%179, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%180, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%181, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%182, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%183, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%184, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%185, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%186, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%187, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%188, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%189, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%190, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  "llh.symbolic_bind"(%191, %123) <{expressions = affine_map<()[s0, s1] -> (s0, 512, 1, 1)>}> : (tensor<?x512x1x1xf32>, i64) -> ()
  %192 = "llh.flatten"(%191, %0) : (tensor<?x512x1x1xf32>, i64) -> tensor<?x512xf32>
  %193 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %194 = "llh.matmul"(%192, %193) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %195 = "llh.add"(%194, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %195 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.flatten'(0x556256dec290) {
  %192 = "llh.flatten"(%191, %0) : (tensor<?x512x1x1xf32>, i64) -> tensor<?x512xf32>


  * Pattern {anonymous}::replaceFlattenOp : 'llh.flatten -> ()' {
Trying to match "{anonymous}::replaceFlattenOp"
ImplicitTypeIDRegistry::lookupOrInsert(mlir::llh::detail::ConstantOpGenericAdaptorBase::Properties)
"{anonymous}::replaceFlattenOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%138, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%139, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%140, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%141, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%142, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%143, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%144, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%145, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%146, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%147, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%148, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%149, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%150, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%151, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%152, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%153, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%154, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%155, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%156, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%157, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%158, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%159, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%160, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%161, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%162, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%163, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%164, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%165, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%166, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%167, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%168, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%169, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%170, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%171, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%172, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%173, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%174, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%175, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%176, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%177, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%178, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%179, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%180, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%181, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%182, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%183, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%184, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%185, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%186, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%187, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%188, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%189, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%190, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  "llh.symbolic_bind"(%191, %123) <{expressions = affine_map<()[s0, s1] -> (s0, 512, 1, 1)>}> : (tensor<?x512x1x1xf32>, i64) -> ()
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256ddb060) {
  "llh.symbolic_bind"(%191, %123) <{expressions = affine_map<()[s0, s1] -> (s0, 512, 1, 1)>}> : (tensor<?x512x1x1xf32>, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%138, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%139, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%140, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%141, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%142, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%143, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%144, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%145, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%146, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%147, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%148, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%149, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%150, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%151, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%152, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%153, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%154, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%155, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%156, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%157, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%158, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%159, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%160, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%161, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%162, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%163, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%164, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%165, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%166, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%167, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%168, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%169, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%170, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%171, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%172, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%173, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%174, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%175, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%176, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%177, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%178, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%179, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%180, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%181, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%182, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%183, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%184, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%185, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%186, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%187, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%188, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%189, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%190, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.adaptive_average_pool'(0x556256dfffd0) {
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dffec0) {
  "llh.symbolic_bind"(%190, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%138, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%139, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%140, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%141, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%142, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%143, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%144, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%145, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%146, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%147, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%148, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%149, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%150, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%151, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%152, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%153, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%154, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%155, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%156, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%157, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%158, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%159, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%160, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%161, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%162, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%163, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%164, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%165, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%166, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%167, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%168, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%169, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%170, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%171, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%172, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%173, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%174, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%175, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%176, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%177, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%178, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%179, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%180, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%181, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%182, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%183, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%184, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%185, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%186, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%187, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%188, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%189, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256dffde0) {
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dffd10) {
  "llh.symbolic_bind"(%189, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%138, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%139, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%140, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%141, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%142, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%143, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%144, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%145, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%146, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%147, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%148, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%149, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%150, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%151, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%152, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%153, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%154, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%155, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%156, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%157, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%158, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%159, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%160, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%161, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%162, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%163, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%164, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%165, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%166, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%167, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%168, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%169, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%170, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%171, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%172, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%173, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%174, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%175, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%176, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%177, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%178, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%179, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%180, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%181, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%182, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%183, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%184, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%185, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%186, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%187, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%188, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256dffc10) {
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dffb40) {
  "llh.symbolic_bind"(%188, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%138, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%139, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%140, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%141, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%142, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%143, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%144, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%145, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%146, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%147, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%148, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%149, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%150, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%151, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%152, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%153, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%154, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%155, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%156, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%157, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%158, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%159, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%160, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%161, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%162, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%163, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%164, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%165, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%166, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%167, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%168, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%169, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%170, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%171, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%172, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%173, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%174, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%175, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%176, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%177, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%178, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%179, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%180, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%181, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%182, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%183, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%184, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%185, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%186, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%187, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dff9f0) {
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dff920) {
  "llh.symbolic_bind"(%187, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%138, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%139, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%140, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%141, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%142, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%143, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%144, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%145, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%146, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%147, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%148, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%149, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%150, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%151, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%152, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%153, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%154, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%155, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%156, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%157, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%158, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%159, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%160, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%161, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%162, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%163, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%164, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%165, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%166, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%167, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%168, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%169, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%170, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%171, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%172, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%173, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%174, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%175, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%176, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%177, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%178, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%179, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%180, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%181, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%182, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%183, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%184, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%185, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%186, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dff810) {
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dff700) {
  "llh.symbolic_bind"(%186, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%138, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%139, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%140, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%141, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%142, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%143, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%144, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%145, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%146, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%147, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%148, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%149, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%150, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%151, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%152, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%153, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%154, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%155, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%156, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%157, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%158, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%159, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%160, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%161, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%162, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%163, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%164, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%165, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%166, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%167, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%168, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%169, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%170, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%171, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%172, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%173, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%174, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%175, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%176, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%177, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%178, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%179, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%180, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%181, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%182, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%183, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%184, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%185, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256dff620) {
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dff550) {
  "llh.symbolic_bind"(%185, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%138, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%139, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%140, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%141, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%142, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%143, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%144, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%145, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%146, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%147, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%148, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%149, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%150, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%151, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%152, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%153, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%154, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%155, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%156, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%157, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%158, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%159, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%160, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%161, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%162, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%163, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%164, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%165, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%166, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%167, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%168, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%169, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%170, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%171, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%172, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%173, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%174, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%175, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%176, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%177, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%178, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%179, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%180, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%181, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%182, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%183, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%184, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dfebf0) {
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dfeb20) {
  "llh.symbolic_bind"(%184, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%138, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%139, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%140, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%141, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%142, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%143, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%144, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%145, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%146, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%147, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%148, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%149, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%150, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%151, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%152, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%153, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%154, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%155, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%156, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%157, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%158, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%159, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%160, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%161, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%162, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%163, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%164, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%165, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%166, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%167, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%168, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%169, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%170, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%171, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%172, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%173, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%174, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%175, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%176, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%177, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%178, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%179, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%180, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%181, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%182, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%183, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dfea10) {
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dfe900) {
  "llh.symbolic_bind"(%183, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%138, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%139, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%140, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%141, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%142, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%143, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%144, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%145, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%146, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%147, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%148, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%149, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%150, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%151, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%152, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%153, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%154, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%155, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%156, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%157, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%158, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%159, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%160, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%161, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%162, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%163, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%164, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%165, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%166, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%167, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%168, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%169, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%170, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%171, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%172, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%173, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%174, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%175, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%176, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%177, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%178, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%179, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%180, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%181, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%182, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256dfe820) {
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dfe750) {
  "llh.symbolic_bind"(%182, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%138, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%139, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%140, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%141, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%142, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%143, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%144, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%145, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%146, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%147, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%148, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%149, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%150, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%151, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%152, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%153, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%154, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%155, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%156, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%157, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%158, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%159, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%160, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%161, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%162, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%163, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%164, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%165, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%166, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%167, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%168, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%169, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%170, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%171, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%172, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%173, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%174, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%175, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%176, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%177, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%178, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%179, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%180, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%181, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256dfe650) {
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dfe580) {
  "llh.symbolic_bind"(%181, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%138, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%139, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%140, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%141, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%142, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%143, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%144, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%145, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%146, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%147, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%148, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%149, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%150, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%151, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%152, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%153, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%154, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%155, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%156, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%157, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%158, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%159, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%160, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%161, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%162, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%163, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%164, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%165, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%166, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%167, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%168, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%169, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%170, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%171, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%172, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%173, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%174, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%175, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%176, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%177, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%178, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%179, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%180, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dfe430) {
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dfe360) {
  "llh.symbolic_bind"(%180, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%138, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%139, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%140, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%141, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%142, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%143, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%144, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%145, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%146, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%147, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%148, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%149, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%150, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%151, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%152, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%153, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%154, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%155, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%156, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%157, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%158, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%159, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%160, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%161, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%162, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%163, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%164, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%165, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%166, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%167, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%168, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%169, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%170, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%171, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%172, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%173, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%174, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%175, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%176, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%177, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%178, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%179, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dfe250) {
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dfe140) {
  "llh.symbolic_bind"(%179, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%138, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%139, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%140, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%141, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%142, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%143, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%144, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%145, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%146, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%147, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%148, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%149, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%150, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%151, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%152, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%153, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%154, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%155, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%156, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%157, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%158, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%159, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%160, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%161, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%162, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%163, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%164, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%165, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%166, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%167, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%168, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%169, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%170, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%171, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%172, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%173, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%174, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%175, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%176, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%177, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%178, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dfdff0) {
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dfdf20) {
  "llh.symbolic_bind"(%178, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%138, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%139, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%140, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%141, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%142, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%143, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%144, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%145, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%146, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%147, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%148, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%149, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%150, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%151, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%152, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%153, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%154, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%155, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%156, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%157, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%158, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%159, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%160, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%161, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%162, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%163, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%164, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%165, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%166, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%167, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%168, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%169, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%170, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%171, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%172, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%173, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%174, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%175, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%176, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%177, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dfde10) {
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dfdd00) {
  "llh.symbolic_bind"(%177, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%138, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%139, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%140, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%141, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%142, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%143, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%144, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%145, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%146, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%147, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%148, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%149, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%150, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%151, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%152, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%153, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%154, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%155, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%156, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%157, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%158, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%159, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%160, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%161, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%162, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%163, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%164, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%165, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%166, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%167, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%168, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%169, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%170, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%171, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%172, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%173, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%174, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%175, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%176, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256dfdc20) {
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dfdb50) {
  "llh.symbolic_bind"(%176, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%138, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%139, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%140, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%141, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%142, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%143, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%144, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%145, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%146, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%147, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%148, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%149, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%150, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%151, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%152, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%153, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%154, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%155, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%156, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%157, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%158, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%159, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%160, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%161, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%162, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%163, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%164, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%165, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%166, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%167, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%168, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%169, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%170, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%171, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%172, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%173, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%174, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  "llh.symbolic_bind"(%175, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dfda00) {
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dfd930) {
  "llh.symbolic_bind"(%175, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 512, (s1 - 1) floordiv 32 + 1, (s1 - 1) floordiv 32 + 1)>}> : (tensor<?x512x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%138, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%139, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%140, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%141, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%142, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%143, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%144, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%145, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%146, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%147, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%148, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%149, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%150, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%151, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%152, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%153, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%154, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%155, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%156, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%157, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%158, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%159, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%160, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%161, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%162, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%163, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%164, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%165, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%166, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%167, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%168, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%169, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%170, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%171, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%172, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%173, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%174, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dfc810) {
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dfc690) {
  "llh.symbolic_bind"(%174, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%138, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%139, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%140, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%141, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%142, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%143, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%144, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%145, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%146, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%147, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%148, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%149, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%150, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%151, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%152, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%153, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%154, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%155, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%156, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%157, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%158, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%159, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%160, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%161, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%162, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%163, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%164, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%165, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%166, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%167, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%168, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%169, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%170, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%171, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%172, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%173, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256dfc5b0) {
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dfc4e0) {
  "llh.symbolic_bind"(%173, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%138, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%139, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%140, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%141, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%142, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%143, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%144, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%145, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%146, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%147, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%148, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%149, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%150, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%151, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%152, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%153, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%154, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%155, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%156, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%157, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%158, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%159, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%160, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%161, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%162, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%163, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%164, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%165, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%166, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%167, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%168, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%169, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%170, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%171, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%172, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256dfc3e0) {
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dfc310) {
  "llh.symbolic_bind"(%172, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%138, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%139, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%140, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%141, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%142, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%143, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%144, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%145, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%146, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%147, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%148, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%149, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%150, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%151, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%152, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%153, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%154, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%155, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%156, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%157, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%158, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%159, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%160, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%161, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%162, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%163, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%164, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%165, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%166, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%167, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%168, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%169, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%170, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%171, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dfc1c0) {
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dfc0f0) {
  "llh.symbolic_bind"(%171, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%138, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%139, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%140, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%141, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%142, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%143, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%144, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%145, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%146, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%147, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%148, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%149, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%150, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%151, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%152, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%153, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%154, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%155, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%156, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%157, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%158, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%159, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%160, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%161, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%162, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%163, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%164, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%165, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%166, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%167, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%168, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%169, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%170, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dfbfe0) {
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dfbed0) {
  "llh.symbolic_bind"(%170, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%138, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%139, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%140, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%141, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%142, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%143, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%144, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%145, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%146, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%147, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%148, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%149, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%150, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%151, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%152, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%153, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%154, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%155, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%156, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%157, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%158, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%159, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%160, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%161, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%162, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%163, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%164, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%165, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%166, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%167, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%168, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%169, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256dfbdf0) {
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dfbd20) {
  "llh.symbolic_bind"(%169, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%138, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%139, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%140, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%141, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%142, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%143, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%144, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%145, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%146, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%147, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%148, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%149, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%150, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%151, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%152, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%153, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%154, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%155, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%156, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%157, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%158, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%159, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%160, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%161, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%162, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%163, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%164, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%165, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%166, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%167, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%168, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dfbbd0) {
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dfbb00) {
  "llh.symbolic_bind"(%168, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%138, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%139, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%140, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%141, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%142, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%143, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%144, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%145, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%146, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%147, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%148, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%149, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%150, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%151, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%152, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%153, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%154, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%155, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%156, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%157, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%158, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%159, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%160, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%161, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%162, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%163, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%164, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%165, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%166, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%167, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dfb9f0) {
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dfb8e0) {
  "llh.symbolic_bind"(%167, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%138, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%139, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%140, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%141, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%142, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%143, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%144, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%145, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%146, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%147, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%148, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%149, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%150, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%151, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%152, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%153, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%154, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%155, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%156, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%157, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%158, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%159, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%160, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%161, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%162, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%163, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%164, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%165, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%166, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256dfb800) {
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dfb730) {
  "llh.symbolic_bind"(%166, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%138, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%139, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%140, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%141, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%142, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%143, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%144, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%145, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%146, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%147, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%148, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%149, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%150, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%151, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%152, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%153, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%154, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%155, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%156, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%157, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%158, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%159, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%160, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%161, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%162, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%163, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%164, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%165, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256dfb630) {
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dfb560) {
  "llh.symbolic_bind"(%165, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%138, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%139, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%140, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%141, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%142, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%143, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%144, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%145, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%146, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%147, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%148, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%149, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%150, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%151, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%152, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%153, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%154, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%155, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%156, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%157, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%158, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%159, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%160, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%161, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%162, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%163, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%164, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dfb410) {
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dfb340) {
  "llh.symbolic_bind"(%164, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%138, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%139, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%140, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%141, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%142, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%143, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%144, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%145, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%146, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%147, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%148, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%149, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%150, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%151, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%152, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%153, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%154, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%155, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%156, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%157, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%158, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%159, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%160, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%161, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%162, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%163, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dfb230) {
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dfb120) {
  "llh.symbolic_bind"(%163, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%138, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%139, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%140, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%141, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%142, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%143, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%144, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%145, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%146, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%147, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%148, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%149, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%150, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%151, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%152, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%153, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%154, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%155, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%156, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%157, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%158, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%159, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%160, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%161, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%162, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dfafd0) {
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256dfa6f0) {
  "llh.symbolic_bind"(%162, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%138, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%139, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%140, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%141, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%142, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%143, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%144, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%145, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%146, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%147, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%148, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%149, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%150, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%151, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%152, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%153, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%154, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%155, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%156, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%157, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%158, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%159, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%160, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%161, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dfa5e0) {
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df9cc0) {
  "llh.symbolic_bind"(%161, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%138, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%139, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%140, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%141, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%142, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%143, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%144, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%145, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%146, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%147, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%148, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%149, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%150, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%151, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%152, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%153, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%154, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%155, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%156, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%157, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%158, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%159, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%160, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df9be0) {
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df9b10) {
  "llh.symbolic_bind"(%160, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%138, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%139, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%140, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%141, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%142, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%143, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%144, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%145, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%146, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%147, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%148, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%149, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%150, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%151, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%152, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%153, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%154, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%155, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%156, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%157, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%158, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  "llh.symbolic_bind"(%159, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df99c0) {
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df98f0) {
  "llh.symbolic_bind"(%159, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 256, (s1 - 1) floordiv 16 + 1, (s1 - 1) floordiv 16 + 1)>}> : (tensor<?x256x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%138, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%139, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%140, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%141, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%142, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%143, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%144, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%145, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%146, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%147, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%148, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%149, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%150, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%151, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%152, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%153, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%154, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%155, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%156, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%157, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%158, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256df97e0) {
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df96d0) {
  "llh.symbolic_bind"(%158, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%138, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%139, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%140, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%141, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%142, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%143, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%144, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%145, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%146, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%147, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%148, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%149, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%150, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%151, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%152, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%153, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%154, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%155, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%156, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%157, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df95f0) {
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df9520) {
  "llh.symbolic_bind"(%157, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%138, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%139, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%140, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%141, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%142, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%143, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%144, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%145, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%146, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%147, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%148, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%149, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%150, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%151, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%152, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%153, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%154, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%155, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%156, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256df9420) {
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df9350) {
  "llh.symbolic_bind"(%156, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%138, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%139, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%140, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%141, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%142, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%143, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%144, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%145, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%146, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%147, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%148, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%149, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%150, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%151, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%152, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%153, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%154, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%155, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df9200) {
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df9130) {
  "llh.symbolic_bind"(%155, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%138, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%139, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%140, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%141, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%142, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%143, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%144, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%145, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%146, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%147, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%148, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%149, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%150, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%151, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%152, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%153, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%154, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256df8810) {
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df8700) {
  "llh.symbolic_bind"(%154, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%138, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%139, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%140, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%141, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%142, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%143, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%144, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%145, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%146, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%147, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%148, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%149, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%150, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%151, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%152, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%153, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df8620) {
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df8550) {
  "llh.symbolic_bind"(%153, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%138, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%139, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%140, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%141, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%142, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%143, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%144, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%145, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%146, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%147, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%148, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%149, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%150, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%151, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%152, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df8400) {
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df7b20) {
  "llh.symbolic_bind"(%152, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%138, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%139, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%140, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%141, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%142, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%143, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%144, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%145, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%146, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%147, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%148, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%149, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%150, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%151, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256df7a10) {
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df7900) {
  "llh.symbolic_bind"(%151, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%138, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%139, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%140, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%141, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%142, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%143, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%144, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%145, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%146, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%147, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%148, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%149, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%150, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df7820) {
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df7750) {
  "llh.symbolic_bind"(%150, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%138, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%139, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%140, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%141, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%142, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%143, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%144, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%145, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%146, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%147, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%148, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%149, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256df7650) {
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df7580) {
  "llh.symbolic_bind"(%149, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%138, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%139, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%140, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%141, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%142, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%143, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%144, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%145, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%146, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%147, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%148, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df7430) {
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df7360) {
  "llh.symbolic_bind"(%148, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%138, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%139, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%140, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%141, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%142, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%143, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%144, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%145, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%146, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%147, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256df6a40) {
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df68c0) {
  "llh.symbolic_bind"(%147, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%138, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%139, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%140, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%141, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%142, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%143, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%144, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%145, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%146, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df5f60) {
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df5e90) {
  "llh.symbolic_bind"(%146, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%138, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%139, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%140, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%141, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%142, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%143, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%144, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%145, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256d6b1a0) {
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df5d50) {
  "llh.symbolic_bind"(%145, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%138, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%139, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%140, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%141, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%142, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%143, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%144, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df5c70) {
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df5ba0) {
  "llh.symbolic_bind"(%144, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%138, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%139, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%140, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%141, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%142, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  "llh.symbolic_bind"(%143, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df5a50) {
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df5980) {
  "llh.symbolic_bind"(%143, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 128, (s1 - 1) floordiv 8 + 1, (s1 - 1) floordiv 8 + 1)>}> : (tensor<?x128x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%138, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%139, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%140, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%141, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%142, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256d6f0a0) {
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df5840) {
  "llh.symbolic_bind"(%142, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%138, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%139, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%140, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%141, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df5760) {
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df5690) {
  "llh.symbolic_bind"(%141, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%138, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%139, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%140, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256df5590) {
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df54c0) {
  "llh.symbolic_bind"(%140, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%138, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%139, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df5370) {
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df52a0) {
  "llh.symbolic_bind"(%139, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%138, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256d6f2a0) {
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df5160) {
  "llh.symbolic_bind"(%138, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df5080) {
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df4fb0) {
  "llh.symbolic_bind"(%137, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df3640) {
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df3570) {
  "llh.symbolic_bind"(%136, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256d71db0) {
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df3430) {
  "llh.symbolic_bind"(%135, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df3350) {
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df3280) {
  "llh.symbolic_bind"(%134, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256de84d0) {
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df3160) {
  "llh.symbolic_bind"(%133, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df3010) {
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df2f40) {
  "llh.symbolic_bind"(%132, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256db4320) {
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df2e00) {
  "llh.symbolic_bind"(%131, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df2d20) {
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df2c50) {
  "llh.symbolic_bind"(%130, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df2b00) {
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df2a30) {
  "llh.symbolic_bind"(%129, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256db4840) {
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df2910) {
  "llh.symbolic_bind"(%128, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 4 + 1, (s1 - 1) floordiv 4 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.max_pool'(0x556256df2820) {
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df2290) {
  "llh.symbolic_bind"(%127, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256dd8f40) {
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df2170) {
  "llh.symbolic_bind"(%126, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256d7a010) {
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df1770) {
  "llh.symbolic_bind"(%125, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 64, (s1 - 1) floordiv 2 + 1, (s1 - 1) floordiv 2 + 1)>}> : (tensor<?x64x?x?xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dc82f0) {
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x556256df0c50) {
  "llh.symbolic_bind"(%arg0, %123, %124) <{expressions = affine_map<()[s0, s1] -> (s0, 3, s1, s1)>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64
  %125 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  %126 = "llh.batch_norm"(%125, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %127 = "llh.relu"(%126) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %128 = "llh.max_pool"(%127) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %129 = "llh.conv"(%128, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  %130 = "llh.batch_norm"(%129, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %131 = "llh.relu"(%130) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %132 = "llh.conv"(%131, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  %133 = "llh.batch_norm"(%132, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %134 = "llh.add"(%133, %128) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %135 = "llh.relu"(%134) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %136 = "llh.conv"(%135, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  %137 = "llh.batch_norm"(%136, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %138 = "llh.relu"(%137) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %139 = "llh.conv"(%138, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  %140 = "llh.batch_norm"(%139, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %141 = "llh.add"(%140, %135) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %142 = "llh.relu"(%141) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %143 = "llh.conv"(%142, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  %144 = "llh.batch_norm"(%143, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %145 = "llh.relu"(%144) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %146 = "llh.conv"(%145, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %147 = "llh.batch_norm"(%146, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %148 = "llh.conv"(%142, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  %149 = "llh.batch_norm"(%148, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %150 = "llh.add"(%147, %149) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %151 = "llh.relu"(%150) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %152 = "llh.conv"(%151, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %153 = "llh.batch_norm"(%152, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %154 = "llh.relu"(%153) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %155 = "llh.conv"(%154, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %156 = "llh.batch_norm"(%155, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %157 = "llh.add"(%156, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %158 = "llh.relu"(%157) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %159 = "llh.conv"(%158, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  %160 = "llh.batch_norm"(%159, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %161 = "llh.relu"(%160) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %162 = "llh.conv"(%161, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %163 = "llh.batch_norm"(%162, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %164 = "llh.conv"(%158, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  %165 = "llh.batch_norm"(%164, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %166 = "llh.add"(%163, %165) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %167 = "llh.relu"(%166) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %168 = "llh.conv"(%167, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %169 = "llh.batch_norm"(%168, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %170 = "llh.relu"(%169) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %171 = "llh.conv"(%170, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %172 = "llh.batch_norm"(%171, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %173 = "llh.add"(%172, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %174 = "llh.relu"(%173) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %175 = "llh.conv"(%174, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  %176 = "llh.batch_norm"(%175, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %177 = "llh.relu"(%176) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %178 = "llh.conv"(%177, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %179 = "llh.batch_norm"(%178, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.conv"(%174, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.batch_norm"(%180, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.add"(%179, %181) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.relu"(%182) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.conv"(%183, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.batch_norm"(%184, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.relu"(%185) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.conv"(%186, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.batch_norm"(%187, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.add"(%188, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.relu"(%189) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.adaptive_average_pool"(%190) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %192 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %193 = "llh.dim"(%191, %192) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %195 = "llh.dim"(%191, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %197 = "llh.dim"(%191, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %199 = "llh.dim"(%191, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.mul"(%195, %197) : (i64, i64) -> i64
  %201 = "llh.mul"(%200, %199) : (i64, i64) -> i64
  %202 = "llh.reshape"(%191, %193, %201) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %203 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %204 = "llh.matmul"(%202, %203) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %205 = "llh.add"(%204, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %205 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.torch_symbolic_int'(0x556256df0ba0) {
  %124 = "llh.torch_symbolic_int"() <{sym_name = "s2"}> : () -> i64


  * Pattern {anonymous}::replaceTorchSymbolicIntOp : 'llh.torch_symbolic_int -> ()' {
Trying to match "{anonymous}::replaceTorchSymbolicIntOp"
"{anonymous}::replaceTorchSymbolicIntOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %124 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %125 = "llh.dim"(%arg0, %124) : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64) -> i64
  %126 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  %127 = "llh.batch_norm"(%126, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %128 = "llh.relu"(%127) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %129 = "llh.max_pool"(%128) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %130 = "llh.conv"(%129, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  %131 = "llh.batch_norm"(%130, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %132 = "llh.relu"(%131) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %133 = "llh.conv"(%132, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  %134 = "llh.batch_norm"(%133, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %135 = "llh.add"(%134, %129) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %136 = "llh.relu"(%135) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %137 = "llh.conv"(%136, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  %138 = "llh.batch_norm"(%137, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %139 = "llh.relu"(%138) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %140 = "llh.conv"(%139, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  %141 = "llh.batch_norm"(%140, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %142 = "llh.add"(%141, %136) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %143 = "llh.relu"(%142) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %144 = "llh.conv"(%143, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  %145 = "llh.batch_norm"(%144, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %146 = "llh.relu"(%145) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %147 = "llh.conv"(%146, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %148 = "llh.batch_norm"(%147, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %149 = "llh.conv"(%143, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  %150 = "llh.batch_norm"(%149, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %151 = "llh.add"(%148, %150) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %152 = "llh.relu"(%151) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %153 = "llh.conv"(%152, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %154 = "llh.batch_norm"(%153, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %155 = "llh.relu"(%154) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %156 = "llh.conv"(%155, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %157 = "llh.batch_norm"(%156, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %158 = "llh.add"(%157, %152) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %159 = "llh.relu"(%158) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %160 = "llh.conv"(%159, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  %161 = "llh.batch_norm"(%160, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %162 = "llh.relu"(%161) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %163 = "llh.conv"(%162, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %164 = "llh.batch_norm"(%163, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %165 = "llh.conv"(%159, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  %166 = "llh.batch_norm"(%165, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %167 = "llh.add"(%164, %166) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %168 = "llh.relu"(%167) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %169 = "llh.conv"(%168, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %170 = "llh.batch_norm"(%169, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %171 = "llh.relu"(%170) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %172 = "llh.conv"(%171, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %173 = "llh.batch_norm"(%172, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %174 = "llh.add"(%173, %168) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %175 = "llh.relu"(%174) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %176 = "llh.conv"(%175, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  %177 = "llh.batch_norm"(%176, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %178 = "llh.relu"(%177) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %179 = "llh.conv"(%178, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.batch_norm"(%179, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.conv"(%175, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.batch_norm"(%181, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.add"(%180, %182) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.relu"(%183) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.conv"(%184, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.batch_norm"(%185, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.relu"(%186) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.conv"(%187, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.batch_norm"(%188, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.add"(%189, %184) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.relu"(%190) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %192 = "llh.adaptive_average_pool"(%191) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %193 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %194 = "llh.dim"(%192, %193) : (tensor<?x512x1x1xf32>, i64) -> i64
  %195 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %196 = "llh.dim"(%192, %195) : (tensor<?x512x1x1xf32>, i64) -> i64
  %197 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %198 = "llh.dim"(%192, %197) : (tensor<?x512x1x1xf32>, i64) -> i64
  %199 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %200 = "llh.dim"(%192, %199) : (tensor<?x512x1x1xf32>, i64) -> i64
  %201 = "llh.mul"(%196, %198) : (i64, i64) -> i64
  %202 = "llh.mul"(%201, %200) : (i64, i64) -> i64
  %203 = "llh.reshape"(%192, %194, %202) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %204 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %205 = "llh.matmul"(%203, %204) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %206 = "llh.add"(%205, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %206 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.torch_symbolic_int'(0x556256df0ae0) {
  %123 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64


  * Pattern {anonymous}::replaceTorchSymbolicIntOp : 'llh.torch_symbolic_int -> ()' {
Trying to match "{anonymous}::replaceTorchSymbolicIntOp"
"{anonymous}::replaceTorchSymbolicIntOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %124 = "llh.dim"(%arg0, %123) : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64) -> i64
  %125 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %126 = "llh.dim"(%arg0, %125) : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, i64) -> i64
  %127 = "llh.conv"(%arg0, %1) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  %128 = "llh.batch_norm"(%127, %2, %3, %63, %64) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %129 = "llh.relu"(%128) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %130 = "llh.max_pool"(%129) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %131 = "llh.conv"(%130, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  %132 = "llh.batch_norm"(%131, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %133 = "llh.relu"(%132) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %134 = "llh.conv"(%133, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  %135 = "llh.batch_norm"(%134, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %136 = "llh.add"(%135, %130) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %137 = "llh.relu"(%136) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %138 = "llh.conv"(%137, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  %139 = "llh.batch_norm"(%138, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %140 = "llh.relu"(%139) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %141 = "llh.conv"(%140, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  %142 = "llh.batch_norm"(%141, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %143 = "llh.add"(%142, %137) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %144 = "llh.relu"(%143) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %145 = "llh.conv"(%144, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  %146 = "llh.batch_norm"(%145, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %147 = "llh.relu"(%146) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %148 = "llh.conv"(%147, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %149 = "llh.batch_norm"(%148, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %150 = "llh.conv"(%144, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  %151 = "llh.batch_norm"(%150, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %152 = "llh.add"(%149, %151) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %153 = "llh.relu"(%152) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %154 = "llh.conv"(%153, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %155 = "llh.batch_norm"(%154, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %156 = "llh.relu"(%155) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %157 = "llh.conv"(%156, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %158 = "llh.batch_norm"(%157, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %159 = "llh.add"(%158, %153) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %160 = "llh.relu"(%159) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %161 = "llh.conv"(%160, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  %162 = "llh.batch_norm"(%161, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %163 = "llh.relu"(%162) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %164 = "llh.conv"(%163, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %165 = "llh.batch_norm"(%164, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %166 = "llh.conv"(%160, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  %167 = "llh.batch_norm"(%166, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %168 = "llh.add"(%165, %167) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %169 = "llh.relu"(%168) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %170 = "llh.conv"(%169, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %171 = "llh.batch_norm"(%170, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %172 = "llh.relu"(%171) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %173 = "llh.conv"(%172, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %174 = "llh.batch_norm"(%173, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %175 = "llh.add"(%174, %169) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %176 = "llh.relu"(%175) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %177 = "llh.conv"(%176, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  %178 = "llh.batch_norm"(%177, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %179 = "llh.relu"(%178) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.conv"(%179, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.batch_norm"(%180, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.conv"(%176, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.batch_norm"(%182, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.add"(%181, %183) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.relu"(%184) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.conv"(%185, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.batch_norm"(%186, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.relu"(%187) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.conv"(%188, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.batch_norm"(%189, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.add"(%190, %185) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %192 = "llh.relu"(%191) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %193 = "llh.adaptive_average_pool"(%192) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %194 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %195 = "llh.dim"(%193, %194) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %197 = "llh.dim"(%193, %196) : (tensor<?x512x1x1xf32>, i64) -> i64
  %198 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %199 = "llh.dim"(%193, %198) : (tensor<?x512x1x1xf32>, i64) -> i64
  %200 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %201 = "llh.dim"(%193, %200) : (tensor<?x512x1x1xf32>, i64) -> i64
  %202 = "llh.mul"(%197, %199) : (i64, i64) -> i64
  %203 = "llh.mul"(%202, %201) : (i64, i64) -> i64
  %204 = "llh.reshape"(%193, %195, %203) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %205 = "llh.transpose"(%61) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %206 = "llh.matmul"(%204, %205) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %207 = "llh.add"(%206, %62) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
  return %207 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256df09f0) {
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256df0930) {
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256df0870) {
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256df07b0) {
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256df06f0) {
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256df0630) {
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256def560) {
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256def4a0) {
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256def3e0) {
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256def320) {
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256def260) {
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256deeae0) {
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5440) {
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5380) {
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de52c0) {
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5200) {
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5140) {
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5080) {
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4fc0) {
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4f20) {
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4d80) {
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4cc0) {
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4c00) {
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4b40) {
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4a80) {
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de49c0) {
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4900) {
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dec1f0) {
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dec130) {
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dec070) {
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256debfb0) {
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256debef0) {
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256debe30) {
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256debd70) {
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256deaca0) {
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256deabe0) {
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256deab20) {
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256deaa60) {
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea9a0) {
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea8e0) {
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea820) {
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea760) {
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea6a0) {
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea5e0) {
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea520) {
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea460) {
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea3a0) {
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de9ad0) {
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de9a10) {
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de8940) {
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de8880) {
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de87c0) {
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de8700) {
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de8640) {
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de8580) {
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de8410) {
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de8350) {
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de7a80) {
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de79c0) {
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de7900) {
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de7840) {
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de7780) {
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de76c0) {
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de7600) {
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de6530) {
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de6470) {
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de63b0) {
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5f70) {
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5eb0) {
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5df0) {
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5d30) {
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de57f0) {
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5730) {
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5670) {
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5540) {
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4840) {
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4780) {
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de46c0) {
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4600) {
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de3530) {
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de3470) {
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de2ba0) {
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de2ae0) {
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de2a20) {
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de2960) {
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de28a0) {
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de27e0) {
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de22a0) {
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de21e0) {
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de2120) {
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de2060) {
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de1fa0) {
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de1ee0) {
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de1e40) {
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddcb80) {
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de0b60) {
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de0aa0) {
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de09e0) {
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de0920) {
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddfda0) {
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddfce0) {
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddf320) {
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddf260) {
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddf1a0) {
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddec60) {
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddeba0) {
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dde660) {
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dddd10) {
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddcc60) {
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dd2fa0) {
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dd2ea0) {
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddc7a0) {
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddc6e0) {
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddc620) {
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddc560) {
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddc4a0) {
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256da6a00) {
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dc3ed0) {
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dc58c0) {
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dc5a90) {
  %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dd3680) {
  %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dd3850) {
  %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'func.func'(0x556256de5490) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.constant'(0x556256dd8e70) {
  %0 = "llh.constant"() <{value = 1 : i64}> : () -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//
** Erase   : 'llh.dim'(0x556256dec290)
** Erase   : 'llh.dim'(0x556256deda20)
** Replace : 'llh.constant'(0x556256ded740)
** Modified: 'llh.dim'(0x556256f202f0)
** Erase   : 'llh.constant'(0x556256ded740)
** Replace : 'llh.constant'(0x556256dec380)
** Modified: 'llh.dim'(0x556256f1fbb0)
** Erase   : 'llh.constant'(0x556256dec380)
** Replace : 'llh.constant'(0x556256fb7210)
** Modified: 'llh.dim'(0x556256f1fd40)
** Erase   : 'llh.constant'(0x556256fb7210)

//===-------------------------------------------===//
Processing operation : 'func.return'(0x556256ded7d0) {
  "func.return"(%202) : (tensor<?x1000xf32>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256ded630) {
  %202 = "llh.add"(%201, %65) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.matmul'(0x556256ded540) {
  %201 = "llh.matmul"(%199, %200) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.transpose'(0x556256ded470) {
  %200 = "llh.transpose"(%64) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.reshape'(0x556256f20e10) {
  %199 = "llh.reshape"(%192, %193, %198) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.mul'(0x556256dd2830) {
  %198 = "llh.mul"(%197, %196) : (i64, i64) -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.mul'(0x556256f1f460) {
  %197 = "llh.mul"(%194, %195) : (i64, i64) -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.dim'(0x556256f1f2b0) {
  %196 = "llh.dim"(%192, %0) : (tensor<?x512x1x1xf32>, i64) -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.constant'(0x556256fb72f0) {
  %0 = "llh.constant"() <{value = 3 : i64}> : () -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.dim'(0x556256f1fd40) {
  %195 = "llh.dim"(%192, %1) : (tensor<?x512x1x1xf32>, i64) -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.dim'(0x556256f1fbb0) {
  %194 = "llh.dim"(%192, %3) : (tensor<?x512x1x1xf32>, i64) -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.dim'(0x556256f202f0) {
  %193 = "llh.dim"(%192, %2) : (tensor<?x512x1x1xf32>, i64) -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.adaptive_average_pool'(0x556256dfffd0) {
  %192 = "llh.adaptive_average_pool"(%191) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256dffde0) {
  %191 = "llh.relu"(%190) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256dffc10) {
  %190 = "llh.add"(%189, %184) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dff9f0) {
  %189 = "llh.batch_norm"(%188, %62, %63, %123, %124) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dff810) {
  %188 = "llh.conv"(%187, %61) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256dff620) {
  %187 = "llh.relu"(%186) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dfebf0) {
  %186 = "llh.batch_norm"(%185, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dfea10) {
  %185 = "llh.conv"(%184, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256dfe820) {
  %184 = "llh.relu"(%183) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256dfe650) {
  %183 = "llh.add"(%180, %182) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dfe430) {
  %182 = "llh.batch_norm"(%181, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dfe250) {
  %181 = "llh.conv"(%175, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dfdff0) {
  %180 = "llh.batch_norm"(%179, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dfde10) {
  %179 = "llh.conv"(%178, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256dfdc20) {
  %178 = "llh.relu"(%177) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dfda00) {
  %177 = "llh.batch_norm"(%176, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dfc810) {
  %176 = "llh.conv"(%175, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256dfc5b0) {
  %175 = "llh.relu"(%174) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256dfc3e0) {
  %174 = "llh.add"(%173, %168) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dfc1c0) {
  %173 = "llh.batch_norm"(%172, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dfbfe0) {
  %172 = "llh.conv"(%171, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256dfbdf0) {
  %171 = "llh.relu"(%170) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dfbbd0) {
  %170 = "llh.batch_norm"(%169, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dfb9f0) {
  %169 = "llh.conv"(%168, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256dfb800) {
  %168 = "llh.relu"(%167) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256dfb630) {
  %167 = "llh.add"(%164, %166) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dfb410) {
  %166 = "llh.batch_norm"(%165, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dfb230) {
  %165 = "llh.conv"(%159, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dfafd0) {
  %164 = "llh.batch_norm"(%163, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dfa5e0) {
  %163 = "llh.conv"(%162, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df9be0) {
  %162 = "llh.relu"(%161) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df99c0) {
  %161 = "llh.batch_norm"(%160, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256df97e0) {
  %160 = "llh.conv"(%159, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df95f0) {
  %159 = "llh.relu"(%158) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256df9420) {
  %158 = "llh.add"(%157, %152) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df9200) {
  %157 = "llh.batch_norm"(%156, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256df8810) {
  %156 = "llh.conv"(%155, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df8620) {
  %155 = "llh.relu"(%154) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df8400) {
  %154 = "llh.batch_norm"(%153, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256df7a10) {
  %153 = "llh.conv"(%152, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df7820) {
  %152 = "llh.relu"(%151) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256df7650) {
  %151 = "llh.add"(%148, %150) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df7430) {
  %150 = "llh.batch_norm"(%149, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256df6a40) {
  %149 = "llh.conv"(%143, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df5f60) {
  %148 = "llh.batch_norm"(%147, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256d6b1a0) {
  %147 = "llh.conv"(%146, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df5c70) {
  %146 = "llh.relu"(%145) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df5a50) {
  %145 = "llh.batch_norm"(%144, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256d6f0a0) {
  %144 = "llh.conv"(%143, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df5760) {
  %143 = "llh.relu"(%142) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256df5590) {
  %142 = "llh.add"(%141, %136) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df5370) {
  %141 = "llh.batch_norm"(%140, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256d6f2a0) {
  %140 = "llh.conv"(%139, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df5080) {
  %139 = "llh.relu"(%138) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df3640) {
  %138 = "llh.batch_norm"(%137, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256d71db0) {
  %137 = "llh.conv"(%136, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df3350) {
  %136 = "llh.relu"(%135) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256de84d0) {
  %135 = "llh.add"(%134, %129) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df3010) {
  %134 = "llh.batch_norm"(%133, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256db4320) {
  %133 = "llh.conv"(%132, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df2d20) {
  %132 = "llh.relu"(%131) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df2b00) {
  %131 = "llh.batch_norm"(%130, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256db4840) {
  %130 = "llh.conv"(%129, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.max_pool'(0x556256df2820) {
  %129 = "llh.max_pool"(%128) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256dd8f40) {
  %128 = "llh.relu"(%127) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256d7a010) {
  %127 = "llh.batch_norm"(%126, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dc82f0) {
  %126 = "llh.conv"(%arg0, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, {"0" = "s0", "1" = "c3", "2" = "s2", "3" = "s2"}>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.constant'(0x556256ddb070) {
  %1 = "llh.constant"() <{value = 2 : i64}> : () -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.constant'(0x556256dffed0) {
  %2 = "llh.constant"() <{value = 0 : i64}> : () -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256df09f0) {
  %125 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256df0930) {
  %124 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256df0870) {
  %123 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256df07b0) {
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256df06f0) {
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256df0630) {
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256def560) {
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256def4a0) {
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256def3e0) {
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256def320) {
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256def260) {
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256deeae0) {
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5440) {
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5380) {
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de52c0) {
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5200) {
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5140) {
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5080) {
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4fc0) {
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4f20) {
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4d80) {
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4cc0) {
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4c00) {
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4b40) {
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4a80) {
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de49c0) {
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4900) {
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dec1f0) {
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dec130) {
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dec070) {
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256debfb0) {
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256debef0) {
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256debe30) {
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256debd70) {
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256deaca0) {
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256deabe0) {
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256deab20) {
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256deaa60) {
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea9a0) {
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea8e0) {
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea820) {
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea760) {
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea6a0) {
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea5e0) {
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea520) {
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea460) {
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea3a0) {
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de9ad0) {
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de9a10) {
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de8940) {
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de8880) {
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de87c0) {
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de8700) {
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de8640) {
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de8580) {
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de8410) {
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de8350) {
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de7a80) {
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de79c0) {
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de7900) {
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de7840) {
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de7780) {
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de76c0) {
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de7600) {
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de6530) {
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de6470) {
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de63b0) {
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5f70) {
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5eb0) {
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5df0) {
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5d30) {
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de57f0) {
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5730) {
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5670) {
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5540) {
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4840) {
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4780) {
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de46c0) {
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4600) {
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de3530) {
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de3470) {
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de2ba0) {
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de2ae0) {
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de2a20) {
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de2960) {
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de28a0) {
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de27e0) {
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de22a0) {
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de21e0) {
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de2120) {
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de2060) {
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de1fa0) {
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de1ee0) {
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de1e40) {
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddcb80) {
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de0b60) {
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de0aa0) {
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de09e0) {
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de0920) {
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddfda0) {
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddfce0) {
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddf320) {
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddf260) {
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddf1a0) {
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddec60) {
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddeba0) {
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dde660) {
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dddd10) {
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddcc60) {
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dd2fa0) {
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dd2ea0) {
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddc7a0) {
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddc6e0) {
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddc620) {
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddc560) {
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddc4a0) {
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256da6a00) {
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dc3ed0) {
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dc58c0) {
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dc5a90) {
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dd3680) {
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dd3850) {
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'func.func'(0x556256de5490) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.constant'(0x556256dd8e70) {
  %3 = "llh.constant"() <{value = 1 : i64}> : () -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//
ImplicitTypeIDRegistry::lookupOrInsert(mlir::llh::detail::SymbolicIntOpGenericAdaptorBase::Properties)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::CallGraph)

//===-------------------------------------------===//
Processing operation : 'llh.constant'(0x556256fb72f0) {
  %0 = "llh.constant"() <{value = 3 : i64}> : () -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.constant'(0x556256ddb070) {
  %1 = "llh.constant"() <{value = 2 : i64}> : () -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.constant'(0x556256dffed0) {
  %2 = "llh.constant"() <{value = 0 : i64}> : () -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.constant'(0x556256dd8e70) {
  %3 = "llh.constant"() <{value = 1 : i64}> : () -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dd3850) {
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dd3680) {
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dc5a90) {
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dc58c0) {
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dc3ed0) {
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256da6a00) {
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddc4a0) {
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddc560) {
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddc620) {
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddc6e0) {
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddc7a0) {
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dd2ea0) {
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dd2fa0) {
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddcc60) {
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dddd10) {
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dde660) {
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddeba0) {
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddec60) {
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddf1a0) {
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddf260) {
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddf320) {
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddfce0) {
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddfda0) {
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de0920) {
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de09e0) {
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de0aa0) {
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de0b60) {
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddcb80) {
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de1e40) {
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de1ee0) {
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de1fa0) {
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de2060) {
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de2120) {
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de21e0) {
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de22a0) {
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de27e0) {
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de28a0) {
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de2960) {
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de2a20) {
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de2ae0) {
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de2ba0) {
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de3470) {
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de3530) {
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4600) {
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de46c0) {
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4780) {
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4840) {
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5540) {
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5670) {
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5730) {
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de57f0) {
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5d30) {
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5df0) {
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5eb0) {
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5f70) {
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de63b0) {
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de6470) {
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de6530) {
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de7600) {
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de76c0) {
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de7780) {
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de7840) {
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de7900) {
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de79c0) {
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de7a80) {
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de8350) {
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de8410) {
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de8580) {
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de8640) {
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de8700) {
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de87c0) {
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de8880) {
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de8940) {
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de9a10) {
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de9ad0) {
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea3a0) {
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea460) {
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea520) {
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea5e0) {
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea6a0) {
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea760) {
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea820) {
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea8e0) {
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea9a0) {
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256deaa60) {
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256deab20) {
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256deabe0) {
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256deaca0) {
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256debd70) {
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256debe30) {
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256debef0) {
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256debfb0) {
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dec070) {
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dec130) {
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dec1f0) {
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4900) {
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de49c0) {
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4a80) {
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4b40) {
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4c00) {
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4cc0) {
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4d80) {
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4f20) {
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4fc0) {
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5080) {
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5140) {
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5200) {
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de52c0) {
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5380) {
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5440) {
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256deeae0) {
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256def260) {
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256def320) {
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256def3e0) {
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256def4a0) {
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256def560) {
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256df0630) {
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256df06f0) {
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256df07b0) {
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256df0870) {
  %123 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256df0930) {
  %124 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256df09f0) {
  %125 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dc82f0) {
  %126 = "llh.conv"(%arg0, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, #llh.encoding<shapes = @s0, @c3, @s2, @s2>>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256d7a010) {
  %127 = "llh.batch_norm"(%126, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256dd8f40) {
  %128 = "llh.relu"(%127) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.max_pool'(0x556256df2820) {
  %129 = "llh.max_pool"(%128) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256db4840) {
  %130 = "llh.conv"(%129, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df2b00) {
  %131 = "llh.batch_norm"(%130, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df2d20) {
  %132 = "llh.relu"(%131) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256db4320) {
  %133 = "llh.conv"(%132, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df3010) {
  %134 = "llh.batch_norm"(%133, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256de84d0) {
  %135 = "llh.add"(%134, %129) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df3350) {
  %136 = "llh.relu"(%135) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256d71db0) {
  %137 = "llh.conv"(%136, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df3640) {
  %138 = "llh.batch_norm"(%137, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df5080) {
  %139 = "llh.relu"(%138) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256d6f2a0) {
  %140 = "llh.conv"(%139, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df5370) {
  %141 = "llh.batch_norm"(%140, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256df5590) {
  %142 = "llh.add"(%141, %136) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df5760) {
  %143 = "llh.relu"(%142) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256d6f0a0) {
  %144 = "llh.conv"(%143, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df5a50) {
  %145 = "llh.batch_norm"(%144, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df5c70) {
  %146 = "llh.relu"(%145) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256d6b1a0) {
  %147 = "llh.conv"(%146, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df5f60) {
  %148 = "llh.batch_norm"(%147, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256df6a40) {
  %149 = "llh.conv"(%143, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df7430) {
  %150 = "llh.batch_norm"(%149, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256df7650) {
  %151 = "llh.add"(%148, %150) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df7820) {
  %152 = "llh.relu"(%151) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256df7a10) {
  %153 = "llh.conv"(%152, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df8400) {
  %154 = "llh.batch_norm"(%153, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df8620) {
  %155 = "llh.relu"(%154) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256df8810) {
  %156 = "llh.conv"(%155, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df9200) {
  %157 = "llh.batch_norm"(%156, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256df9420) {
  %158 = "llh.add"(%157, %152) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df95f0) {
  %159 = "llh.relu"(%158) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256df97e0) {
  %160 = "llh.conv"(%159, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df99c0) {
  %161 = "llh.batch_norm"(%160, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df9be0) {
  %162 = "llh.relu"(%161) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dfa5e0) {
  %163 = "llh.conv"(%162, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dfafd0) {
  %164 = "llh.batch_norm"(%163, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dfb230) {
  %165 = "llh.conv"(%159, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dfb410) {
  %166 = "llh.batch_norm"(%165, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256dfb630) {
  %167 = "llh.add"(%164, %166) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256dfb800) {
  %168 = "llh.relu"(%167) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dfb9f0) {
  %169 = "llh.conv"(%168, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dfbbd0) {
  %170 = "llh.batch_norm"(%169, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256dfbdf0) {
  %171 = "llh.relu"(%170) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dfbfe0) {
  %172 = "llh.conv"(%171, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dfc1c0) {
  %173 = "llh.batch_norm"(%172, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256dfc3e0) {
  %174 = "llh.add"(%173, %168) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256dfc5b0) {
  %175 = "llh.relu"(%174) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dfc810) {
  %176 = "llh.conv"(%175, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dfda00) {
  %177 = "llh.batch_norm"(%176, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256dfdc20) {
  %178 = "llh.relu"(%177) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dfde10) {
  %179 = "llh.conv"(%178, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dfdff0) {
  %180 = "llh.batch_norm"(%179, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dfe250) {
  %181 = "llh.conv"(%175, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dfe430) {
  %182 = "llh.batch_norm"(%181, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256dfe650) {
  %183 = "llh.add"(%180, %182) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256dfe820) {
  %184 = "llh.relu"(%183) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dfea10) {
  %185 = "llh.conv"(%184, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dfebf0) {
  %186 = "llh.batch_norm"(%185, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256dff620) {
  %187 = "llh.relu"(%186) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dff810) {
  %188 = "llh.conv"(%187, %61) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dff9f0) {
  %189 = "llh.batch_norm"(%188, %62, %63, %123, %124) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256dffc10) {
  %190 = "llh.add"(%189, %184) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256dffde0) {
  %191 = "llh.relu"(%190) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.adaptive_average_pool'(0x556256dfffd0) {
  %192 = "llh.adaptive_average_pool"(%191) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.dim'(0x556256f202f0) {
  %193 = "llh.dim"(%192, %2) : (tensor<?x512x1x1xf32>, i64) -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.dim'(0x556256f1fbb0) {
  %194 = "llh.dim"(%192, %3) : (tensor<?x512x1x1xf32>, i64) -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.dim'(0x556256f1fd40) {
  %195 = "llh.dim"(%192, %1) : (tensor<?x512x1x1xf32>, i64) -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.dim'(0x556256f1f2b0) {
  %196 = "llh.dim"(%192, %0) : (tensor<?x512x1x1xf32>, i64) -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.mul'(0x556256f1f460) {
  %197 = "llh.mul"(%194, %195) : (i64, i64) -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.mul'(0x556256dd2830) {
  %198 = "llh.mul"(%197, %196) : (i64, i64) -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.reshape'(0x556256f20e10) {
  %199 = "llh.reshape"(%192, %193, %198) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.transpose'(0x556256ded470) {
  %200 = "llh.transpose"(%64) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.matmul'(0x556256ded540) {
  %201 = "llh.matmul"(%199, %200) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256ded630) {
  %202 = "llh.add"(%201, %65) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'func.return'(0x556256ded7d0) {
  "func.return"(%202) : (tensor<?x1000xf32>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//
* Inliner: Initial calls in SCC are: {
}
* Inliner: Initial calls in SCC are: {
}

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_int'(0x556256dffb40) {
  "llh.symbolic_int"() <{sym_name = "s2"}> : () -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_int'(0x556256df0b90) {
  "llh.symbolic_int"() <{sym_name = "c3"}> : () -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_int'(0x556256dfff30) {
  "llh.symbolic_int"() <{sym_name = "s0"}> : () -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'func.func'(0x556256de5490) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.constant'(0x556256fb72f0) {
  %0 = "llh.constant"() <{value = 3 : i64}> : () -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.constant'(0x556256ddb070) {
  %1 = "llh.constant"() <{value = 2 : i64}> : () -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.constant'(0x556256dffed0) {
  %2 = "llh.constant"() <{value = 0 : i64}> : () -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.constant'(0x556256dd8e70) {
  %3 = "llh.constant"() <{value = 1 : i64}> : () -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dd3850) {
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dd3680) {
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dc5a90) {
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dc58c0) {
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dc3ed0) {
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256da6a00) {
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddc4a0) {
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddc560) {
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddc620) {
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddc6e0) {
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddc7a0) {
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dd2ea0) {
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dd2fa0) {
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddcc60) {
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dddd10) {
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dde660) {
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddeba0) {
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddec60) {
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddf1a0) {
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddf260) {
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddf320) {
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddfce0) {
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddfda0) {
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de0920) {
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de09e0) {
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de0aa0) {
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de0b60) {
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddcb80) {
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de1e40) {
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de1ee0) {
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de1fa0) {
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de2060) {
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de2120) {
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de21e0) {
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de22a0) {
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de27e0) {
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de28a0) {
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de2960) {
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de2a20) {
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de2ae0) {
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de2ba0) {
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de3470) {
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de3530) {
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4600) {
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de46c0) {
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4780) {
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4840) {
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5540) {
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5670) {
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5730) {
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de57f0) {
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5d30) {
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5df0) {
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5eb0) {
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5f70) {
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de63b0) {
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de6470) {
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de6530) {
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de7600) {
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de76c0) {
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de7780) {
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de7840) {
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de7900) {
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de79c0) {
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de7a80) {
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de8350) {
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de8410) {
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de8580) {
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de8640) {
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de8700) {
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de87c0) {
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de8880) {
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de8940) {
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de9a10) {
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de9ad0) {
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea3a0) {
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea460) {
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea520) {
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea5e0) {
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea6a0) {
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea760) {
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea820) {
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea8e0) {
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea9a0) {
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256deaa60) {
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256deab20) {
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256deabe0) {
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256deaca0) {
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256debd70) {
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256debe30) {
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256debef0) {
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256debfb0) {
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dec070) {
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dec130) {
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dec1f0) {
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4900) {
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de49c0) {
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4a80) {
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4b40) {
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4c00) {
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4cc0) {
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4d80) {
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4f20) {
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4fc0) {
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5080) {
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5140) {
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5200) {
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de52c0) {
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5380) {
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5440) {
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256deeae0) {
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256def260) {
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256def320) {
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256def3e0) {
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256def4a0) {
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256def560) {
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256df0630) {
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256df06f0) {
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256df07b0) {
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256df0870) {
  %123 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256df0930) {
  %124 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256df09f0) {
  %125 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dc82f0) {
  %126 = "llh.conv"(%arg0, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, #llh.encoding<shapes = @s0, @c3, @s2, @s2>>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256d7a010) {
  %127 = "llh.batch_norm"(%126, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256dd8f40) {
  %128 = "llh.relu"(%127) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.max_pool'(0x556256df2820) {
  %129 = "llh.max_pool"(%128) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256db4840) {
  %130 = "llh.conv"(%129, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df2b00) {
  %131 = "llh.batch_norm"(%130, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df2d20) {
  %132 = "llh.relu"(%131) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256db4320) {
  %133 = "llh.conv"(%132, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df3010) {
  %134 = "llh.batch_norm"(%133, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256de84d0) {
  %135 = "llh.add"(%134, %129) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df3350) {
  %136 = "llh.relu"(%135) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256d71db0) {
  %137 = "llh.conv"(%136, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df3640) {
  %138 = "llh.batch_norm"(%137, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df5080) {
  %139 = "llh.relu"(%138) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256d6f2a0) {
  %140 = "llh.conv"(%139, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df5370) {
  %141 = "llh.batch_norm"(%140, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256df5590) {
  %142 = "llh.add"(%141, %136) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df5760) {
  %143 = "llh.relu"(%142) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256d6f0a0) {
  %144 = "llh.conv"(%143, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df5a50) {
  %145 = "llh.batch_norm"(%144, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df5c70) {
  %146 = "llh.relu"(%145) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256d6b1a0) {
  %147 = "llh.conv"(%146, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df5f60) {
  %148 = "llh.batch_norm"(%147, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256df6a40) {
  %149 = "llh.conv"(%143, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df7430) {
  %150 = "llh.batch_norm"(%149, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256df7650) {
  %151 = "llh.add"(%148, %150) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df7820) {
  %152 = "llh.relu"(%151) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256df7a10) {
  %153 = "llh.conv"(%152, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df8400) {
  %154 = "llh.batch_norm"(%153, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df8620) {
  %155 = "llh.relu"(%154) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256df8810) {
  %156 = "llh.conv"(%155, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df9200) {
  %157 = "llh.batch_norm"(%156, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256df9420) {
  %158 = "llh.add"(%157, %152) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df95f0) {
  %159 = "llh.relu"(%158) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256df97e0) {
  %160 = "llh.conv"(%159, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df99c0) {
  %161 = "llh.batch_norm"(%160, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df9be0) {
  %162 = "llh.relu"(%161) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dfa5e0) {
  %163 = "llh.conv"(%162, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dfafd0) {
  %164 = "llh.batch_norm"(%163, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dfb230) {
  %165 = "llh.conv"(%159, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dfb410) {
  %166 = "llh.batch_norm"(%165, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256dfb630) {
  %167 = "llh.add"(%164, %166) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256dfb800) {
  %168 = "llh.relu"(%167) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dfb9f0) {
  %169 = "llh.conv"(%168, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dfbbd0) {
  %170 = "llh.batch_norm"(%169, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256dfbdf0) {
  %171 = "llh.relu"(%170) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dfbfe0) {
  %172 = "llh.conv"(%171, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dfc1c0) {
  %173 = "llh.batch_norm"(%172, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256dfc3e0) {
  %174 = "llh.add"(%173, %168) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256dfc5b0) {
  %175 = "llh.relu"(%174) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dfc810) {
  %176 = "llh.conv"(%175, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dfda00) {
  %177 = "llh.batch_norm"(%176, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256dfdc20) {
  %178 = "llh.relu"(%177) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dfde10) {
  %179 = "llh.conv"(%178, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dfdff0) {
  %180 = "llh.batch_norm"(%179, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dfe250) {
  %181 = "llh.conv"(%175, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dfe430) {
  %182 = "llh.batch_norm"(%181, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256dfe650) {
  %183 = "llh.add"(%180, %182) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256dfe820) {
  %184 = "llh.relu"(%183) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dfea10) {
  %185 = "llh.conv"(%184, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dfebf0) {
  %186 = "llh.batch_norm"(%185, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256dff620) {
  %187 = "llh.relu"(%186) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dff810) {
  %188 = "llh.conv"(%187, %61) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dff9f0) {
  %189 = "llh.batch_norm"(%188, %62, %63, %123, %124) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256dffc10) {
  %190 = "llh.add"(%189, %184) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256dffde0) {
  %191 = "llh.relu"(%190) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.adaptive_average_pool'(0x556256dfffd0) {
  %192 = "llh.adaptive_average_pool"(%191) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.dim'(0x556256f202f0) {
  %193 = "llh.dim"(%192, %2) : (tensor<?x512x1x1xf32>, i64) -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.dim'(0x556256f1fbb0) {
  %194 = "llh.dim"(%192, %3) : (tensor<?x512x1x1xf32>, i64) -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.dim'(0x556256f1fd40) {
  %195 = "llh.dim"(%192, %1) : (tensor<?x512x1x1xf32>, i64) -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.dim'(0x556256f1f2b0) {
  %196 = "llh.dim"(%192, %0) : (tensor<?x512x1x1xf32>, i64) -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.mul'(0x556256f1f460) {
  %197 = "llh.mul"(%194, %195) : (i64, i64) -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.mul'(0x556256dd2830) {
  %198 = "llh.mul"(%197, %196) : (i64, i64) -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.reshape'(0x556256f20e10) {
  %199 = "llh.reshape"(%192, %193, %198) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.transpose'(0x556256ded470) {
  %200 = "llh.transpose"(%64) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.matmul'(0x556256ded540) {
  %201 = "llh.matmul"(%199, %200) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256ded630) {
  %202 = "llh.add"(%201, %65) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'func.return'(0x556256ded7d0) {
  "func.return"(%202) : (tensor<?x1000xf32>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'builtin.module'(0x556256fb8330) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'builtin.module'(0x556256fb8330) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'func.return'(0x556256ded7d0) {
  "func.return"(%202) : (tensor<?x1000xf32>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256ded630) {
  %202 = "llh.add"(%201, %65) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>


  * Pattern {anonymous}::SimplyBinaryOp<mlir::llh::AddOp> : 'llh.add -> ()' {
Trying to match "{anonymous}::SimplyBinaryOp<mlir::llh::AddOp>"
"{anonymous}::SimplyBinaryOp<mlir::llh::AddOp>" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x3x?x?xf32, #llh.encoding<shapes = @s0, @c3, @s2, @s2>>) -> tensor<?x1000xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %1 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %2 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %3 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %123 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
  %124 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
  %125 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
  %126 = "llh.conv"(%arg0, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, #llh.encoding<shapes = @s0, @c3, @s2, @s2>>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
  %127 = "llh.batch_norm"(%126, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %128 = "llh.relu"(%127) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %129 = "llh.max_pool"(%128) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %130 = "llh.conv"(%129, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  %131 = "llh.batch_norm"(%130, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %132 = "llh.relu"(%131) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %133 = "llh.conv"(%132, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  %134 = "llh.batch_norm"(%133, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %135 = "llh.add"(%134, %129) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %136 = "llh.relu"(%135) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %137 = "llh.conv"(%136, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  %138 = "llh.batch_norm"(%137, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %139 = "llh.relu"(%138) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %140 = "llh.conv"(%139, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
  %141 = "llh.batch_norm"(%140, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
  %142 = "llh.add"(%141, %136) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %143 = "llh.relu"(%142) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
  %144 = "llh.conv"(%143, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
  %145 = "llh.batch_norm"(%144, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %146 = "llh.relu"(%145) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %147 = "llh.conv"(%146, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %148 = "llh.batch_norm"(%147, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %149 = "llh.conv"(%143, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
  %150 = "llh.batch_norm"(%149, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %151 = "llh.add"(%148, %150) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %152 = "llh.relu"(%151) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %153 = "llh.conv"(%152, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %154 = "llh.batch_norm"(%153, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %155 = "llh.relu"(%154) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %156 = "llh.conv"(%155, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
  %157 = "llh.batch_norm"(%156, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
  %158 = "llh.add"(%157, %152) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %159 = "llh.relu"(%158) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
  %160 = "llh.conv"(%159, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
  %161 = "llh.batch_norm"(%160, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %162 = "llh.relu"(%161) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %163 = "llh.conv"(%162, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %164 = "llh.batch_norm"(%163, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %165 = "llh.conv"(%159, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
  %166 = "llh.batch_norm"(%165, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %167 = "llh.add"(%164, %166) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %168 = "llh.relu"(%167) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %169 = "llh.conv"(%168, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %170 = "llh.batch_norm"(%169, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %171 = "llh.relu"(%170) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %172 = "llh.conv"(%171, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
  %173 = "llh.batch_norm"(%172, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
  %174 = "llh.add"(%173, %168) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %175 = "llh.relu"(%174) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
  %176 = "llh.conv"(%175, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
  %177 = "llh.batch_norm"(%176, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %178 = "llh.relu"(%177) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %179 = "llh.conv"(%178, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %180 = "llh.batch_norm"(%179, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %181 = "llh.conv"(%175, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
  %182 = "llh.batch_norm"(%181, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %183 = "llh.add"(%180, %182) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %184 = "llh.relu"(%183) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %185 = "llh.conv"(%184, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %186 = "llh.batch_norm"(%185, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %187 = "llh.relu"(%186) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %188 = "llh.conv"(%187, %61) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
  %189 = "llh.batch_norm"(%188, %62, %63, %123, %124) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
  %190 = "llh.add"(%189, %184) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %191 = "llh.relu"(%190) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
  %192 = "llh.adaptive_average_pool"(%191) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
  %193 = "llh.dim"(%192, %2) : (tensor<?x512x1x1xf32>, i64) -> i64
  %194 = "llh.dim"(%192, %3) : (tensor<?x512x1x1xf32>, i64) -> i64
  %195 = "llh.dim"(%192, %1) : (tensor<?x512x1x1xf32>, i64) -> i64
  %196 = "llh.dim"(%192, %0) : (tensor<?x512x1x1xf32>, i64) -> i64
  %197 = "llh.mul"(%194, %195) : (i64, i64) -> i64
  %198 = "llh.mul"(%197, %196) : (i64, i64) -> i64
  %199 = "llh.reshape"(%192, %193, %198) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
  %200 = "llh.transpose"(%64) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
  %201 = "llh.matmul"(%199, %200) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
  %202 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %203 = "llh.constant"() <{value = 0 : i64}> : () -> i64
  %204 = "llh.dim"(%65, %203) : (tensor<1000xf32>, i64) -> i64
  %205 = "llh.reshape"(%65, %202, %204) : (tensor<1000xf32>, i64, i64) -> tensor<1x1000xf32>
  %206 = "llh.add"(%201, %205) : (tensor<?x1000xf32>, tensor<1x1000xf32>) -> tensor<?x1000xf32>
  return %206 : tensor<?x1000xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.matmul'(0x556256ded540) {
  %201 = "llh.matmul"(%199, %200) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.transpose'(0x556256ded470) {
  %200 = "llh.transpose"(%64) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.reshape'(0x556256f20e10) {
  %199 = "llh.reshape"(%192, %193, %198) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.mul'(0x556256dd2830) {
  %198 = "llh.mul"(%197, %196) : (i64, i64) -> i64


  * Pattern {anonymous}::SimplyBinaryOp<mlir::llh::MulOp> : 'llh.mul -> ()' {
Trying to match "{anonymous}::SimplyBinaryOp<mlir::llh::MulOp>"
"{anonymous}::SimplyBinaryOp<mlir::llh::MulOp>" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.mul'(0x556256f1f460) {
  %197 = "llh.mul"(%194, %195) : (i64, i64) -> i64


  * Pattern {anonymous}::SimplyBinaryOp<mlir::llh::MulOp> : 'llh.mul -> ()' {
Trying to match "{anonymous}::SimplyBinaryOp<mlir::llh::MulOp>"
"{anonymous}::SimplyBinaryOp<mlir::llh::MulOp>" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.dim'(0x556256f1f2b0) {
  %196 = "llh.dim"(%192, %0) : (tensor<?x512x1x1xf32>, i64) -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.dim'(0x556256f1fd40) {
  %195 = "llh.dim"(%192, %1) : (tensor<?x512x1x1xf32>, i64) -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.dim'(0x556256f1fbb0) {
  %194 = "llh.dim"(%192, %3) : (tensor<?x512x1x1xf32>, i64) -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.dim'(0x556256f202f0) {
  %193 = "llh.dim"(%192, %2) : (tensor<?x512x1x1xf32>, i64) -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.adaptive_average_pool'(0x556256dfffd0) {
  %192 = "llh.adaptive_average_pool"(%191) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256dffde0) {
  %191 = "llh.relu"(%190) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256dffc10) {
  %190 = "llh.add"(%189, %184) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>


  * Pattern {anonymous}::SimplyBinaryOp<mlir::llh::AddOp> : 'llh.add -> ()' {
Trying to match "{anonymous}::SimplyBinaryOp<mlir::llh::AddOp>"
"{anonymous}::SimplyBinaryOp<mlir::llh::AddOp>" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dff9f0) {
  %189 = "llh.batch_norm"(%188, %62, %63, %123, %124) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dff810) {
  %188 = "llh.conv"(%187, %61) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256dff620) {
  %187 = "llh.relu"(%186) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dfebf0) {
  %186 = "llh.batch_norm"(%185, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dfea10) {
  %185 = "llh.conv"(%184, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256dfe820) {
  %184 = "llh.relu"(%183) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256dfe650) {
  %183 = "llh.add"(%180, %182) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>


  * Pattern {anonymous}::SimplyBinaryOp<mlir::llh::AddOp> : 'llh.add -> ()' {
Trying to match "{anonymous}::SimplyBinaryOp<mlir::llh::AddOp>"
"{anonymous}::SimplyBinaryOp<mlir::llh::AddOp>" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dfe430) {
  %182 = "llh.batch_norm"(%181, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dfe250) {
  %181 = "llh.conv"(%175, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dfdff0) {
  %180 = "llh.batch_norm"(%179, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dfde10) {
  %179 = "llh.conv"(%178, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256dfdc20) {
  %178 = "llh.relu"(%177) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dfda00) {
  %177 = "llh.batch_norm"(%176, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dfc810) {
  %176 = "llh.conv"(%175, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256dfc5b0) {
  %175 = "llh.relu"(%174) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256dfc3e0) {
  %174 = "llh.add"(%173, %168) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>


  * Pattern {anonymous}::SimplyBinaryOp<mlir::llh::AddOp> : 'llh.add -> ()' {
Trying to match "{anonymous}::SimplyBinaryOp<mlir::llh::AddOp>"
"{anonymous}::SimplyBinaryOp<mlir::llh::AddOp>" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dfc1c0) {
  %173 = "llh.batch_norm"(%172, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dfbfe0) {
  %172 = "llh.conv"(%171, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256dfbdf0) {
  %171 = "llh.relu"(%170) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dfbbd0) {
  %170 = "llh.batch_norm"(%169, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dfb9f0) {
  %169 = "llh.conv"(%168, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256dfb800) {
  %168 = "llh.relu"(%167) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256dfb630) {
  %167 = "llh.add"(%164, %166) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>


  * Pattern {anonymous}::SimplyBinaryOp<mlir::llh::AddOp> : 'llh.add -> ()' {
Trying to match "{anonymous}::SimplyBinaryOp<mlir::llh::AddOp>"
"{anonymous}::SimplyBinaryOp<mlir::llh::AddOp>" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dfb410) {
  %166 = "llh.batch_norm"(%165, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dfb230) {
  %165 = "llh.conv"(%159, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dfafd0) {
  %164 = "llh.batch_norm"(%163, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dfa5e0) {
  %163 = "llh.conv"(%162, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df9be0) {
  %162 = "llh.relu"(%161) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df99c0) {
  %161 = "llh.batch_norm"(%160, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256df97e0) {
  %160 = "llh.conv"(%159, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df95f0) {
  %159 = "llh.relu"(%158) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256df9420) {
  %158 = "llh.add"(%157, %152) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>


  * Pattern {anonymous}::SimplyBinaryOp<mlir::llh::AddOp> : 'llh.add -> ()' {
Trying to match "{anonymous}::SimplyBinaryOp<mlir::llh::AddOp>"
"{anonymous}::SimplyBinaryOp<mlir::llh::AddOp>" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df9200) {
  %157 = "llh.batch_norm"(%156, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256df8810) {
  %156 = "llh.conv"(%155, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df8620) {
  %155 = "llh.relu"(%154) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df8400) {
  %154 = "llh.batch_norm"(%153, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256df7a10) {
  %153 = "llh.conv"(%152, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df7820) {
  %152 = "llh.relu"(%151) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256df7650) {
  %151 = "llh.add"(%148, %150) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>


  * Pattern {anonymous}::SimplyBinaryOp<mlir::llh::AddOp> : 'llh.add -> ()' {
Trying to match "{anonymous}::SimplyBinaryOp<mlir::llh::AddOp>"
"{anonymous}::SimplyBinaryOp<mlir::llh::AddOp>" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df7430) {
  %150 = "llh.batch_norm"(%149, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256df6a40) {
  %149 = "llh.conv"(%143, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df5f60) {
  %148 = "llh.batch_norm"(%147, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256d6b1a0) {
  %147 = "llh.conv"(%146, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df5c70) {
  %146 = "llh.relu"(%145) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df5a50) {
  %145 = "llh.batch_norm"(%144, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256d6f0a0) {
  %144 = "llh.conv"(%143, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df5760) {
  %143 = "llh.relu"(%142) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256df5590) {
  %142 = "llh.add"(%141, %136) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>


  * Pattern {anonymous}::SimplyBinaryOp<mlir::llh::AddOp> : 'llh.add -> ()' {
Trying to match "{anonymous}::SimplyBinaryOp<mlir::llh::AddOp>"
"{anonymous}::SimplyBinaryOp<mlir::llh::AddOp>" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df5370) {
  %141 = "llh.batch_norm"(%140, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256d6f2a0) {
  %140 = "llh.conv"(%139, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df5080) {
  %139 = "llh.relu"(%138) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df3640) {
  %138 = "llh.batch_norm"(%137, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256d71db0) {
  %137 = "llh.conv"(%136, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df3350) {
  %136 = "llh.relu"(%135) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256de84d0) {
  %135 = "llh.add"(%134, %129) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>


  * Pattern {anonymous}::SimplyBinaryOp<mlir::llh::AddOp> : 'llh.add -> ()' {
Trying to match "{anonymous}::SimplyBinaryOp<mlir::llh::AddOp>"
"{anonymous}::SimplyBinaryOp<mlir::llh::AddOp>" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df3010) {
  %134 = "llh.batch_norm"(%133, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256db4320) {
  %133 = "llh.conv"(%132, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df2d20) {
  %132 = "llh.relu"(%131) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df2b00) {
  %131 = "llh.batch_norm"(%130, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256db4840) {
  %130 = "llh.conv"(%129, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.max_pool'(0x556256df2820) {
  %129 = "llh.max_pool"(%128) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256dd8f40) {
  %128 = "llh.relu"(%127) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256d7a010) {
  %127 = "llh.batch_norm"(%126, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dc82f0) {
  %126 = "llh.conv"(%arg0, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, #llh.encoding<shapes = @s0, @c3, @s2, @s2>>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256df09f0) {
  %125 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256df0930) {
  %124 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256df0870) {
  %123 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256df07b0) {
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256df06f0) {
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256df0630) {
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256def560) {
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256def4a0) {
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256def3e0) {
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256def320) {
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256def260) {
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256deeae0) {
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5440) {
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5380) {
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de52c0) {
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5200) {
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5140) {
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5080) {
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4fc0) {
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4f20) {
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4d80) {
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4cc0) {
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4c00) {
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4b40) {
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4a80) {
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de49c0) {
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4900) {
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dec1f0) {
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dec130) {
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dec070) {
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256debfb0) {
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256debef0) {
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256debe30) {
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256debd70) {
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256deaca0) {
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256deabe0) {
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256deab20) {
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256deaa60) {
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea9a0) {
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea8e0) {
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea820) {
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea760) {
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea6a0) {
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea5e0) {
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea520) {
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea460) {
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea3a0) {
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de9ad0) {
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de9a10) {
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de8940) {
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de8880) {
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de87c0) {
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de8700) {
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de8640) {
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de8580) {
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de8410) {
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de8350) {
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de7a80) {
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de79c0) {
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de7900) {
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de7840) {
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de7780) {
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de76c0) {
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de7600) {
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de6530) {
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de6470) {
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de63b0) {
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5f70) {
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5eb0) {
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5df0) {
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5d30) {
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de57f0) {
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5730) {
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5670) {
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5540) {
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4840) {
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4780) {
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de46c0) {
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4600) {
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de3530) {
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de3470) {
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de2ba0) {
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de2ae0) {
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de2a20) {
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de2960) {
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de28a0) {
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de27e0) {
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de22a0) {
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de21e0) {
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de2120) {
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de2060) {
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de1fa0) {
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de1ee0) {
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de1e40) {
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddcb80) {
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de0b60) {
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de0aa0) {
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de09e0) {
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de0920) {
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddfda0) {
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddfce0) {
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddf320) {
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddf260) {
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddf1a0) {
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddec60) {
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddeba0) {
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dde660) {
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dddd10) {
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddcc60) {
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dd2fa0) {
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dd2ea0) {
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddc7a0) {
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddc6e0) {
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddc620) {
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddc560) {
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddc4a0) {
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256da6a00) {
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dc3ed0) {
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dc58c0) {
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dc5a90) {
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dd3680) {
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dd3850) {
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.constant'(0x556256dd8e70) {
  %3 = "llh.constant"() <{value = 1 : i64}> : () -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.constant'(0x556256dffed0) {
  %2 = "llh.constant"() <{value = 0 : i64}> : () -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.constant'(0x556256ddb070) {
  %1 = "llh.constant"() <{value = 2 : i64}> : () -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'func.func'(0x556256de5490) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.constant'(0x556256fb72f0) {
  %0 = "llh.constant"() <{value = 3 : i64}> : () -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_int'(0x556256dfff30) {
  "llh.symbolic_int"() <{sym_name = "s0"}> : () -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_int'(0x556256df0b90) {
  "llh.symbolic_int"() <{sym_name = "c3"}> : () -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_int'(0x556256dffb40) {
  "llh.symbolic_int"() <{sym_name = "s2"}> : () -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//
** Replace : 'llh.constant'(0x556256dec380)
** Modified: 'llh.reshape'(0x556256f1fff0)
** Erase   : 'llh.constant'(0x556256dec380)
** Replace : 'llh.constant'(0x556256fb7210)
** Modified: 'llh.dim'(0x556256deda20)
** Erase   : 'llh.constant'(0x556256fb7210)

//===-------------------------------------------===//
Processing operation : 'builtin.module'(0x556256fb8330) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'func.return'(0x556256ded7d0) {
  "func.return"(%204) : (tensor<?x1000xf32>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256dec290) {
  %204 = "llh.add"(%201, %203) : (tensor<?x1000xf32>, tensor<1x1000xf32>) -> tensor<?x1000xf32>


  * Pattern {anonymous}::SimplyBinaryOp<mlir::llh::AddOp> : 'llh.add -> ()' {
Trying to match "{anonymous}::SimplyBinaryOp<mlir::llh::AddOp>"
"{anonymous}::SimplyBinaryOp<mlir::llh::AddOp>" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.dim'(0x556256deda20) {
  %202 = "llh.dim"(%65, %2) : (tensor<1000xf32>, i64) -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.reshape'(0x556256f1fff0) {
  %203 = "llh.reshape"(%65, %3, %202) : (tensor<1000xf32>, i64, i64) -> tensor<1x1000xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.matmul'(0x556256ded540) {
  %201 = "llh.matmul"(%199, %200) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.transpose'(0x556256ded470) {
  %200 = "llh.transpose"(%64) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.reshape'(0x556256f20e10) {
  %199 = "llh.reshape"(%192, %193, %198) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.mul'(0x556256dd2830) {
  %198 = "llh.mul"(%197, %196) : (i64, i64) -> i64


  * Pattern {anonymous}::SimplyBinaryOp<mlir::llh::MulOp> : 'llh.mul -> ()' {
Trying to match "{anonymous}::SimplyBinaryOp<mlir::llh::MulOp>"
"{anonymous}::SimplyBinaryOp<mlir::llh::MulOp>" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.mul'(0x556256f1f460) {
  %197 = "llh.mul"(%194, %195) : (i64, i64) -> i64


  * Pattern {anonymous}::SimplyBinaryOp<mlir::llh::MulOp> : 'llh.mul -> ()' {
Trying to match "{anonymous}::SimplyBinaryOp<mlir::llh::MulOp>"
"{anonymous}::SimplyBinaryOp<mlir::llh::MulOp>" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.dim'(0x556256f1f2b0) {
  %196 = "llh.dim"(%192, %0) : (tensor<?x512x1x1xf32>, i64) -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.dim'(0x556256f1fd40) {
  %195 = "llh.dim"(%192, %1) : (tensor<?x512x1x1xf32>, i64) -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.dim'(0x556256f1fbb0) {
  %194 = "llh.dim"(%192, %3) : (tensor<?x512x1x1xf32>, i64) -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.dim'(0x556256f202f0) {
  %193 = "llh.dim"(%192, %2) : (tensor<?x512x1x1xf32>, i64) -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.adaptive_average_pool'(0x556256dfffd0) {
  %192 = "llh.adaptive_average_pool"(%191) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256dffde0) {
  %191 = "llh.relu"(%190) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256dffc10) {
  %190 = "llh.add"(%189, %184) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>


  * Pattern {anonymous}::SimplyBinaryOp<mlir::llh::AddOp> : 'llh.add -> ()' {
Trying to match "{anonymous}::SimplyBinaryOp<mlir::llh::AddOp>"
"{anonymous}::SimplyBinaryOp<mlir::llh::AddOp>" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dff9f0) {
  %189 = "llh.batch_norm"(%188, %62, %63, %123, %124) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dff810) {
  %188 = "llh.conv"(%187, %61) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256dff620) {
  %187 = "llh.relu"(%186) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dfebf0) {
  %186 = "llh.batch_norm"(%185, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dfea10) {
  %185 = "llh.conv"(%184, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256dfe820) {
  %184 = "llh.relu"(%183) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256dfe650) {
  %183 = "llh.add"(%180, %182) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>


  * Pattern {anonymous}::SimplyBinaryOp<mlir::llh::AddOp> : 'llh.add -> ()' {
Trying to match "{anonymous}::SimplyBinaryOp<mlir::llh::AddOp>"
"{anonymous}::SimplyBinaryOp<mlir::llh::AddOp>" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dfe430) {
  %182 = "llh.batch_norm"(%181, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dfe250) {
  %181 = "llh.conv"(%175, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dfdff0) {
  %180 = "llh.batch_norm"(%179, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dfde10) {
  %179 = "llh.conv"(%178, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256dfdc20) {
  %178 = "llh.relu"(%177) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dfda00) {
  %177 = "llh.batch_norm"(%176, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dfc810) {
  %176 = "llh.conv"(%175, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256dfc5b0) {
  %175 = "llh.relu"(%174) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256dfc3e0) {
  %174 = "llh.add"(%173, %168) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>


  * Pattern {anonymous}::SimplyBinaryOp<mlir::llh::AddOp> : 'llh.add -> ()' {
Trying to match "{anonymous}::SimplyBinaryOp<mlir::llh::AddOp>"
"{anonymous}::SimplyBinaryOp<mlir::llh::AddOp>" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dfc1c0) {
  %173 = "llh.batch_norm"(%172, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dfbfe0) {
  %172 = "llh.conv"(%171, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256dfbdf0) {
  %171 = "llh.relu"(%170) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dfbbd0) {
  %170 = "llh.batch_norm"(%169, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dfb9f0) {
  %169 = "llh.conv"(%168, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256dfb800) {
  %168 = "llh.relu"(%167) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256dfb630) {
  %167 = "llh.add"(%164, %166) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>


  * Pattern {anonymous}::SimplyBinaryOp<mlir::llh::AddOp> : 'llh.add -> ()' {
Trying to match "{anonymous}::SimplyBinaryOp<mlir::llh::AddOp>"
"{anonymous}::SimplyBinaryOp<mlir::llh::AddOp>" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dfb410) {
  %166 = "llh.batch_norm"(%165, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dfb230) {
  %165 = "llh.conv"(%159, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256dfafd0) {
  %164 = "llh.batch_norm"(%163, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dfa5e0) {
  %163 = "llh.conv"(%162, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df9be0) {
  %162 = "llh.relu"(%161) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df99c0) {
  %161 = "llh.batch_norm"(%160, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256df97e0) {
  %160 = "llh.conv"(%159, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df95f0) {
  %159 = "llh.relu"(%158) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256df9420) {
  %158 = "llh.add"(%157, %152) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>


  * Pattern {anonymous}::SimplyBinaryOp<mlir::llh::AddOp> : 'llh.add -> ()' {
Trying to match "{anonymous}::SimplyBinaryOp<mlir::llh::AddOp>"
"{anonymous}::SimplyBinaryOp<mlir::llh::AddOp>" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df9200) {
  %157 = "llh.batch_norm"(%156, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256df8810) {
  %156 = "llh.conv"(%155, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df8620) {
  %155 = "llh.relu"(%154) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df8400) {
  %154 = "llh.batch_norm"(%153, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256df7a10) {
  %153 = "llh.conv"(%152, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df7820) {
  %152 = "llh.relu"(%151) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256df7650) {
  %151 = "llh.add"(%148, %150) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>


  * Pattern {anonymous}::SimplyBinaryOp<mlir::llh::AddOp> : 'llh.add -> ()' {
Trying to match "{anonymous}::SimplyBinaryOp<mlir::llh::AddOp>"
"{anonymous}::SimplyBinaryOp<mlir::llh::AddOp>" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df7430) {
  %150 = "llh.batch_norm"(%149, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256df6a40) {
  %149 = "llh.conv"(%143, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df5f60) {
  %148 = "llh.batch_norm"(%147, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256d6b1a0) {
  %147 = "llh.conv"(%146, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df5c70) {
  %146 = "llh.relu"(%145) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df5a50) {
  %145 = "llh.batch_norm"(%144, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256d6f0a0) {
  %144 = "llh.conv"(%143, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df5760) {
  %143 = "llh.relu"(%142) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256df5590) {
  %142 = "llh.add"(%141, %136) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>


  * Pattern {anonymous}::SimplyBinaryOp<mlir::llh::AddOp> : 'llh.add -> ()' {
Trying to match "{anonymous}::SimplyBinaryOp<mlir::llh::AddOp>"
"{anonymous}::SimplyBinaryOp<mlir::llh::AddOp>" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df5370) {
  %141 = "llh.batch_norm"(%140, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256d6f2a0) {
  %140 = "llh.conv"(%139, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df5080) {
  %139 = "llh.relu"(%138) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df3640) {
  %138 = "llh.batch_norm"(%137, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256d71db0) {
  %137 = "llh.conv"(%136, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df3350) {
  %136 = "llh.relu"(%135) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256de84d0) {
  %135 = "llh.add"(%134, %129) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>


  * Pattern {anonymous}::SimplyBinaryOp<mlir::llh::AddOp> : 'llh.add -> ()' {
Trying to match "{anonymous}::SimplyBinaryOp<mlir::llh::AddOp>"
"{anonymous}::SimplyBinaryOp<mlir::llh::AddOp>" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df3010) {
  %134 = "llh.batch_norm"(%133, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256db4320) {
  %133 = "llh.conv"(%132, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256df2d20) {
  %132 = "llh.relu"(%131) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256df2b00) {
  %131 = "llh.batch_norm"(%130, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256db4840) {
  %130 = "llh.conv"(%129, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.max_pool'(0x556256df2820) {
  %129 = "llh.max_pool"(%128) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.relu'(0x556256dd8f40) {
  %128 = "llh.relu"(%127) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.batch_norm'(0x556256d7a010) {
  %127 = "llh.batch_norm"(%126, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv'(0x556256dc82f0) {
  %126 = "llh.conv"(%arg0, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, #llh.encoding<shapes = @s0, @c3, @s2, @s2>>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256df09f0) {
  %125 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256df0930) {
  %124 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256df0870) {
  %123 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256df07b0) {
  %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256df06f0) {
  %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256df0630) {
  %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256def560) {
  %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256def4a0) {
  %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256def3e0) {
  %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256def320) {
  %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256def260) {
  %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256deeae0) {
  %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5440) {
  %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5380) {
  %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de52c0) {
  %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5200) {
  %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5140) {
  %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5080) {
  %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4fc0) {
  %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4f20) {
  %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4d80) {
  %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4cc0) {
  %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4c00) {
  %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4b40) {
  %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4a80) {
  %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de49c0) {
  %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4900) {
  %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dec1f0) {
  %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dec130) {
  %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dec070) {
  %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256debfb0) {
  %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256debef0) {
  %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256debe30) {
  %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256debd70) {
  %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256deaca0) {
  %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256deabe0) {
  %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256deab20) {
  %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256deaa60) {
  %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea9a0) {
  %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea8e0) {
  %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea820) {
  %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea760) {
  %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea6a0) {
  %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea5e0) {
  %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea520) {
  %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea460) {
  %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dea3a0) {
  %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de9ad0) {
  %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de9a10) {
  %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de8940) {
  %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de8880) {
  %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de87c0) {
  %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de8700) {
  %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de8640) {
  %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de8580) {
  %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de8410) {
  %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de8350) {
  %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de7a80) {
  %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de79c0) {
  %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de7900) {
  %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de7840) {
  %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de7780) {
  %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de76c0) {
  %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de7600) {
  %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de6530) {
  %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de6470) {
  %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de63b0) {
  %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5f70) {
  %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5eb0) {
  %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5df0) {
  %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5d30) {
  %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de57f0) {
  %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5730) {
  %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5670) {
  %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de5540) {
  %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4840) {
  %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4780) {
  %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de46c0) {
  %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de4600) {
  %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de3530) {
  %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de3470) {
  %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de2ba0) {
  %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de2ae0) {
  %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de2a20) {
  %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de2960) {
  %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de28a0) {
  %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de27e0) {
  %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de22a0) {
  %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de21e0) {
  %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de2120) {
  %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de2060) {
  %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de1fa0) {
  %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de1ee0) {
  %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de1e40) {
  %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddcb80) {
  %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de0b60) {
  %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de0aa0) {
  %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de09e0) {
  %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256de0920) {
  %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddfda0) {
  %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddfce0) {
  %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddf320) {
  %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddf260) {
  %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddf1a0) {
  %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddec60) {
  %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddeba0) {
  %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dde660) {
  %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dddd10) {
  %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddcc60) {
  %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dd2fa0) {
  %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dd2ea0) {
  %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddc7a0) {
  %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddc6e0) {
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddc620) {
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddc560) {
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256ddc4a0) {
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256da6a00) {
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dc3ed0) {
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dc58c0) {
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dc5a90) {
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dd3680) {
  %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x556256dd3850) {
  %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-18T03:28:09.884125+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.constant'(0x556256dd8e70) {
  %3 = "llh.constant"() <{value = 1 : i64}> : () -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.constant'(0x556256dffed0) {
  %2 = "llh.constant"() <{value = 0 : i64}> : () -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.constant'(0x556256ddb070) {
  %1 = "llh.constant"() <{value = 2 : i64}> : () -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'func.func'(0x556256de5490) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.constant'(0x556256fb72f0) {
  %0 = "llh.constant"() <{value = 3 : i64}> : () -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_int'(0x556256dfff30) {
  "llh.symbolic_int"() <{sym_name = "s0"}> : () -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_int'(0x556256df0b90) {
  "llh.symbolic_int"() <{sym_name = "c3"}> : () -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_int'(0x556256dffb40) {
  "llh.symbolic_int"() <{sym_name = "s2"}> : () -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'builtin.module'(0x556256fb8330) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'func.return'(0x556256ded7d0) {
  "func.return"(%204) : (tensor<?x1000xf32>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x556256dec290) {
  %204 = "llh.add"(%201, %203) : (tensor<?x1000xf32>, tensor<1x1000xf32>) -> tensor<?x1000xf32>


  * Pattern {anonymous}::SimplyBinaryOp<mlir::llh::AddOp> : 'llh.add -> ()' {
Trying to match "{anonymous}::SimplyBinaryOp<mlir::llh::AddOp>"
PLEASE submit a bug report to https://github.com/llvm/llvm-project/issues/ and include the crash backtrace.
Stack dump:
0.	Program arguments: /home/lfr/LLCompiler/build/bin/llc-opt --dump-pass-pipeline /home/lfr/LLCompiler/ir_tree/inference/fx/resnet18/builtin_module_no-symbol-name/0_operation-legalization.mlir --debug -basic-pipeline
Stack dump without symbol names (ensure you have llvm-symbolizer in your PATH or set the environment var `LLVM_SYMBOLIZER_PATH` to point to it):
0  libLLVMSupport.so.20.0git        0x00007fb1bfaa8ff0 llvm::sys::PrintStackTrace(llvm::raw_ostream&, int) + 240
1  libLLVMSupport.so.20.0git        0x00007fb1bfaa655a llvm::sys::RunSignalHandlers() + 58
2  libLLVMSupport.so.20.0git        0x00007fb1bfaa67c5
3  libc.so.6                        0x00007fb1bf47b520
4  libLLCMLIRUtility.so             0x00007fb1be81e580 llc::getEncodingFrom(mlir::Type) + 192
5  libMLIRLLHTransforms.so          0x00007fb1c21141b7
6  libMLIRLLHTransforms.so          0x00007fb1c210d919 mlir::detail::LLCOpOrInterfaceRewritePatternBase<mlir::llh::AddOp>::matchAndRewrite(mlir::llh::AddOp, mlir::LLHPatternRewriter&) const + 393
7  libMLIRLLHTransforms.so          0x00007fb1c210ddc4 mlir::detail::LLCOpOrInterfaceRewritePatternBase<mlir::llh::AddOp>::matchAndRewrite(mlir::Operation*, mlir::PatternRewriter&) const + 324
8  libMLIRRewrite.so.20.0git        0x00007fb1be729908 mlir::PatternApplicator::matchAndRewrite(mlir::Operation*, mlir::PatternRewriter&, llvm::function_ref<bool (mlir::Pattern const&)>, llvm::function_ref<void (mlir::Pattern const&)>, llvm::function_ref<llvm::LogicalResult (mlir::Pattern const&)>) + 2776
9  libMLIRTransformUtils.so.20.0git 0x00007fb1be7974fe
10 libMLIRTransformUtils.so.20.0git 0x00007fb1be799d05 mlir::applyPatternsAndFoldGreedily(mlir::Region&, mlir::FrozenRewritePatternSet const&, mlir::GreedyRewriteConfig, bool*) + 1093
11 libMLIRLLHTransforms.so          0x00007fb1c21132ca
12 libMLIRPass.so.20.0git           0x00007fb1bfe5b351 mlir::detail::OpToOpPassAdaptor::run(mlir::Pass*, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int) + 1313
13 libMLIRPass.so.20.0git           0x00007fb1bfe5b8c1 mlir::detail::OpToOpPassAdaptor::runPipeline(mlir::OpPassManager&, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int, mlir::PassInstrumentor*, mlir::PassInstrumentation::PipelineParentInfo const*) + 321
14 libMLIRPass.so.20.0git           0x00007fb1bfe5c945 mlir::PassManager::run(mlir::Operation*) + 1445
15 libMLIROptLib.so.20.0git         0x00007fb1c21b32b7
16 libMLIROptLib.so.20.0git         0x00007fb1c21b3ccc
17 libMLIROptLib.so.20.0git         0x00007fb1c21b3e2d
18 libMLIRSupport.so.20.0git        0x00007fb1bfb958de mlir::splitAndProcessBuffer(std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::function_ref<llvm::LogicalResult (std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::raw_ostream&)>, llvm::raw_ostream&, llvm::StringRef, llvm::StringRef) + 174
19 libMLIROptLib.so.20.0git         0x00007fb1c21aa4bc mlir::MlirOptMain(llvm::raw_ostream&, std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, mlir::DialectRegistry&, mlir::MlirOptMainConfig const&) + 220
20 libMLIROptLib.so.20.0git         0x00007fb1c21b3f90 mlir::MlirOptMain(int, char**, llvm::StringRef, llvm::StringRef, mlir::DialectRegistry&) + 304
21 libMLIROptLib.so.20.0git         0x00007fb1c21b44b7 mlir::MlirOptMain(int, char**, llvm::StringRef, mlir::DialectRegistry&) + 391
22 llc-opt                          0x0000556255fc4300
23 libc.so.6                        0x00007fb1bf462d90
24 libc.so.6                        0x00007fb1bf462e40 __libc_start_main + 128
25 llc-opt                          0x0000556255fc4435
