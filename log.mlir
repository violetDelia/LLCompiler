Args: /home/lfr/LLCompiler/build/bin/llc-opt --dump-pass-pipeline -o=/home/lfr/LLCompiler/out.mlir --log-lever=debug --log-root=C:codingLLCompilerlog --mlir-print-ir-tree-dir=/home/lfr/LLCompiler/ir_tree --mlir-print-ir-after-all -basic-pipeline /home/lfr/LLCompiler/test/model_ir/Base.mlir --debug 
Load new dialect in Context builtin
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ShapedType)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::MemRefLayoutAttrInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::TypedAttr)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ElementsAttr)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DistinctAttr)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::BytecodeOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SymbolOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpAsmOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::RegionKindInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ConditionallySpeculatable)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::MemoryEffectOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ResourceBlobManagerDialectInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpAsmDialectInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::BytecodeDialectInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::AffineBinaryOpExprStorage)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::AffineConstantExprStorage)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::AffineDimExprStorage)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::AffineMapStorage)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::IntegerSetStorage)
Load new dialect in Context builtin
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::ZeroOperands<mlir::TypeID::get<mlir::OpTrait::ZeroOperands>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneRegion<mlir::TypeID::get<mlir::OpTrait::OneRegion>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::ZeroResults<mlir::TypeID::get<mlir::OpTrait::ZeroResults>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::ZeroSuccessors<mlir::TypeID::get<mlir::OpTrait::ZeroSuccessors>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::NoRegionArguments<mlir::TypeID::get<mlir::OpTrait::NoRegionArguments>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::NoTerminator<mlir::TypeID::get<mlir::OpTrait::NoTerminator>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SingleBlock<mlir::TypeID::get<mlir::OpTrait::SingleBlock>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OpInvariants<mlir::TypeID::get<mlir::OpTrait::OpInvariants>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::BytecodeOpInterface::Trait<mlir::TypeID::get<mlir::BytecodeOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::AffineScope<mlir::TypeID::get<mlir::OpTrait::AffineScope>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::IsIsolatedFromAbove<mlir::TypeID::get<mlir::OpTrait::IsIsolatedFromAbove>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SymbolTable<mlir::TypeID::get<mlir::OpTrait::SymbolTable>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SymbolOpInterface::Trait<mlir::TypeID::get<mlir::SymbolOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpAsmOpInterface::Trait<mlir::TypeID::get<mlir::OpAsmOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::RegionKindInterface::Trait<mlir::TypeID::get<mlir::RegionKindInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::HasOnlyGraphRegion<mlir::TypeID::get<mlir::OpTrait::HasOnlyGraphRegion>()::Empty>)
Load new dialect in Context func
ImplicitTypeIDRegistry::lookupOrInsert(mlir::CallOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SymbolUserOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::CallableOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::FunctionOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::RegionBranchTerminatorOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DialectInlinerInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ConvertToLLVMPatternInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::bufferization::BufferizableOpInterface)
Load new dialect in Context cf
Load new dialect in Context arith
ImplicitTypeIDRegistry::lookupOrInsert(mlir::arith::ArithFastMathInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::VectorUnrollOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::InferTypeOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::InferIntRangeInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::arith::ArithIntegerOverflowFlagsInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::CastOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::arith::ArithRoundingModeInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SelectLikeOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::bufferization::BufferDeallocationOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ValueBoundsOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::BranchOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::AutomaticAllocationScope<mlir::TypeID::get<mlir::OpTrait::AutomaticAllocationScope>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::CallableOpInterface::Trait<mlir::TypeID::get<mlir::CallableOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::FunctionOpInterface::Trait<mlir::TypeID::get<mlir::FunctionOpInterface::Trait>()::Empty>)
Load new dialect in Context llh
Load new dialect in Context mlir_ex
ImplicitTypeIDRegistry::lookupOrInsert(mlir::InferShapedTypeOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SymbolicInferShapeOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::ZeroRegions<mlir::TypeID::get<mlir::OpTrait::ZeroRegions>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneResult<mlir::TypeID::get<mlir::OpTrait::OneResult>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneTypedResult<mlir::Type>::Impl<mlir::TypeID::get<mlir::OpTrait::OneTypedResult<mlir::Type>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::InferShapedTypeOpInterface::Trait<mlir::TypeID::get<mlir::InferShapedTypeOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SymbolicInferShapeOpInterface::Trait<mlir::TypeID::get<mlir::SymbolicInferShapeOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneTypedResult<mlir::IntegerType>::Impl<mlir::TypeID::get<mlir::OpTrait::OneTypedResult<mlir::IntegerType>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::InferTypeOpInterface::Trait<mlir::TypeID::get<mlir::InferTypeOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::ConstantLike<mlir::TypeID::get<mlir::OpTrait::ConstantLike>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::VariadicOperands<mlir::TypeID::get<mlir::OpTrait::VariadicOperands>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::HasParent<mlir::func::FuncOp>::Impl<mlir::TypeID::get<mlir::OpTrait::HasParent<mlir::func::FuncOp>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ConditionallySpeculatable::Trait<mlir::TypeID::get<mlir::ConditionallySpeculatable::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::AlwaysSpeculatableImplTrait<mlir::TypeID::get<mlir::OpTrait::AlwaysSpeculatableImplTrait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::MemoryEffectOpInterface::Trait<mlir::TypeID::get<mlir::MemoryEffectOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::MemRefsNormalizable<mlir::TypeID::get<mlir::OpTrait::MemRefsNormalizable>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::RegionBranchTerminatorOpInterface::Trait<mlir::TypeID::get<mlir::RegionBranchTerminatorOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::ReturnLike<mlir::TypeID::get<mlir::OpTrait::ReturnLike>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::IsTerminator<mlir::TypeID::get<mlir::OpTrait::IsTerminator>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DataLayoutSpecInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::AtLeastNOperands<1>::Impl<mlir::TypeID::get<mlir::OpTrait::AtLeastNOperands<1>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::NOperands<2>::Impl<mlir::TypeID::get<mlir::OpTrait::NOperands<2>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::NOperands<3>::Impl<mlir::TypeID::get<mlir::OpTrait::NOperands<3>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::ResultsBroadcastableShape<mlir::TypeID::get<mlir::OpTrait::ResultsBroadcastableShape>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneOperand<mlir::TypeID::get<mlir::OpTrait::OneOperand>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SameOperandsAndResultRank<mlir::TypeID::get<mlir::OpTrait::SameOperandsAndResultRank>()::Empty>)
Pass Manager with 6 passes:
builtin.module(ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::OpToOpPassAdaptor)
operation-legalization,inline{default-pipeline=canonicalize inlining-threshold=4294967295 max-iterations=4 },infer-symbol-shape,canonicalize{  max-iterations=10 max-num-rewrites=-1 region-simplify=normal test-convergence=false top-down=true},load-weight,canonicalize{  max-iterations=10 max-num-rewrites=-1 region-simplify=normal test-convergence=false top-down=true})

[2024-09-30 05:21:30.204] [info] ----- run in pass: Operationlegalization -----
module attributes {builtin.gloabal_layout = "NCHW"} {
  func.func @main(%arg0: tensor<?x?x224x224xf32>) -> tensor<2x3x110x2xf32> attributes {entrance} {
    %0 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer1.weight.npy"}> : () -> tensor<10x3x5x5xf32>
    %1 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer1.bias.npy"}> : () -> tensor<10xf32>
    %2 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer2.weight.npy"}> : () -> tensor<3x10x5x5xf32>
    %3 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer2.bias.npy"}> : () -> tensor<3xf32>
    %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___cf.weight.npy"}> : () -> tensor<2x110xf32>
    %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___cf.bias.npy"}> : () -> tensor<2xf32>
    %6 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
    %7 = "llh.torch_symbolic_int"() <{sym_name = "s1"}> : () -> i64
    "llh.symbolic_bind"(%arg0, %6, %7) <{expressions = affine_map<()[s0, s1] -> (s0, s1, 224, 224)>}> : (tensor<?x?x224x224xf32>, i64, i64) -> ()
    %8 = "llh.constant"() <{value = 2 : i64}> : () -> i64
    %9 = "llh.dim"(%arg0, %8) : (tensor<?x?x224x224xf32>, i64) -> i64
    %10 = "llh.constant"() <{value = 3 : i64}> : () -> i64
    %11 = "llh.dim"(%arg0, %10) : (tensor<?x?x224x224xf32>, i64) -> i64
    %12 = "llh.constant"() <{value = 1 : i64}> : () -> i64
    %13 = "llh.constant"() <{value = 6 : i64}> : () -> i64
    %14 = "llh.reshape"(%arg0, %12, %13, %9, %11) : (tensor<?x?x224x224xf32>, i64, i64, i64, i64) -> tensor<1x?x224x224xf32>
    "llh.symbolic_bind"(%14, %7, %6) <{expressions = affine_map<()[s0, s1] -> (1, s0 * s1, 224, 224)>}> : (tensor<1x?x224x224xf32>, i64, i64) -> ()
    %15 = "llh.constant"() <{value = 2 : i64}> : () -> i64
    %16 = "llh.constant"() <{value = 3 : i64}> : () -> i64
    %17 = "llh.constant"() <{value = 224 : i64}> : () -> i64
    %18 = "llh.constant"() <{value = 224 : i64}> : () -> i64
    %19 = "llh.reshape"(%14, %15, %16, %17, %18) : (tensor<1x?x224x224xf32>, i64, i64, i64, i64) -> tensor<2x?x224x224xf32>
    "llh.symbolic_bind"(%19, %7, %6) <{expressions = affine_map<()[s0, s1] -> (2, (s0 * s1) floordiv 2, 224, 224)>}> : (tensor<2x?x224x224xf32>, i64, i64) -> ()
    %20 = "llh.conv_bias"(%19, %0, %1) <{dilation = array<i64: 5, 5>, group = 1 : i64, kernel_shape = array<i64: 5, 5>, pad = array<i64: 2, 2, 2, 2>, stride = array<i64: 2, 2>}> : (tensor<2x?x224x224xf32>, tensor<10x3x5x5xf32>, tensor<10xf32>) -> tensor<2x10x104x104xf32>
    "llh.symbolic_bind"(%20) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
    %21 = "llh.add"(%20, %20) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
    "llh.symbolic_bind"(%21) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
    %22 = "llh.constant"() <{value = 5.33333302 : f32}> : () -> f32
    %23 = "llh.div"(%20, %22) : (tensor<2x10x104x104xf32>, f32) -> tensor<2x10x104x104xf32>
    "llh.symbolic_bind"(%23) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
    %24 = "llh.add"(%23, %21) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
    "llh.symbolic_bind"(%24) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
    %25 = "llh.mul"(%23, %23) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
    "llh.symbolic_bind"(%25) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
    %26 = "llh.add"(%24, %25) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
    "llh.symbolic_bind"(%26) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
    %27 = "llh.add"(%26, %21) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
    "llh.symbolic_bind"(%27) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
    %28 = "llh.conv_bias"(%27, %2, %3) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 5, 5>, pad = array<i64: 5, 5, 5, 5>, stride = array<i64: 1, 1>}> : (tensor<2x10x104x104xf32>, tensor<3x10x5x5xf32>, tensor<3xf32>) -> tensor<2x3x110x110xf32>
    "llh.symbolic_bind"(%28) <{expressions = affine_map<()[s0, s1] -> (2, 3, 110, 110)>}> : (tensor<2x3x110x110xf32>) -> ()
    %29 = "llh.mul"(%28, %28) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
    "llh.symbolic_bind"(%29) <{expressions = affine_map<()[s0, s1] -> (2, 3, 110, 110)>}> : (tensor<2x3x110x110xf32>) -> ()
    %30 = "llh.add"(%28, %29) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
    "llh.symbolic_bind"(%30) <{expressions = affine_map<()[s0, s1] -> (2, 3, 110, 110)>}> : (tensor<2x3x110x110xf32>) -> ()
    %31 = "llh.constant"() <{value = 2 : i64}> : () -> i64
    %32 = "llh.div"(%28, %31) : (tensor<2x3x110x110xf32>, i64) -> tensor<2x3x110x110xf32>
    "llh.symbolic_bind"(%32) <{expressions = affine_map<()[s0, s1] -> (2, 3, 110, 110)>}> : (tensor<2x3x110x110xf32>) -> ()
    %33 = "llh.add"(%30, %32) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
    "llh.symbolic_bind"(%33) <{expressions = affine_map<()[s0, s1] -> (2, 3, 110, 110)>}> : (tensor<2x3x110x110xf32>) -> ()
    %34 = "llh.transpose"(%4) <{perms = array<i64: 1, 0>}> : (tensor<2x110xf32>) -> tensor<110x2xf32>
    %35 = "llh.matmul"(%33, %34) : (tensor<2x3x110x110xf32>, tensor<110x2xf32>) -> tensor<2x3x110x2xf32>
    %36 = "llh.add"(%35, %5) : (tensor<2x3x110x2xf32>, tensor<2xf32>) -> tensor<2x3x110x2xf32>
    "llh.symbolic_bind"(%36) <{expressions = affine_map<()[s0, s1] -> (2, 3, 110, 2)>}> : (tensor<2x3x110x2xf32>) -> ()
    return %36 : tensor<2x3x110x2xf32>
  }
}
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DialectFoldInterface)
** Replace : 'llh.constant'(0x561dcc20a0a0)
** Modified: 'llh.reshape'(0x561dcc1d5480)
** Erase   : 'llh.constant'(0x561dcc20a0a0)
** Replace : 'llh.constant'(0x561dcc20a160)
** Modified: 'llh.reshape'(0x561dcc1d5480)
** Erase   : 'llh.constant'(0x561dcc20a160)
** Replace : 'llh.constant'(0x561dcc20a2e0)
** Modified: 'llh.reshape'(0x561dcc1d5480)
** Erase   : 'llh.constant'(0x561dcc20a2e0)
** Replace : 'llh.constant'(0x561dcc20e130)
** Modified: 'llh.div'(0x561dcc20e1f0)
** Erase   : 'llh.constant'(0x561dcc20e130)

//===-------------------------------------------===//
Processing operation : 'func.return'(0x561dcc20f890) {
  "func.return"(%32) : (tensor<2x3x110x2xf32>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x561dcc20e780) {
  "llh.symbolic_bind"(%32) <{expressions = affine_map<()[s0, s1] -> (2, 3, 110, 2)>}> : (tensor<2x3x110x2xf32>) -> ()

ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::HasRecursiveMemoryEffects<mlir::TypeID::get<mlir::OpTrait::HasRecursiveMemoryEffects>()::Empty>)

  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
    ** Erase   : 'llh.symbolic_bind'(0x561dcc20e780)
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x?x224x224xf32>) -> tensor<2x3x110x2xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 5.33333302 : f32}> : () -> f32
  %1 = "llh.constant"() <{value = 224 : i64}> : () -> i64
  %2 = "llh.constant"() <{value = 6 : i64}> : () -> i64
  %3 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %4 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %5 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer1.weight.npy"}> : () -> tensor<10x3x5x5xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer1.bias.npy"}> : () -> tensor<10xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer2.weight.npy"}> : () -> tensor<3x10x5x5xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer2.bias.npy"}> : () -> tensor<3xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___cf.weight.npy"}> : () -> tensor<2x110xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___cf.bias.npy"}> : () -> tensor<2xf32>
  %12 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %13 = "llh.torch_symbolic_int"() <{sym_name = "s1"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %12, %13) <{expressions = affine_map<()[s0, s1] -> (s0, s1, 224, 224)>}> : (tensor<?x?x224x224xf32>, i64, i64) -> ()
  %14 = "llh.dim"(%arg0, %5) : (tensor<?x?x224x224xf32>, i64) -> i64
  %15 = "llh.dim"(%arg0, %4) : (tensor<?x?x224x224xf32>, i64) -> i64
  %16 = "llh.reshape"(%arg0, %3, %2, %14, %15) : (tensor<?x?x224x224xf32>, i64, i64, i64, i64) -> tensor<1x?x224x224xf32>
  "llh.symbolic_bind"(%16, %13, %12) <{expressions = affine_map<()[s0, s1] -> (1, s0 * s1, 224, 224)>}> : (tensor<1x?x224x224xf32>, i64, i64) -> ()
  %17 = "llh.reshape"(%16, %5, %4, %1, %1) : (tensor<1x?x224x224xf32>, i64, i64, i64, i64) -> tensor<2x?x224x224xf32>
  "llh.symbolic_bind"(%17, %13, %12) <{expressions = affine_map<()[s0, s1] -> (2, (s0 * s1) floordiv 2, 224, 224)>}> : (tensor<2x?x224x224xf32>, i64, i64) -> ()
  %18 = "llh.conv_bias"(%17, %6, %7) <{dilation = array<i64: 5, 5>, group = 1 : i64, kernel_shape = array<i64: 5, 5>, layout = #llh.Layout<NCHW>, pad = array<i64: 2, 2, 2, 2>, stride = array<i64: 2, 2>}> : (tensor<2x?x224x224xf32>, tensor<10x3x5x5xf32>, tensor<10xf32>) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%18) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %19 = "llh.add"(%18, %18) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%19) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %20 = "llh.div"(%18, %0) : (tensor<2x10x104x104xf32>, f32) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%20) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %21 = "llh.add"(%20, %19) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%21) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %22 = "llh.mul"(%20, %20) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%22) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %23 = "llh.add"(%21, %22) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%23) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %24 = "llh.add"(%23, %19) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%24) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %25 = "llh.conv_bias"(%24, %8, %9) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 5, 5>, layout = #llh.Layout<NCHW>, pad = array<i64: 5, 5, 5, 5>, stride = array<i64: 1, 1>}> : (tensor<2x10x104x104xf32>, tensor<3x10x5x5xf32>, tensor<3xf32>) -> tensor<2x3x110x110xf32>
  "llh.symbolic_bind"(%25) <{expressions = affine_map<()[s0, s1] -> (2, 3, 110, 110)>}> : (tensor<2x3x110x110xf32>) -> ()
  %26 = "llh.mul"(%25, %25) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  "llh.symbolic_bind"(%26) <{expressions = affine_map<()[s0, s1] -> (2, 3, 110, 110)>}> : (tensor<2x3x110x110xf32>) -> ()
  %27 = "llh.add"(%25, %26) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  "llh.symbolic_bind"(%27) <{expressions = affine_map<()[s0, s1] -> (2, 3, 110, 110)>}> : (tensor<2x3x110x110xf32>) -> ()
  %28 = "llh.div"(%25, %5) : (tensor<2x3x110x110xf32>, i64) -> tensor<2x3x110x110xf32>
  "llh.symbolic_bind"(%28) <{expressions = affine_map<()[s0, s1] -> (2, 3, 110, 110)>}> : (tensor<2x3x110x110xf32>) -> ()
  %29 = "llh.add"(%27, %28) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  "llh.symbolic_bind"(%29) <{expressions = affine_map<()[s0, s1] -> (2, 3, 110, 110)>}> : (tensor<2x3x110x110xf32>) -> ()
  %30 = "llh.transpose"(%10) <{perms = array<i64: 1, 0>}> : (tensor<2x110xf32>) -> tensor<110x2xf32>
  %31 = "llh.matmul"(%29, %30) : (tensor<2x3x110x110xf32>, tensor<110x2xf32>) -> tensor<2x3x110x2xf32>
  %32 = "llh.add"(%31, %11) : (tensor<2x3x110x2xf32>, tensor<2xf32>) -> tensor<2x3x110x2xf32>
  return %32 : tensor<2x3x110x2xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x561dcc20e680) {
  %32 = "llh.add"(%31, %11) : (tensor<2x3x110x2xf32>, tensor<2xf32>) -> tensor<2x3x110x2xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.matmul'(0x561dcc20e590) {
  %31 = "llh.matmul"(%29, %30) : (tensor<2x3x110x110xf32>, tensor<110x2xf32>) -> tensor<2x3x110x2xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.transpose'(0x561dcc201c90) {
  %30 = "llh.transpose"(%10) <{perms = array<i64: 1, 0>}> : (tensor<2x110xf32>) -> tensor<110x2xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x561dcc20e480) {
  "llh.symbolic_bind"(%29) <{expressions = affine_map<()[s0, s1] -> (2, 3, 110, 110)>}> : (tensor<2x3x110x110xf32>) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
    ** Erase   : 'llh.symbolic_bind'(0x561dcc20e480)
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x?x224x224xf32>) -> tensor<2x3x110x2xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 5.33333302 : f32}> : () -> f32
  %1 = "llh.constant"() <{value = 224 : i64}> : () -> i64
  %2 = "llh.constant"() <{value = 6 : i64}> : () -> i64
  %3 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %4 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %5 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer1.weight.npy"}> : () -> tensor<10x3x5x5xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer1.bias.npy"}> : () -> tensor<10xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer2.weight.npy"}> : () -> tensor<3x10x5x5xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer2.bias.npy"}> : () -> tensor<3xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___cf.weight.npy"}> : () -> tensor<2x110xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___cf.bias.npy"}> : () -> tensor<2xf32>
  %12 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %13 = "llh.torch_symbolic_int"() <{sym_name = "s1"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %12, %13) <{expressions = affine_map<()[s0, s1] -> (s0, s1, 224, 224)>}> : (tensor<?x?x224x224xf32>, i64, i64) -> ()
  %14 = "llh.dim"(%arg0, %5) : (tensor<?x?x224x224xf32>, i64) -> i64
  %15 = "llh.dim"(%arg0, %4) : (tensor<?x?x224x224xf32>, i64) -> i64
  %16 = "llh.reshape"(%arg0, %3, %2, %14, %15) : (tensor<?x?x224x224xf32>, i64, i64, i64, i64) -> tensor<1x?x224x224xf32>
  "llh.symbolic_bind"(%16, %13, %12) <{expressions = affine_map<()[s0, s1] -> (1, s0 * s1, 224, 224)>}> : (tensor<1x?x224x224xf32>, i64, i64) -> ()
  %17 = "llh.reshape"(%16, %5, %4, %1, %1) : (tensor<1x?x224x224xf32>, i64, i64, i64, i64) -> tensor<2x?x224x224xf32>
  "llh.symbolic_bind"(%17, %13, %12) <{expressions = affine_map<()[s0, s1] -> (2, (s0 * s1) floordiv 2, 224, 224)>}> : (tensor<2x?x224x224xf32>, i64, i64) -> ()
  %18 = "llh.conv_bias"(%17, %6, %7) <{dilation = array<i64: 5, 5>, group = 1 : i64, kernel_shape = array<i64: 5, 5>, layout = #llh.Layout<NCHW>, pad = array<i64: 2, 2, 2, 2>, stride = array<i64: 2, 2>}> : (tensor<2x?x224x224xf32>, tensor<10x3x5x5xf32>, tensor<10xf32>) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%18) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %19 = "llh.add"(%18, %18) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%19) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %20 = "llh.div"(%18, %0) : (tensor<2x10x104x104xf32>, f32) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%20) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %21 = "llh.add"(%20, %19) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%21) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %22 = "llh.mul"(%20, %20) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%22) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %23 = "llh.add"(%21, %22) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%23) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %24 = "llh.add"(%23, %19) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%24) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %25 = "llh.conv_bias"(%24, %8, %9) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 5, 5>, layout = #llh.Layout<NCHW>, pad = array<i64: 5, 5, 5, 5>, stride = array<i64: 1, 1>}> : (tensor<2x10x104x104xf32>, tensor<3x10x5x5xf32>, tensor<3xf32>) -> tensor<2x3x110x110xf32>
  "llh.symbolic_bind"(%25) <{expressions = affine_map<()[s0, s1] -> (2, 3, 110, 110)>}> : (tensor<2x3x110x110xf32>) -> ()
  %26 = "llh.mul"(%25, %25) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  "llh.symbolic_bind"(%26) <{expressions = affine_map<()[s0, s1] -> (2, 3, 110, 110)>}> : (tensor<2x3x110x110xf32>) -> ()
  %27 = "llh.add"(%25, %26) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  "llh.symbolic_bind"(%27) <{expressions = affine_map<()[s0, s1] -> (2, 3, 110, 110)>}> : (tensor<2x3x110x110xf32>) -> ()
  %28 = "llh.div"(%25, %5) : (tensor<2x3x110x110xf32>, i64) -> tensor<2x3x110x110xf32>
  "llh.symbolic_bind"(%28) <{expressions = affine_map<()[s0, s1] -> (2, 3, 110, 110)>}> : (tensor<2x3x110x110xf32>) -> ()
  %29 = "llh.add"(%27, %28) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  %30 = "llh.transpose"(%10) <{perms = array<i64: 1, 0>}> : (tensor<2x110xf32>) -> tensor<110x2xf32>
  %31 = "llh.matmul"(%29, %30) : (tensor<2x3x110x110xf32>, tensor<110x2xf32>) -> tensor<2x3x110x2xf32>
  %32 = "llh.add"(%31, %11) : (tensor<2x3x110x2xf32>, tensor<2xf32>) -> tensor<2x3x110x2xf32>
  return %32 : tensor<2x3x110x2xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x561dcc20e380) {
  %29 = "llh.add"(%27, %28) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x561dcc20e2f0) {
  "llh.symbolic_bind"(%28) <{expressions = affine_map<()[s0, s1] -> (2, 3, 110, 110)>}> : (tensor<2x3x110x110xf32>) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
    ** Erase   : 'llh.symbolic_bind'(0x561dcc20e2f0)
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x?x224x224xf32>) -> tensor<2x3x110x2xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 5.33333302 : f32}> : () -> f32
  %1 = "llh.constant"() <{value = 224 : i64}> : () -> i64
  %2 = "llh.constant"() <{value = 6 : i64}> : () -> i64
  %3 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %4 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %5 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer1.weight.npy"}> : () -> tensor<10x3x5x5xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer1.bias.npy"}> : () -> tensor<10xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer2.weight.npy"}> : () -> tensor<3x10x5x5xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer2.bias.npy"}> : () -> tensor<3xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___cf.weight.npy"}> : () -> tensor<2x110xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___cf.bias.npy"}> : () -> tensor<2xf32>
  %12 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %13 = "llh.torch_symbolic_int"() <{sym_name = "s1"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %12, %13) <{expressions = affine_map<()[s0, s1] -> (s0, s1, 224, 224)>}> : (tensor<?x?x224x224xf32>, i64, i64) -> ()
  %14 = "llh.dim"(%arg0, %5) : (tensor<?x?x224x224xf32>, i64) -> i64
  %15 = "llh.dim"(%arg0, %4) : (tensor<?x?x224x224xf32>, i64) -> i64
  %16 = "llh.reshape"(%arg0, %3, %2, %14, %15) : (tensor<?x?x224x224xf32>, i64, i64, i64, i64) -> tensor<1x?x224x224xf32>
  "llh.symbolic_bind"(%16, %13, %12) <{expressions = affine_map<()[s0, s1] -> (1, s0 * s1, 224, 224)>}> : (tensor<1x?x224x224xf32>, i64, i64) -> ()
  %17 = "llh.reshape"(%16, %5, %4, %1, %1) : (tensor<1x?x224x224xf32>, i64, i64, i64, i64) -> tensor<2x?x224x224xf32>
  "llh.symbolic_bind"(%17, %13, %12) <{expressions = affine_map<()[s0, s1] -> (2, (s0 * s1) floordiv 2, 224, 224)>}> : (tensor<2x?x224x224xf32>, i64, i64) -> ()
  %18 = "llh.conv_bias"(%17, %6, %7) <{dilation = array<i64: 5, 5>, group = 1 : i64, kernel_shape = array<i64: 5, 5>, layout = #llh.Layout<NCHW>, pad = array<i64: 2, 2, 2, 2>, stride = array<i64: 2, 2>}> : (tensor<2x?x224x224xf32>, tensor<10x3x5x5xf32>, tensor<10xf32>) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%18) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %19 = "llh.add"(%18, %18) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%19) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %20 = "llh.div"(%18, %0) : (tensor<2x10x104x104xf32>, f32) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%20) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %21 = "llh.add"(%20, %19) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%21) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %22 = "llh.mul"(%20, %20) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%22) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %23 = "llh.add"(%21, %22) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%23) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %24 = "llh.add"(%23, %19) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%24) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %25 = "llh.conv_bias"(%24, %8, %9) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 5, 5>, layout = #llh.Layout<NCHW>, pad = array<i64: 5, 5, 5, 5>, stride = array<i64: 1, 1>}> : (tensor<2x10x104x104xf32>, tensor<3x10x5x5xf32>, tensor<3xf32>) -> tensor<2x3x110x110xf32>
  "llh.symbolic_bind"(%25) <{expressions = affine_map<()[s0, s1] -> (2, 3, 110, 110)>}> : (tensor<2x3x110x110xf32>) -> ()
  %26 = "llh.mul"(%25, %25) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  "llh.symbolic_bind"(%26) <{expressions = affine_map<()[s0, s1] -> (2, 3, 110, 110)>}> : (tensor<2x3x110x110xf32>) -> ()
  %27 = "llh.add"(%25, %26) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  "llh.symbolic_bind"(%27) <{expressions = affine_map<()[s0, s1] -> (2, 3, 110, 110)>}> : (tensor<2x3x110x110xf32>) -> ()
  %28 = "llh.div"(%25, %5) : (tensor<2x3x110x110xf32>, i64) -> tensor<2x3x110x110xf32>
  %29 = "llh.add"(%27, %28) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  %30 = "llh.transpose"(%10) <{perms = array<i64: 1, 0>}> : (tensor<2x110xf32>) -> tensor<110x2xf32>
  %31 = "llh.matmul"(%29, %30) : (tensor<2x3x110x110xf32>, tensor<110x2xf32>) -> tensor<2x3x110x2xf32>
  %32 = "llh.add"(%31, %11) : (tensor<2x3x110x2xf32>, tensor<2xf32>) -> tensor<2x3x110x2xf32>
  return %32 : tensor<2x3x110x2xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.div'(0x561dcc20e1f0) {
  %28 = "llh.div"(%25, %5) : (tensor<2x3x110x110xf32>, i64) -> tensor<2x3x110x110xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x561dcc20e0a0) {
  "llh.symbolic_bind"(%27) <{expressions = affine_map<()[s0, s1] -> (2, 3, 110, 110)>}> : (tensor<2x3x110x110xf32>) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
    ** Erase   : 'llh.symbolic_bind'(0x561dcc20e0a0)
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x?x224x224xf32>) -> tensor<2x3x110x2xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 5.33333302 : f32}> : () -> f32
  %1 = "llh.constant"() <{value = 224 : i64}> : () -> i64
  %2 = "llh.constant"() <{value = 6 : i64}> : () -> i64
  %3 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %4 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %5 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer1.weight.npy"}> : () -> tensor<10x3x5x5xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer1.bias.npy"}> : () -> tensor<10xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer2.weight.npy"}> : () -> tensor<3x10x5x5xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer2.bias.npy"}> : () -> tensor<3xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___cf.weight.npy"}> : () -> tensor<2x110xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___cf.bias.npy"}> : () -> tensor<2xf32>
  %12 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %13 = "llh.torch_symbolic_int"() <{sym_name = "s1"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %12, %13) <{expressions = affine_map<()[s0, s1] -> (s0, s1, 224, 224)>}> : (tensor<?x?x224x224xf32>, i64, i64) -> ()
  %14 = "llh.dim"(%arg0, %5) : (tensor<?x?x224x224xf32>, i64) -> i64
  %15 = "llh.dim"(%arg0, %4) : (tensor<?x?x224x224xf32>, i64) -> i64
  %16 = "llh.reshape"(%arg0, %3, %2, %14, %15) : (tensor<?x?x224x224xf32>, i64, i64, i64, i64) -> tensor<1x?x224x224xf32>
  "llh.symbolic_bind"(%16, %13, %12) <{expressions = affine_map<()[s0, s1] -> (1, s0 * s1, 224, 224)>}> : (tensor<1x?x224x224xf32>, i64, i64) -> ()
  %17 = "llh.reshape"(%16, %5, %4, %1, %1) : (tensor<1x?x224x224xf32>, i64, i64, i64, i64) -> tensor<2x?x224x224xf32>
  "llh.symbolic_bind"(%17, %13, %12) <{expressions = affine_map<()[s0, s1] -> (2, (s0 * s1) floordiv 2, 224, 224)>}> : (tensor<2x?x224x224xf32>, i64, i64) -> ()
  %18 = "llh.conv_bias"(%17, %6, %7) <{dilation = array<i64: 5, 5>, group = 1 : i64, kernel_shape = array<i64: 5, 5>, layout = #llh.Layout<NCHW>, pad = array<i64: 2, 2, 2, 2>, stride = array<i64: 2, 2>}> : (tensor<2x?x224x224xf32>, tensor<10x3x5x5xf32>, tensor<10xf32>) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%18) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %19 = "llh.add"(%18, %18) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%19) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %20 = "llh.div"(%18, %0) : (tensor<2x10x104x104xf32>, f32) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%20) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %21 = "llh.add"(%20, %19) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%21) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %22 = "llh.mul"(%20, %20) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%22) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %23 = "llh.add"(%21, %22) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%23) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %24 = "llh.add"(%23, %19) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%24) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %25 = "llh.conv_bias"(%24, %8, %9) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 5, 5>, layout = #llh.Layout<NCHW>, pad = array<i64: 5, 5, 5, 5>, stride = array<i64: 1, 1>}> : (tensor<2x10x104x104xf32>, tensor<3x10x5x5xf32>, tensor<3xf32>) -> tensor<2x3x110x110xf32>
  "llh.symbolic_bind"(%25) <{expressions = affine_map<()[s0, s1] -> (2, 3, 110, 110)>}> : (tensor<2x3x110x110xf32>) -> ()
  %26 = "llh.mul"(%25, %25) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  "llh.symbolic_bind"(%26) <{expressions = affine_map<()[s0, s1] -> (2, 3, 110, 110)>}> : (tensor<2x3x110x110xf32>) -> ()
  %27 = "llh.add"(%25, %26) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  %28 = "llh.div"(%25, %5) : (tensor<2x3x110x110xf32>, i64) -> tensor<2x3x110x110xf32>
  %29 = "llh.add"(%27, %28) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  %30 = "llh.transpose"(%10) <{perms = array<i64: 1, 0>}> : (tensor<2x110xf32>) -> tensor<110x2xf32>
  %31 = "llh.matmul"(%29, %30) : (tensor<2x3x110x110xf32>, tensor<110x2xf32>) -> tensor<2x3x110x2xf32>
  %32 = "llh.add"(%31, %11) : (tensor<2x3x110x2xf32>, tensor<2xf32>) -> tensor<2x3x110x2xf32>
  return %32 : tensor<2x3x110x2xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x561dcc20dfa0) {
  %27 = "llh.add"(%25, %26) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x561dcc20df10) {
  "llh.symbolic_bind"(%26) <{expressions = affine_map<()[s0, s1] -> (2, 3, 110, 110)>}> : (tensor<2x3x110x110xf32>) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
    ** Erase   : 'llh.symbolic_bind'(0x561dcc20df10)
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x?x224x224xf32>) -> tensor<2x3x110x2xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 5.33333302 : f32}> : () -> f32
  %1 = "llh.constant"() <{value = 224 : i64}> : () -> i64
  %2 = "llh.constant"() <{value = 6 : i64}> : () -> i64
  %3 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %4 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %5 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer1.weight.npy"}> : () -> tensor<10x3x5x5xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer1.bias.npy"}> : () -> tensor<10xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer2.weight.npy"}> : () -> tensor<3x10x5x5xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer2.bias.npy"}> : () -> tensor<3xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___cf.weight.npy"}> : () -> tensor<2x110xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___cf.bias.npy"}> : () -> tensor<2xf32>
  %12 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %13 = "llh.torch_symbolic_int"() <{sym_name = "s1"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %12, %13) <{expressions = affine_map<()[s0, s1] -> (s0, s1, 224, 224)>}> : (tensor<?x?x224x224xf32>, i64, i64) -> ()
  %14 = "llh.dim"(%arg0, %5) : (tensor<?x?x224x224xf32>, i64) -> i64
  %15 = "llh.dim"(%arg0, %4) : (tensor<?x?x224x224xf32>, i64) -> i64
  %16 = "llh.reshape"(%arg0, %3, %2, %14, %15) : (tensor<?x?x224x224xf32>, i64, i64, i64, i64) -> tensor<1x?x224x224xf32>
  "llh.symbolic_bind"(%16, %13, %12) <{expressions = affine_map<()[s0, s1] -> (1, s0 * s1, 224, 224)>}> : (tensor<1x?x224x224xf32>, i64, i64) -> ()
  %17 = "llh.reshape"(%16, %5, %4, %1, %1) : (tensor<1x?x224x224xf32>, i64, i64, i64, i64) -> tensor<2x?x224x224xf32>
  "llh.symbolic_bind"(%17, %13, %12) <{expressions = affine_map<()[s0, s1] -> (2, (s0 * s1) floordiv 2, 224, 224)>}> : (tensor<2x?x224x224xf32>, i64, i64) -> ()
  %18 = "llh.conv_bias"(%17, %6, %7) <{dilation = array<i64: 5, 5>, group = 1 : i64, kernel_shape = array<i64: 5, 5>, layout = #llh.Layout<NCHW>, pad = array<i64: 2, 2, 2, 2>, stride = array<i64: 2, 2>}> : (tensor<2x?x224x224xf32>, tensor<10x3x5x5xf32>, tensor<10xf32>) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%18) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %19 = "llh.add"(%18, %18) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%19) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %20 = "llh.div"(%18, %0) : (tensor<2x10x104x104xf32>, f32) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%20) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %21 = "llh.add"(%20, %19) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%21) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %22 = "llh.mul"(%20, %20) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%22) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %23 = "llh.add"(%21, %22) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%23) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %24 = "llh.add"(%23, %19) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%24) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %25 = "llh.conv_bias"(%24, %8, %9) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 5, 5>, layout = #llh.Layout<NCHW>, pad = array<i64: 5, 5, 5, 5>, stride = array<i64: 1, 1>}> : (tensor<2x10x104x104xf32>, tensor<3x10x5x5xf32>, tensor<3xf32>) -> tensor<2x3x110x110xf32>
  "llh.symbolic_bind"(%25) <{expressions = affine_map<()[s0, s1] -> (2, 3, 110, 110)>}> : (tensor<2x3x110x110xf32>) -> ()
  %26 = "llh.mul"(%25, %25) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  %27 = "llh.add"(%25, %26) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  %28 = "llh.div"(%25, %5) : (tensor<2x3x110x110xf32>, i64) -> tensor<2x3x110x110xf32>
  %29 = "llh.add"(%27, %28) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  %30 = "llh.transpose"(%10) <{perms = array<i64: 1, 0>}> : (tensor<2x110xf32>) -> tensor<110x2xf32>
  %31 = "llh.matmul"(%29, %30) : (tensor<2x3x110x110xf32>, tensor<110x2xf32>) -> tensor<2x3x110x2xf32>
  %32 = "llh.add"(%31, %11) : (tensor<2x3x110x2xf32>, tensor<2xf32>) -> tensor<2x3x110x2xf32>
  return %32 : tensor<2x3x110x2xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.mul'(0x561dcc20de30) {
  %26 = "llh.mul"(%25, %25) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x561dcc20dda0) {
  "llh.symbolic_bind"(%25) <{expressions = affine_map<()[s0, s1] -> (2, 3, 110, 110)>}> : (tensor<2x3x110x110xf32>) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
    ** Erase   : 'llh.symbolic_bind'(0x561dcc20dda0)
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x?x224x224xf32>) -> tensor<2x3x110x2xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 5.33333302 : f32}> : () -> f32
  %1 = "llh.constant"() <{value = 224 : i64}> : () -> i64
  %2 = "llh.constant"() <{value = 6 : i64}> : () -> i64
  %3 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %4 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %5 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer1.weight.npy"}> : () -> tensor<10x3x5x5xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer1.bias.npy"}> : () -> tensor<10xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer2.weight.npy"}> : () -> tensor<3x10x5x5xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer2.bias.npy"}> : () -> tensor<3xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___cf.weight.npy"}> : () -> tensor<2x110xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___cf.bias.npy"}> : () -> tensor<2xf32>
  %12 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %13 = "llh.torch_symbolic_int"() <{sym_name = "s1"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %12, %13) <{expressions = affine_map<()[s0, s1] -> (s0, s1, 224, 224)>}> : (tensor<?x?x224x224xf32>, i64, i64) -> ()
  %14 = "llh.dim"(%arg0, %5) : (tensor<?x?x224x224xf32>, i64) -> i64
  %15 = "llh.dim"(%arg0, %4) : (tensor<?x?x224x224xf32>, i64) -> i64
  %16 = "llh.reshape"(%arg0, %3, %2, %14, %15) : (tensor<?x?x224x224xf32>, i64, i64, i64, i64) -> tensor<1x?x224x224xf32>
  "llh.symbolic_bind"(%16, %13, %12) <{expressions = affine_map<()[s0, s1] -> (1, s0 * s1, 224, 224)>}> : (tensor<1x?x224x224xf32>, i64, i64) -> ()
  %17 = "llh.reshape"(%16, %5, %4, %1, %1) : (tensor<1x?x224x224xf32>, i64, i64, i64, i64) -> tensor<2x?x224x224xf32>
  "llh.symbolic_bind"(%17, %13, %12) <{expressions = affine_map<()[s0, s1] -> (2, (s0 * s1) floordiv 2, 224, 224)>}> : (tensor<2x?x224x224xf32>, i64, i64) -> ()
  %18 = "llh.conv_bias"(%17, %6, %7) <{dilation = array<i64: 5, 5>, group = 1 : i64, kernel_shape = array<i64: 5, 5>, layout = #llh.Layout<NCHW>, pad = array<i64: 2, 2, 2, 2>, stride = array<i64: 2, 2>}> : (tensor<2x?x224x224xf32>, tensor<10x3x5x5xf32>, tensor<10xf32>) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%18) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %19 = "llh.add"(%18, %18) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%19) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %20 = "llh.div"(%18, %0) : (tensor<2x10x104x104xf32>, f32) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%20) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %21 = "llh.add"(%20, %19) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%21) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %22 = "llh.mul"(%20, %20) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%22) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %23 = "llh.add"(%21, %22) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%23) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %24 = "llh.add"(%23, %19) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%24) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %25 = "llh.conv_bias"(%24, %8, %9) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 5, 5>, layout = #llh.Layout<NCHW>, pad = array<i64: 5, 5, 5, 5>, stride = array<i64: 1, 1>}> : (tensor<2x10x104x104xf32>, tensor<3x10x5x5xf32>, tensor<3xf32>) -> tensor<2x3x110x110xf32>
  %26 = "llh.mul"(%25, %25) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  %27 = "llh.add"(%25, %26) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  %28 = "llh.div"(%25, %5) : (tensor<2x3x110x110xf32>, i64) -> tensor<2x3x110x110xf32>
  %29 = "llh.add"(%27, %28) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  %30 = "llh.transpose"(%10) <{perms = array<i64: 1, 0>}> : (tensor<2x110xf32>) -> tensor<110x2xf32>
  %31 = "llh.matmul"(%29, %30) : (tensor<2x3x110x110xf32>, tensor<110x2xf32>) -> tensor<2x3x110x2xf32>
  %32 = "llh.add"(%31, %11) : (tensor<2x3x110x2xf32>, tensor<2xf32>) -> tensor<2x3x110x2xf32>
  return %32 : tensor<2x3x110x2xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv_bias'(0x561dcc20d7f0) {
  %25 = "llh.conv_bias"(%24, %8, %9) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 5, 5>, layout = #llh.Layout<NCHW>, pad = array<i64: 5, 5, 5, 5>, stride = array<i64: 1, 1>}> : (tensor<2x10x104x104xf32>, tensor<3x10x5x5xf32>, tensor<3xf32>) -> tensor<2x3x110x110xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x561dcc20ce20) {
  "llh.symbolic_bind"(%24) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
    ** Erase   : 'llh.symbolic_bind'(0x561dcc20ce20)
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x?x224x224xf32>) -> tensor<2x3x110x2xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 5.33333302 : f32}> : () -> f32
  %1 = "llh.constant"() <{value = 224 : i64}> : () -> i64
  %2 = "llh.constant"() <{value = 6 : i64}> : () -> i64
  %3 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %4 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %5 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer1.weight.npy"}> : () -> tensor<10x3x5x5xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer1.bias.npy"}> : () -> tensor<10xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer2.weight.npy"}> : () -> tensor<3x10x5x5xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer2.bias.npy"}> : () -> tensor<3xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___cf.weight.npy"}> : () -> tensor<2x110xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___cf.bias.npy"}> : () -> tensor<2xf32>
  %12 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %13 = "llh.torch_symbolic_int"() <{sym_name = "s1"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %12, %13) <{expressions = affine_map<()[s0, s1] -> (s0, s1, 224, 224)>}> : (tensor<?x?x224x224xf32>, i64, i64) -> ()
  %14 = "llh.dim"(%arg0, %5) : (tensor<?x?x224x224xf32>, i64) -> i64
  %15 = "llh.dim"(%arg0, %4) : (tensor<?x?x224x224xf32>, i64) -> i64
  %16 = "llh.reshape"(%arg0, %3, %2, %14, %15) : (tensor<?x?x224x224xf32>, i64, i64, i64, i64) -> tensor<1x?x224x224xf32>
  "llh.symbolic_bind"(%16, %13, %12) <{expressions = affine_map<()[s0, s1] -> (1, s0 * s1, 224, 224)>}> : (tensor<1x?x224x224xf32>, i64, i64) -> ()
  %17 = "llh.reshape"(%16, %5, %4, %1, %1) : (tensor<1x?x224x224xf32>, i64, i64, i64, i64) -> tensor<2x?x224x224xf32>
  "llh.symbolic_bind"(%17, %13, %12) <{expressions = affine_map<()[s0, s1] -> (2, (s0 * s1) floordiv 2, 224, 224)>}> : (tensor<2x?x224x224xf32>, i64, i64) -> ()
  %18 = "llh.conv_bias"(%17, %6, %7) <{dilation = array<i64: 5, 5>, group = 1 : i64, kernel_shape = array<i64: 5, 5>, layout = #llh.Layout<NCHW>, pad = array<i64: 2, 2, 2, 2>, stride = array<i64: 2, 2>}> : (tensor<2x?x224x224xf32>, tensor<10x3x5x5xf32>, tensor<10xf32>) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%18) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %19 = "llh.add"(%18, %18) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%19) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %20 = "llh.div"(%18, %0) : (tensor<2x10x104x104xf32>, f32) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%20) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %21 = "llh.add"(%20, %19) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%21) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %22 = "llh.mul"(%20, %20) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%22) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %23 = "llh.add"(%21, %22) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%23) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %24 = "llh.add"(%23, %19) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  %25 = "llh.conv_bias"(%24, %8, %9) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 5, 5>, layout = #llh.Layout<NCHW>, pad = array<i64: 5, 5, 5, 5>, stride = array<i64: 1, 1>}> : (tensor<2x10x104x104xf32>, tensor<3x10x5x5xf32>, tensor<3xf32>) -> tensor<2x3x110x110xf32>
  %26 = "llh.mul"(%25, %25) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  %27 = "llh.add"(%25, %26) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  %28 = "llh.div"(%25, %5) : (tensor<2x3x110x110xf32>, i64) -> tensor<2x3x110x110xf32>
  %29 = "llh.add"(%27, %28) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  %30 = "llh.transpose"(%10) <{perms = array<i64: 1, 0>}> : (tensor<2x110xf32>) -> tensor<110x2xf32>
  %31 = "llh.matmul"(%29, %30) : (tensor<2x3x110x110xf32>, tensor<110x2xf32>) -> tensor<2x3x110x2xf32>
  %32 = "llh.add"(%31, %11) : (tensor<2x3x110x2xf32>, tensor<2xf32>) -> tensor<2x3x110x2xf32>
  return %32 : tensor<2x3x110x2xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x561dcc20cd20) {
  %24 = "llh.add"(%23, %19) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x561dcc20cc90) {
  "llh.symbolic_bind"(%23) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
    ** Erase   : 'llh.symbolic_bind'(0x561dcc20cc90)
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x?x224x224xf32>) -> tensor<2x3x110x2xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 5.33333302 : f32}> : () -> f32
  %1 = "llh.constant"() <{value = 224 : i64}> : () -> i64
  %2 = "llh.constant"() <{value = 6 : i64}> : () -> i64
  %3 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %4 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %5 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer1.weight.npy"}> : () -> tensor<10x3x5x5xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer1.bias.npy"}> : () -> tensor<10xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer2.weight.npy"}> : () -> tensor<3x10x5x5xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer2.bias.npy"}> : () -> tensor<3xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___cf.weight.npy"}> : () -> tensor<2x110xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___cf.bias.npy"}> : () -> tensor<2xf32>
  %12 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %13 = "llh.torch_symbolic_int"() <{sym_name = "s1"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %12, %13) <{expressions = affine_map<()[s0, s1] -> (s0, s1, 224, 224)>}> : (tensor<?x?x224x224xf32>, i64, i64) -> ()
  %14 = "llh.dim"(%arg0, %5) : (tensor<?x?x224x224xf32>, i64) -> i64
  %15 = "llh.dim"(%arg0, %4) : (tensor<?x?x224x224xf32>, i64) -> i64
  %16 = "llh.reshape"(%arg0, %3, %2, %14, %15) : (tensor<?x?x224x224xf32>, i64, i64, i64, i64) -> tensor<1x?x224x224xf32>
  "llh.symbolic_bind"(%16, %13, %12) <{expressions = affine_map<()[s0, s1] -> (1, s0 * s1, 224, 224)>}> : (tensor<1x?x224x224xf32>, i64, i64) -> ()
  %17 = "llh.reshape"(%16, %5, %4, %1, %1) : (tensor<1x?x224x224xf32>, i64, i64, i64, i64) -> tensor<2x?x224x224xf32>
  "llh.symbolic_bind"(%17, %13, %12) <{expressions = affine_map<()[s0, s1] -> (2, (s0 * s1) floordiv 2, 224, 224)>}> : (tensor<2x?x224x224xf32>, i64, i64) -> ()
  %18 = "llh.conv_bias"(%17, %6, %7) <{dilation = array<i64: 5, 5>, group = 1 : i64, kernel_shape = array<i64: 5, 5>, layout = #llh.Layout<NCHW>, pad = array<i64: 2, 2, 2, 2>, stride = array<i64: 2, 2>}> : (tensor<2x?x224x224xf32>, tensor<10x3x5x5xf32>, tensor<10xf32>) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%18) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %19 = "llh.add"(%18, %18) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%19) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %20 = "llh.div"(%18, %0) : (tensor<2x10x104x104xf32>, f32) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%20) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %21 = "llh.add"(%20, %19) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%21) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %22 = "llh.mul"(%20, %20) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%22) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %23 = "llh.add"(%21, %22) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  %24 = "llh.add"(%23, %19) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  %25 = "llh.conv_bias"(%24, %8, %9) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 5, 5>, layout = #llh.Layout<NCHW>, pad = array<i64: 5, 5, 5, 5>, stride = array<i64: 1, 1>}> : (tensor<2x10x104x104xf32>, tensor<3x10x5x5xf32>, tensor<3xf32>) -> tensor<2x3x110x110xf32>
  %26 = "llh.mul"(%25, %25) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  %27 = "llh.add"(%25, %26) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  %28 = "llh.div"(%25, %5) : (tensor<2x3x110x110xf32>, i64) -> tensor<2x3x110x110xf32>
  %29 = "llh.add"(%27, %28) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  %30 = "llh.transpose"(%10) <{perms = array<i64: 1, 0>}> : (tensor<2x110xf32>) -> tensor<110x2xf32>
  %31 = "llh.matmul"(%29, %30) : (tensor<2x3x110x110xf32>, tensor<110x2xf32>) -> tensor<2x3x110x2xf32>
  %32 = "llh.add"(%31, %11) : (tensor<2x3x110x2xf32>, tensor<2xf32>) -> tensor<2x3x110x2xf32>
  return %32 : tensor<2x3x110x2xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x561dcc20cb90) {
  %23 = "llh.add"(%21, %22) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x561dcc20cb00) {
  "llh.symbolic_bind"(%22) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
    ** Erase   : 'llh.symbolic_bind'(0x561dcc20cb00)
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x?x224x224xf32>) -> tensor<2x3x110x2xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 5.33333302 : f32}> : () -> f32
  %1 = "llh.constant"() <{value = 224 : i64}> : () -> i64
  %2 = "llh.constant"() <{value = 6 : i64}> : () -> i64
  %3 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %4 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %5 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer1.weight.npy"}> : () -> tensor<10x3x5x5xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer1.bias.npy"}> : () -> tensor<10xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer2.weight.npy"}> : () -> tensor<3x10x5x5xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer2.bias.npy"}> : () -> tensor<3xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___cf.weight.npy"}> : () -> tensor<2x110xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___cf.bias.npy"}> : () -> tensor<2xf32>
  %12 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %13 = "llh.torch_symbolic_int"() <{sym_name = "s1"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %12, %13) <{expressions = affine_map<()[s0, s1] -> (s0, s1, 224, 224)>}> : (tensor<?x?x224x224xf32>, i64, i64) -> ()
  %14 = "llh.dim"(%arg0, %5) : (tensor<?x?x224x224xf32>, i64) -> i64
  %15 = "llh.dim"(%arg0, %4) : (tensor<?x?x224x224xf32>, i64) -> i64
  %16 = "llh.reshape"(%arg0, %3, %2, %14, %15) : (tensor<?x?x224x224xf32>, i64, i64, i64, i64) -> tensor<1x?x224x224xf32>
  "llh.symbolic_bind"(%16, %13, %12) <{expressions = affine_map<()[s0, s1] -> (1, s0 * s1, 224, 224)>}> : (tensor<1x?x224x224xf32>, i64, i64) -> ()
  %17 = "llh.reshape"(%16, %5, %4, %1, %1) : (tensor<1x?x224x224xf32>, i64, i64, i64, i64) -> tensor<2x?x224x224xf32>
  "llh.symbolic_bind"(%17, %13, %12) <{expressions = affine_map<()[s0, s1] -> (2, (s0 * s1) floordiv 2, 224, 224)>}> : (tensor<2x?x224x224xf32>, i64, i64) -> ()
  %18 = "llh.conv_bias"(%17, %6, %7) <{dilation = array<i64: 5, 5>, group = 1 : i64, kernel_shape = array<i64: 5, 5>, layout = #llh.Layout<NCHW>, pad = array<i64: 2, 2, 2, 2>, stride = array<i64: 2, 2>}> : (tensor<2x?x224x224xf32>, tensor<10x3x5x5xf32>, tensor<10xf32>) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%18) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %19 = "llh.add"(%18, %18) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%19) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %20 = "llh.div"(%18, %0) : (tensor<2x10x104x104xf32>, f32) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%20) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %21 = "llh.add"(%20, %19) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%21) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %22 = "llh.mul"(%20, %20) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  %23 = "llh.add"(%21, %22) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  %24 = "llh.add"(%23, %19) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  %25 = "llh.conv_bias"(%24, %8, %9) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 5, 5>, layout = #llh.Layout<NCHW>, pad = array<i64: 5, 5, 5, 5>, stride = array<i64: 1, 1>}> : (tensor<2x10x104x104xf32>, tensor<3x10x5x5xf32>, tensor<3xf32>) -> tensor<2x3x110x110xf32>
  %26 = "llh.mul"(%25, %25) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  %27 = "llh.add"(%25, %26) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  %28 = "llh.div"(%25, %5) : (tensor<2x3x110x110xf32>, i64) -> tensor<2x3x110x110xf32>
  %29 = "llh.add"(%27, %28) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  %30 = "llh.transpose"(%10) <{perms = array<i64: 1, 0>}> : (tensor<2x110xf32>) -> tensor<110x2xf32>
  %31 = "llh.matmul"(%29, %30) : (tensor<2x3x110x110xf32>, tensor<110x2xf32>) -> tensor<2x3x110x2xf32>
  %32 = "llh.add"(%31, %11) : (tensor<2x3x110x2xf32>, tensor<2xf32>) -> tensor<2x3x110x2xf32>
  return %32 : tensor<2x3x110x2xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.mul'(0x561dcc20ca00) {
  %22 = "llh.mul"(%20, %20) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x561dcc20c970) {
  "llh.symbolic_bind"(%21) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
    ** Erase   : 'llh.symbolic_bind'(0x561dcc20c970)
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x?x224x224xf32>) -> tensor<2x3x110x2xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 5.33333302 : f32}> : () -> f32
  %1 = "llh.constant"() <{value = 224 : i64}> : () -> i64
  %2 = "llh.constant"() <{value = 6 : i64}> : () -> i64
  %3 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %4 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %5 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer1.weight.npy"}> : () -> tensor<10x3x5x5xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer1.bias.npy"}> : () -> tensor<10xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer2.weight.npy"}> : () -> tensor<3x10x5x5xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer2.bias.npy"}> : () -> tensor<3xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___cf.weight.npy"}> : () -> tensor<2x110xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___cf.bias.npy"}> : () -> tensor<2xf32>
  %12 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %13 = "llh.torch_symbolic_int"() <{sym_name = "s1"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %12, %13) <{expressions = affine_map<()[s0, s1] -> (s0, s1, 224, 224)>}> : (tensor<?x?x224x224xf32>, i64, i64) -> ()
  %14 = "llh.dim"(%arg0, %5) : (tensor<?x?x224x224xf32>, i64) -> i64
  %15 = "llh.dim"(%arg0, %4) : (tensor<?x?x224x224xf32>, i64) -> i64
  %16 = "llh.reshape"(%arg0, %3, %2, %14, %15) : (tensor<?x?x224x224xf32>, i64, i64, i64, i64) -> tensor<1x?x224x224xf32>
  "llh.symbolic_bind"(%16, %13, %12) <{expressions = affine_map<()[s0, s1] -> (1, s0 * s1, 224, 224)>}> : (tensor<1x?x224x224xf32>, i64, i64) -> ()
  %17 = "llh.reshape"(%16, %5, %4, %1, %1) : (tensor<1x?x224x224xf32>, i64, i64, i64, i64) -> tensor<2x?x224x224xf32>
  "llh.symbolic_bind"(%17, %13, %12) <{expressions = affine_map<()[s0, s1] -> (2, (s0 * s1) floordiv 2, 224, 224)>}> : (tensor<2x?x224x224xf32>, i64, i64) -> ()
  %18 = "llh.conv_bias"(%17, %6, %7) <{dilation = array<i64: 5, 5>, group = 1 : i64, kernel_shape = array<i64: 5, 5>, layout = #llh.Layout<NCHW>, pad = array<i64: 2, 2, 2, 2>, stride = array<i64: 2, 2>}> : (tensor<2x?x224x224xf32>, tensor<10x3x5x5xf32>, tensor<10xf32>) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%18) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %19 = "llh.add"(%18, %18) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%19) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %20 = "llh.div"(%18, %0) : (tensor<2x10x104x104xf32>, f32) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%20) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %21 = "llh.add"(%20, %19) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  %22 = "llh.mul"(%20, %20) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  %23 = "llh.add"(%21, %22) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  %24 = "llh.add"(%23, %19) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  %25 = "llh.conv_bias"(%24, %8, %9) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 5, 5>, layout = #llh.Layout<NCHW>, pad = array<i64: 5, 5, 5, 5>, stride = array<i64: 1, 1>}> : (tensor<2x10x104x104xf32>, tensor<3x10x5x5xf32>, tensor<3xf32>) -> tensor<2x3x110x110xf32>
  %26 = "llh.mul"(%25, %25) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  %27 = "llh.add"(%25, %26) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  %28 = "llh.div"(%25, %5) : (tensor<2x3x110x110xf32>, i64) -> tensor<2x3x110x110xf32>
  %29 = "llh.add"(%27, %28) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  %30 = "llh.transpose"(%10) <{perms = array<i64: 1, 0>}> : (tensor<2x110xf32>) -> tensor<110x2xf32>
  %31 = "llh.matmul"(%29, %30) : (tensor<2x3x110x110xf32>, tensor<110x2xf32>) -> tensor<2x3x110x2xf32>
  %32 = "llh.add"(%31, %11) : (tensor<2x3x110x2xf32>, tensor<2xf32>) -> tensor<2x3x110x2xf32>
  return %32 : tensor<2x3x110x2xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x561dcc20c870) {
  %21 = "llh.add"(%20, %19) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x561dcc20c7e0) {
  "llh.symbolic_bind"(%20) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
    ** Erase   : 'llh.symbolic_bind'(0x561dcc20c7e0)
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x?x224x224xf32>) -> tensor<2x3x110x2xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = 5.33333302 : f32}> : () -> f32
  %1 = "llh.constant"() <{value = 224 : i64}> : () -> i64
  %2 = "llh.constant"() <{value = 6 : i64}> : () -> i64
  %3 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %4 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %5 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer1.weight.npy"}> : () -> tensor<10x3x5x5xf32>
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer1.bias.npy"}> : () -> tensor<10xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer2.weight.npy"}> : () -> tensor<3x10x5x5xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer2.bias.npy"}> : () -> tensor<3xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___cf.weight.npy"}> : () -> tensor<2x110xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___cf.bias.npy"}> : () -> tensor<2xf32>
  %12 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %13 = "llh.torch_symbolic_int"() <{sym_name = "s1"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %12, %13) <{expressions = affine_map<()[s0, s1] -> (s0, s1, 224, 224)>}> : (tensor<?x?x224x224xf32>, i64, i64) -> ()
  %14 = "llh.dim"(%arg0, %5) : (tensor<?x?x224x224xf32>, i64) -> i64
  %15 = "llh.dim"(%arg0, %4) : (tensor<?x?x224x224xf32>, i64) -> i64
  %16 = "llh.reshape"(%arg0, %3, %2, %14, %15) : (tensor<?x?x224x224xf32>, i64, i64, i64, i64) -> tensor<1x?x224x224xf32>
  "llh.symbolic_bind"(%16, %13, %12) <{expressions = affine_map<()[s0, s1] -> (1, s0 * s1, 224, 224)>}> : (tensor<1x?x224x224xf32>, i64, i64) -> ()
  %17 = "llh.reshape"(%16, %5, %4, %1, %1) : (tensor<1x?x224x224xf32>, i64, i64, i64, i64) -> tensor<2x?x224x224xf32>
  "llh.symbolic_bind"(%17, %13, %12) <{expressions = affine_map<()[s0, s1] -> (2, (s0 * s1) floordiv 2, 224, 224)>}> : (tensor<2x?x224x224xf32>, i64, i64) -> ()
  %18 = "llh.conv_bias"(%17, %6, %7) <{dilation = array<i64: 5, 5>, group = 1 : i64, kernel_shape = array<i64: 5, 5>, layout = #llh.Layout<NCHW>, pad = array<i64: 2, 2, 2, 2>, stride = array<i64: 2, 2>}> : (tensor<2x?x224x224xf32>, tensor<10x3x5x5xf32>, tensor<10xf32>) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%18) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %19 = "llh.add"(%18, %18) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%19) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %20 = "llh.div"(%18, %0) : (tensor<2x10x104x104xf32>, f32) -> tensor<2x10x104x104xf32>
  %21 = "llh.add"(%20, %19) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  %22 = "llh.mul"(%20, %20) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  %23 = "llh.add"(%21, %22) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  %24 = "llh.add"(%23, %19) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  %25 = "llh.conv_bias"(%24, %8, %9) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 5, 5>, layout = #llh.Layout<NCHW>, pad = array<i64: 5, 5, 5, 5>, stride = array<i64: 1, 1>}> : (tensor<2x10x104x104xf32>, tensor<3x10x5x5xf32>, tensor<3xf32>) -> tensor<2x3x110x110xf32>
  %26 = "llh.mul"(%25, %25) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  %27 = "llh.add"(%25, %26) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  %28 = "llh.div"(%25, %5) : (tensor<2x3x110x110xf32>, i64) -> tensor<2x3x110x110xf32>
  %29 = "llh.add"(%27, %28) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  %30 = "llh.transpose"(%10) <{perms = array<i64: 1, 0>}> : (tensor<2x110xf32>) -> tensor<110x2xf32>
  %31 = "llh.matmul"(%29, %30) : (tensor<2x3x110x110xf32>, tensor<110x2xf32>) -> tensor<2x3x110x2xf32>
  %32 = "llh.add"(%31, %11) : (tensor<2x3x110x2xf32>, tensor<2xf32>) -> tensor<2x3x110x2xf32>
  return %32 : tensor<2x3x110x2xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.div'(0x561dcc20c0a0) {
  %20 = "llh.div"(%18, %0) : (tensor<2x10x104x104xf32>, f32) -> tensor<2x10x104x104xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.constant'(0x561dcc20c000) {
  %0 = "llh.constant"() <{value = 5.33333302 : f32}> : () -> f32


  * Pattern {anonymous}::BraodcastableScalarToTensor : 'llh.constant -> ()' {
Trying to match "{anonymous}::BraodcastableScalarToTensor"
ImplicitTypeIDRegistry::lookupOrInsert(mlir::llh::detail::ConstantOpGenericAdaptorBase::Properties)
    ** Insert  : 'llh.constant'(0x561dcc208b60)
"{anonymous}::BraodcastableScalarToTensor" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x?x224x224xf32>) -> tensor<2x3x110x2xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = dense<5.33333302> : tensor<1xf32>}> : () -> tensor<1xf32>
  %1 = "llh.constant"() <{value = 5.33333302 : f32}> : () -> f32
  %2 = "llh.constant"() <{value = 224 : i64}> : () -> i64
  %3 = "llh.constant"() <{value = 6 : i64}> : () -> i64
  %4 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %5 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %6 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer1.weight.npy"}> : () -> tensor<10x3x5x5xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer1.bias.npy"}> : () -> tensor<10xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer2.weight.npy"}> : () -> tensor<3x10x5x5xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer2.bias.npy"}> : () -> tensor<3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___cf.weight.npy"}> : () -> tensor<2x110xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___cf.bias.npy"}> : () -> tensor<2xf32>
  %13 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %14 = "llh.torch_symbolic_int"() <{sym_name = "s1"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %13, %14) <{expressions = affine_map<()[s0, s1] -> (s0, s1, 224, 224)>}> : (tensor<?x?x224x224xf32>, i64, i64) -> ()
  %15 = "llh.dim"(%arg0, %6) : (tensor<?x?x224x224xf32>, i64) -> i64
  %16 = "llh.dim"(%arg0, %5) : (tensor<?x?x224x224xf32>, i64) -> i64
  %17 = "llh.reshape"(%arg0, %4, %3, %15, %16) : (tensor<?x?x224x224xf32>, i64, i64, i64, i64) -> tensor<1x?x224x224xf32>
  "llh.symbolic_bind"(%17, %14, %13) <{expressions = affine_map<()[s0, s1] -> (1, s0 * s1, 224, 224)>}> : (tensor<1x?x224x224xf32>, i64, i64) -> ()
  %18 = "llh.reshape"(%17, %6, %5, %2, %2) : (tensor<1x?x224x224xf32>, i64, i64, i64, i64) -> tensor<2x?x224x224xf32>
  "llh.symbolic_bind"(%18, %14, %13) <{expressions = affine_map<()[s0, s1] -> (2, (s0 * s1) floordiv 2, 224, 224)>}> : (tensor<2x?x224x224xf32>, i64, i64) -> ()
  %19 = "llh.conv_bias"(%18, %7, %8) <{dilation = array<i64: 5, 5>, group = 1 : i64, kernel_shape = array<i64: 5, 5>, layout = #llh.Layout<NCHW>, pad = array<i64: 2, 2, 2, 2>, stride = array<i64: 2, 2>}> : (tensor<2x?x224x224xf32>, tensor<10x3x5x5xf32>, tensor<10xf32>) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%19) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %20 = "llh.add"(%19, %19) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%20) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %21 = "llh.div"(%19, %0) : (tensor<2x10x104x104xf32>, tensor<1xf32>) -> tensor<2x10x104x104xf32>
  %22 = "llh.add"(%21, %20) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  %23 = "llh.mul"(%21, %21) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  %24 = "llh.add"(%22, %23) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  %25 = "llh.add"(%24, %20) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  %26 = "llh.conv_bias"(%25, %9, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 5, 5>, layout = #llh.Layout<NCHW>, pad = array<i64: 5, 5, 5, 5>, stride = array<i64: 1, 1>}> : (tensor<2x10x104x104xf32>, tensor<3x10x5x5xf32>, tensor<3xf32>) -> tensor<2x3x110x110xf32>
  %27 = "llh.mul"(%26, %26) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  %28 = "llh.add"(%26, %27) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  %29 = "llh.div"(%26, %6) : (tensor<2x3x110x110xf32>, i64) -> tensor<2x3x110x110xf32>
  %30 = "llh.add"(%28, %29) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  %31 = "llh.transpose"(%11) <{perms = array<i64: 1, 0>}> : (tensor<2x110xf32>) -> tensor<110x2xf32>
  %32 = "llh.matmul"(%30, %31) : (tensor<2x3x110x110xf32>, tensor<110x2xf32>) -> tensor<2x3x110x2xf32>
  %33 = "llh.add"(%32, %12) : (tensor<2x3x110x2xf32>, tensor<2xf32>) -> tensor<2x3x110x2xf32>
  return %33 : tensor<2x3x110x2xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.constant'(0x561dcc208b60) {
  %0 = "llh.constant"() <{value = dense<5.33333302> : tensor<1xf32>}> : () -> tensor<1xf32>


  * Pattern {anonymous}::BraodcastableScalarToTensor : 'llh.constant -> ()' {
Trying to match "{anonymous}::BraodcastableScalarToTensor"
"{anonymous}::BraodcastableScalarToTensor" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x561dcc20bad0) {
  "llh.symbolic_bind"(%20) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
    ** Erase   : 'llh.symbolic_bind'(0x561dcc20bad0)
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x?x224x224xf32>) -> tensor<2x3x110x2xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = dense<5.33333302> : tensor<1xf32>}> : () -> tensor<1xf32>
  %1 = "llh.constant"() <{value = 5.33333302 : f32}> : () -> f32
  %2 = "llh.constant"() <{value = 224 : i64}> : () -> i64
  %3 = "llh.constant"() <{value = 6 : i64}> : () -> i64
  %4 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %5 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %6 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer1.weight.npy"}> : () -> tensor<10x3x5x5xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer1.bias.npy"}> : () -> tensor<10xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer2.weight.npy"}> : () -> tensor<3x10x5x5xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer2.bias.npy"}> : () -> tensor<3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___cf.weight.npy"}> : () -> tensor<2x110xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___cf.bias.npy"}> : () -> tensor<2xf32>
  %13 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %14 = "llh.torch_symbolic_int"() <{sym_name = "s1"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %13, %14) <{expressions = affine_map<()[s0, s1] -> (s0, s1, 224, 224)>}> : (tensor<?x?x224x224xf32>, i64, i64) -> ()
  %15 = "llh.dim"(%arg0, %6) : (tensor<?x?x224x224xf32>, i64) -> i64
  %16 = "llh.dim"(%arg0, %5) : (tensor<?x?x224x224xf32>, i64) -> i64
  %17 = "llh.reshape"(%arg0, %4, %3, %15, %16) : (tensor<?x?x224x224xf32>, i64, i64, i64, i64) -> tensor<1x?x224x224xf32>
  "llh.symbolic_bind"(%17, %14, %13) <{expressions = affine_map<()[s0, s1] -> (1, s0 * s1, 224, 224)>}> : (tensor<1x?x224x224xf32>, i64, i64) -> ()
  %18 = "llh.reshape"(%17, %6, %5, %2, %2) : (tensor<1x?x224x224xf32>, i64, i64, i64, i64) -> tensor<2x?x224x224xf32>
  "llh.symbolic_bind"(%18, %14, %13) <{expressions = affine_map<()[s0, s1] -> (2, (s0 * s1) floordiv 2, 224, 224)>}> : (tensor<2x?x224x224xf32>, i64, i64) -> ()
  %19 = "llh.conv_bias"(%18, %7, %8) <{dilation = array<i64: 5, 5>, group = 1 : i64, kernel_shape = array<i64: 5, 5>, layout = #llh.Layout<NCHW>, pad = array<i64: 2, 2, 2, 2>, stride = array<i64: 2, 2>}> : (tensor<2x?x224x224xf32>, tensor<10x3x5x5xf32>, tensor<10xf32>) -> tensor<2x10x104x104xf32>
  "llh.symbolic_bind"(%19) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()
  %20 = "llh.add"(%19, %19) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  %21 = "llh.div"(%19, %0) : (tensor<2x10x104x104xf32>, tensor<1xf32>) -> tensor<2x10x104x104xf32>
  %22 = "llh.add"(%21, %20) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  %23 = "llh.mul"(%21, %21) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  %24 = "llh.add"(%22, %23) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  %25 = "llh.add"(%24, %20) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  %26 = "llh.conv_bias"(%25, %9, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 5, 5>, layout = #llh.Layout<NCHW>, pad = array<i64: 5, 5, 5, 5>, stride = array<i64: 1, 1>}> : (tensor<2x10x104x104xf32>, tensor<3x10x5x5xf32>, tensor<3xf32>) -> tensor<2x3x110x110xf32>
  %27 = "llh.mul"(%26, %26) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  %28 = "llh.add"(%26, %27) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  %29 = "llh.div"(%26, %6) : (tensor<2x3x110x110xf32>, i64) -> tensor<2x3x110x110xf32>
  %30 = "llh.add"(%28, %29) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  %31 = "llh.transpose"(%11) <{perms = array<i64: 1, 0>}> : (tensor<2x110xf32>) -> tensor<110x2xf32>
  %32 = "llh.matmul"(%30, %31) : (tensor<2x3x110x110xf32>, tensor<110x2xf32>) -> tensor<2x3x110x2xf32>
  %33 = "llh.add"(%32, %12) : (tensor<2x3x110x2xf32>, tensor<2xf32>) -> tensor<2x3x110x2xf32>
  return %33 : tensor<2x3x110x2xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x561dcc20b9f0) {
  %20 = "llh.add"(%19, %19) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x561dcc1fe790) {
  "llh.symbolic_bind"(%19) <{expressions = affine_map<()[s0, s1] -> (2, 10, 104, 104)>}> : (tensor<2x10x104x104xf32>) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
    ** Erase   : 'llh.symbolic_bind'(0x561dcc1fe790)
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x?x224x224xf32>) -> tensor<2x3x110x2xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = dense<5.33333302> : tensor<1xf32>}> : () -> tensor<1xf32>
  %1 = "llh.constant"() <{value = 5.33333302 : f32}> : () -> f32
  %2 = "llh.constant"() <{value = 224 : i64}> : () -> i64
  %3 = "llh.constant"() <{value = 6 : i64}> : () -> i64
  %4 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %5 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %6 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer1.weight.npy"}> : () -> tensor<10x3x5x5xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer1.bias.npy"}> : () -> tensor<10xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer2.weight.npy"}> : () -> tensor<3x10x5x5xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer2.bias.npy"}> : () -> tensor<3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___cf.weight.npy"}> : () -> tensor<2x110xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___cf.bias.npy"}> : () -> tensor<2xf32>
  %13 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %14 = "llh.torch_symbolic_int"() <{sym_name = "s1"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %13, %14) <{expressions = affine_map<()[s0, s1] -> (s0, s1, 224, 224)>}> : (tensor<?x?x224x224xf32>, i64, i64) -> ()
  %15 = "llh.dim"(%arg0, %6) : (tensor<?x?x224x224xf32>, i64) -> i64
  %16 = "llh.dim"(%arg0, %5) : (tensor<?x?x224x224xf32>, i64) -> i64
  %17 = "llh.reshape"(%arg0, %4, %3, %15, %16) : (tensor<?x?x224x224xf32>, i64, i64, i64, i64) -> tensor<1x?x224x224xf32>
  "llh.symbolic_bind"(%17, %14, %13) <{expressions = affine_map<()[s0, s1] -> (1, s0 * s1, 224, 224)>}> : (tensor<1x?x224x224xf32>, i64, i64) -> ()
  %18 = "llh.reshape"(%17, %6, %5, %2, %2) : (tensor<1x?x224x224xf32>, i64, i64, i64, i64) -> tensor<2x?x224x224xf32>
  "llh.symbolic_bind"(%18, %14, %13) <{expressions = affine_map<()[s0, s1] -> (2, (s0 * s1) floordiv 2, 224, 224)>}> : (tensor<2x?x224x224xf32>, i64, i64) -> ()
  %19 = "llh.conv_bias"(%18, %7, %8) <{dilation = array<i64: 5, 5>, group = 1 : i64, kernel_shape = array<i64: 5, 5>, layout = #llh.Layout<NCHW>, pad = array<i64: 2, 2, 2, 2>, stride = array<i64: 2, 2>}> : (tensor<2x?x224x224xf32>, tensor<10x3x5x5xf32>, tensor<10xf32>) -> tensor<2x10x104x104xf32>
  %20 = "llh.add"(%19, %19) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  %21 = "llh.div"(%19, %0) : (tensor<2x10x104x104xf32>, tensor<1xf32>) -> tensor<2x10x104x104xf32>
  %22 = "llh.add"(%21, %20) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  %23 = "llh.mul"(%21, %21) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  %24 = "llh.add"(%22, %23) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  %25 = "llh.add"(%24, %20) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  %26 = "llh.conv_bias"(%25, %9, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 5, 5>, layout = #llh.Layout<NCHW>, pad = array<i64: 5, 5, 5, 5>, stride = array<i64: 1, 1>}> : (tensor<2x10x104x104xf32>, tensor<3x10x5x5xf32>, tensor<3xf32>) -> tensor<2x3x110x110xf32>
  %27 = "llh.mul"(%26, %26) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  %28 = "llh.add"(%26, %27) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  %29 = "llh.div"(%26, %6) : (tensor<2x3x110x110xf32>, i64) -> tensor<2x3x110x110xf32>
  %30 = "llh.add"(%28, %29) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  %31 = "llh.transpose"(%11) <{perms = array<i64: 1, 0>}> : (tensor<2x110xf32>) -> tensor<110x2xf32>
  %32 = "llh.matmul"(%30, %31) : (tensor<2x3x110x110xf32>, tensor<110x2xf32>) -> tensor<2x3x110x2xf32>
  %33 = "llh.add"(%32, %12) : (tensor<2x3x110x2xf32>, tensor<2xf32>) -> tensor<2x3x110x2xf32>
  return %33 : tensor<2x3x110x2xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv_bias'(0x561dcc1f2f30) {
  %19 = "llh.conv_bias"(%18, %7, %8) <{dilation = array<i64: 5, 5>, group = 1 : i64, kernel_shape = array<i64: 5, 5>, layout = #llh.Layout<NCHW>, pad = array<i64: 2, 2, 2, 2>, stride = array<i64: 2, 2>}> : (tensor<2x?x224x224xf32>, tensor<10x3x5x5xf32>, tensor<10xf32>) -> tensor<2x10x104x104xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x561dcc20a3f0) {
  "llh.symbolic_bind"(%18, %14, %13) <{expressions = affine_map<()[s0, s1] -> (2, (s0 * s1) floordiv 2, 224, 224)>}> : (tensor<2x?x224x224xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
    ** Erase   : 'llh.symbolic_bind'(0x561dcc20a3f0)
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x?x224x224xf32>) -> tensor<2x3x110x2xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = dense<5.33333302> : tensor<1xf32>}> : () -> tensor<1xf32>
  %1 = "llh.constant"() <{value = 5.33333302 : f32}> : () -> f32
  %2 = "llh.constant"() <{value = 224 : i64}> : () -> i64
  %3 = "llh.constant"() <{value = 6 : i64}> : () -> i64
  %4 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %5 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %6 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer1.weight.npy"}> : () -> tensor<10x3x5x5xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer1.bias.npy"}> : () -> tensor<10xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer2.weight.npy"}> : () -> tensor<3x10x5x5xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer2.bias.npy"}> : () -> tensor<3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___cf.weight.npy"}> : () -> tensor<2x110xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___cf.bias.npy"}> : () -> tensor<2xf32>
  %13 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %14 = "llh.torch_symbolic_int"() <{sym_name = "s1"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %13, %14) <{expressions = affine_map<()[s0, s1] -> (s0, s1, 224, 224)>}> : (tensor<?x?x224x224xf32>, i64, i64) -> ()
  %15 = "llh.dim"(%arg0, %6) : (tensor<?x?x224x224xf32>, i64) -> i64
  %16 = "llh.dim"(%arg0, %5) : (tensor<?x?x224x224xf32>, i64) -> i64
  %17 = "llh.reshape"(%arg0, %4, %3, %15, %16) : (tensor<?x?x224x224xf32>, i64, i64, i64, i64) -> tensor<1x?x224x224xf32>
  "llh.symbolic_bind"(%17, %14, %13) <{expressions = affine_map<()[s0, s1] -> (1, s0 * s1, 224, 224)>}> : (tensor<1x?x224x224xf32>, i64, i64) -> ()
  %18 = "llh.reshape"(%17, %6, %5, %2, %2) : (tensor<1x?x224x224xf32>, i64, i64, i64, i64) -> tensor<2x?x224x224xf32>
  %19 = "llh.conv_bias"(%18, %7, %8) <{dilation = array<i64: 5, 5>, group = 1 : i64, kernel_shape = array<i64: 5, 5>, layout = #llh.Layout<NCHW>, pad = array<i64: 2, 2, 2, 2>, stride = array<i64: 2, 2>}> : (tensor<2x?x224x224xf32>, tensor<10x3x5x5xf32>, tensor<10xf32>) -> tensor<2x10x104x104xf32>
  %20 = "llh.add"(%19, %19) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  %21 = "llh.div"(%19, %0) : (tensor<2x10x104x104xf32>, tensor<1xf32>) -> tensor<2x10x104x104xf32>
  %22 = "llh.add"(%21, %20) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  %23 = "llh.mul"(%21, %21) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  %24 = "llh.add"(%22, %23) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  %25 = "llh.add"(%24, %20) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  %26 = "llh.conv_bias"(%25, %9, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 5, 5>, layout = #llh.Layout<NCHW>, pad = array<i64: 5, 5, 5, 5>, stride = array<i64: 1, 1>}> : (tensor<2x10x104x104xf32>, tensor<3x10x5x5xf32>, tensor<3xf32>) -> tensor<2x3x110x110xf32>
  %27 = "llh.mul"(%26, %26) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  %28 = "llh.add"(%26, %27) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  %29 = "llh.div"(%26, %6) : (tensor<2x3x110x110xf32>, i64) -> tensor<2x3x110x110xf32>
  %30 = "llh.add"(%28, %29) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  %31 = "llh.transpose"(%11) <{perms = array<i64: 1, 0>}> : (tensor<2x110xf32>) -> tensor<110x2xf32>
  %32 = "llh.matmul"(%30, %31) : (tensor<2x3x110x110xf32>, tensor<110x2xf32>) -> tensor<2x3x110x2xf32>
  %33 = "llh.add"(%32, %12) : (tensor<2x3x110x2xf32>, tensor<2xf32>) -> tensor<2x3x110x2xf32>
  return %33 : tensor<2x3x110x2xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.constant'(0x561dcc20a220) {
  %2 = "llh.constant"() <{value = 224 : i64}> : () -> i64


  * Pattern {anonymous}::BraodcastableScalarToTensor : 'llh.constant -> ()' {
Trying to match "{anonymous}::BraodcastableScalarToTensor"
"{anonymous}::BraodcastableScalarToTensor" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.reshape'(0x561dcc1d5480) {
  %18 = "llh.reshape"(%17, %6, %5, %2, %2) : (tensor<1x?x224x224xf32>, i64, i64, i64, i64) -> tensor<2x?x224x224xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x561dcc209fd0) {
  "llh.symbolic_bind"(%17, %14, %13) <{expressions = affine_map<()[s0, s1] -> (1, s0 * s1, 224, 224)>}> : (tensor<1x?x224x224xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
    ** Erase   : 'llh.symbolic_bind'(0x561dcc209fd0)
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x?x224x224xf32>) -> tensor<2x3x110x2xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = dense<5.33333302> : tensor<1xf32>}> : () -> tensor<1xf32>
  %1 = "llh.constant"() <{value = 5.33333302 : f32}> : () -> f32
  %2 = "llh.constant"() <{value = 224 : i64}> : () -> i64
  %3 = "llh.constant"() <{value = 6 : i64}> : () -> i64
  %4 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %5 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %6 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer1.weight.npy"}> : () -> tensor<10x3x5x5xf32>
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer1.bias.npy"}> : () -> tensor<10xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer2.weight.npy"}> : () -> tensor<3x10x5x5xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer2.bias.npy"}> : () -> tensor<3xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___cf.weight.npy"}> : () -> tensor<2x110xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___cf.bias.npy"}> : () -> tensor<2xf32>
  %13 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %14 = "llh.torch_symbolic_int"() <{sym_name = "s1"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %13, %14) <{expressions = affine_map<()[s0, s1] -> (s0, s1, 224, 224)>}> : (tensor<?x?x224x224xf32>, i64, i64) -> ()
  %15 = "llh.dim"(%arg0, %6) : (tensor<?x?x224x224xf32>, i64) -> i64
  %16 = "llh.dim"(%arg0, %5) : (tensor<?x?x224x224xf32>, i64) -> i64
  %17 = "llh.reshape"(%arg0, %4, %3, %15, %16) : (tensor<?x?x224x224xf32>, i64, i64, i64, i64) -> tensor<1x?x224x224xf32>
  %18 = "llh.reshape"(%17, %6, %5, %2, %2) : (tensor<1x?x224x224xf32>, i64, i64, i64, i64) -> tensor<2x?x224x224xf32>
  %19 = "llh.conv_bias"(%18, %7, %8) <{dilation = array<i64: 5, 5>, group = 1 : i64, kernel_shape = array<i64: 5, 5>, layout = #llh.Layout<NCHW>, pad = array<i64: 2, 2, 2, 2>, stride = array<i64: 2, 2>}> : (tensor<2x?x224x224xf32>, tensor<10x3x5x5xf32>, tensor<10xf32>) -> tensor<2x10x104x104xf32>
  %20 = "llh.add"(%19, %19) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  %21 = "llh.div"(%19, %0) : (tensor<2x10x104x104xf32>, tensor<1xf32>) -> tensor<2x10x104x104xf32>
  %22 = "llh.add"(%21, %20) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  %23 = "llh.mul"(%21, %21) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  %24 = "llh.add"(%22, %23) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  %25 = "llh.add"(%24, %20) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  %26 = "llh.conv_bias"(%25, %9, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 5, 5>, layout = #llh.Layout<NCHW>, pad = array<i64: 5, 5, 5, 5>, stride = array<i64: 1, 1>}> : (tensor<2x10x104x104xf32>, tensor<3x10x5x5xf32>, tensor<3xf32>) -> tensor<2x3x110x110xf32>
  %27 = "llh.mul"(%26, %26) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  %28 = "llh.add"(%26, %27) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  %29 = "llh.div"(%26, %6) : (tensor<2x3x110x110xf32>, i64) -> tensor<2x3x110x110xf32>
  %30 = "llh.add"(%28, %29) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  %31 = "llh.transpose"(%11) <{perms = array<i64: 1, 0>}> : (tensor<2x110xf32>) -> tensor<110x2xf32>
  %32 = "llh.matmul"(%30, %31) : (tensor<2x3x110x110xf32>, tensor<110x2xf32>) -> tensor<2x3x110x2xf32>
  %33 = "llh.add"(%32, %12) : (tensor<2x3x110x2xf32>, tensor<2xf32>) -> tensor<2x3x110x2xf32>
  return %33 : tensor<2x3x110x2xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.reshape'(0x561dcc1efa50) {
  %17 = "llh.reshape"(%arg0, %4, %3, %15, %16) : (tensor<?x?x224x224xf32>, i64, i64, i64, i64) -> tensor<1x?x224x224xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.constant'(0x561dcc209a50) {
  %3 = "llh.constant"() <{value = 6 : i64}> : () -> i64


  * Pattern {anonymous}::BraodcastableScalarToTensor : 'llh.constant -> ()' {
Trying to match "{anonymous}::BraodcastableScalarToTensor"
"{anonymous}::BraodcastableScalarToTensor" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.constant'(0x561dcc1fe670) {
  %4 = "llh.constant"() <{value = 1 : i64}> : () -> i64


  * Pattern {anonymous}::BraodcastableScalarToTensor : 'llh.constant -> ()' {
Trying to match "{anonymous}::BraodcastableScalarToTensor"
"{anonymous}::BraodcastableScalarToTensor" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.dim'(0x561dcc208d90) {
  %16 = "llh.dim"(%arg0, %5) : (tensor<?x?x224x224xf32>, i64) -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.constant'(0x561dcc208cd0) {
  %5 = "llh.constant"() <{value = 3 : i64}> : () -> i64


  * Pattern {anonymous}::BraodcastableScalarToTensor : 'llh.constant -> ()' {
Trying to match "{anonymous}::BraodcastableScalarToTensor"
"{anonymous}::BraodcastableScalarToTensor" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.dim'(0x561dcc208bc0) {
  %15 = "llh.dim"(%arg0, %6) : (tensor<?x?x224x224xf32>, i64) -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.constant'(0x561dcc208b00) {
  %6 = "llh.constant"() <{value = 2 : i64}> : () -> i64


  * Pattern {anonymous}::BraodcastableScalarToTensor : 'llh.constant -> ()' {
Trying to match "{anonymous}::BraodcastableScalarToTensor"
    ** Insert  : 'llh.constant'(0x561dcc20e2a0)
"{anonymous}::BraodcastableScalarToTensor" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x?x224x224xf32>) -> tensor<2x3x110x2xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = dense<5.33333302> : tensor<1xf32>}> : () -> tensor<1xf32>
  %1 = "llh.constant"() <{value = 5.33333302 : f32}> : () -> f32
  %2 = "llh.constant"() <{value = 224 : i64}> : () -> i64
  %3 = "llh.constant"() <{value = 6 : i64}> : () -> i64
  %4 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %5 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %6 = "llh.constant"() <{value = dense<0.000000e+00> : tensor<1xf32>}> : () -> tensor<1xf32>
  %7 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer1.weight.npy"}> : () -> tensor<10x3x5x5xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer1.bias.npy"}> : () -> tensor<10xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer2.weight.npy"}> : () -> tensor<3x10x5x5xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer2.bias.npy"}> : () -> tensor<3xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___cf.weight.npy"}> : () -> tensor<2x110xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___cf.bias.npy"}> : () -> tensor<2xf32>
  %14 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %15 = "llh.torch_symbolic_int"() <{sym_name = "s1"}> : () -> i64
  "llh.symbolic_bind"(%arg0, %14, %15) <{expressions = affine_map<()[s0, s1] -> (s0, s1, 224, 224)>}> : (tensor<?x?x224x224xf32>, i64, i64) -> ()
  %16 = "llh.dim"(%arg0, %7) : (tensor<?x?x224x224xf32>, i64) -> i64
  %17 = "llh.dim"(%arg0, %5) : (tensor<?x?x224x224xf32>, i64) -> i64
  %18 = "llh.reshape"(%arg0, %4, %3, %16, %17) : (tensor<?x?x224x224xf32>, i64, i64, i64, i64) -> tensor<1x?x224x224xf32>
  %19 = "llh.reshape"(%18, %7, %5, %2, %2) : (tensor<1x?x224x224xf32>, i64, i64, i64, i64) -> tensor<2x?x224x224xf32>
  %20 = "llh.conv_bias"(%19, %8, %9) <{dilation = array<i64: 5, 5>, group = 1 : i64, kernel_shape = array<i64: 5, 5>, layout = #llh.Layout<NCHW>, pad = array<i64: 2, 2, 2, 2>, stride = array<i64: 2, 2>}> : (tensor<2x?x224x224xf32>, tensor<10x3x5x5xf32>, tensor<10xf32>) -> tensor<2x10x104x104xf32>
  %21 = "llh.add"(%20, %20) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  %22 = "llh.div"(%20, %0) : (tensor<2x10x104x104xf32>, tensor<1xf32>) -> tensor<2x10x104x104xf32>
  %23 = "llh.add"(%22, %21) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  %24 = "llh.mul"(%22, %22) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  %25 = "llh.add"(%23, %24) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  %26 = "llh.add"(%25, %21) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  %27 = "llh.conv_bias"(%26, %10, %11) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 5, 5>, layout = #llh.Layout<NCHW>, pad = array<i64: 5, 5, 5, 5>, stride = array<i64: 1, 1>}> : (tensor<2x10x104x104xf32>, tensor<3x10x5x5xf32>, tensor<3xf32>) -> tensor<2x3x110x110xf32>
  %28 = "llh.mul"(%27, %27) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  %29 = "llh.add"(%27, %28) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  %30 = "llh.div"(%27, %6) : (tensor<2x3x110x110xf32>, tensor<1xf32>) -> tensor<2x3x110x110xf32>
  %31 = "llh.add"(%29, %30) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  %32 = "llh.transpose"(%12) <{perms = array<i64: 1, 0>}> : (tensor<2x110xf32>) -> tensor<110x2xf32>
  %33 = "llh.matmul"(%31, %32) : (tensor<2x3x110x110xf32>, tensor<110x2xf32>) -> tensor<2x3x110x2xf32>
  %34 = "llh.add"(%33, %13) : (tensor<2x3x110x2xf32>, tensor<2xf32>) -> tensor<2x3x110x2xf32>
  return %34 : tensor<2x3x110x2xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.constant'(0x561dcc20e2a0) {
  %6 = "llh.constant"() <{value = dense<0.000000e+00> : tensor<1xf32>}> : () -> tensor<1xf32>


  * Pattern {anonymous}::BraodcastableScalarToTensor : 'llh.constant -> ()' {
Trying to match "{anonymous}::BraodcastableScalarToTensor"
"{anonymous}::BraodcastableScalarToTensor" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.symbolic_bind'(0x561dcc208130) {
  "llh.symbolic_bind"(%arg0, %14, %15) <{expressions = affine_map<()[s0, s1] -> (s0, s1, 224, 224)>}> : (tensor<?x?x224x224xf32>, i64, i64) -> ()


  * Pattern {anonymous}::replaceSymbolicBindOp : 'llh.symbolic_bind -> ()' {
Trying to match "{anonymous}::replaceSymbolicBindOp"
    ** Erase   : 'llh.symbolic_bind'(0x561dcc208130)
"{anonymous}::replaceSymbolicBindOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x?x224x224xf32>) -> tensor<2x3x110x2xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = dense<5.33333302> : tensor<1xf32>}> : () -> tensor<1xf32>
  %1 = "llh.constant"() <{value = 5.33333302 : f32}> : () -> f32
  %2 = "llh.constant"() <{value = 224 : i64}> : () -> i64
  %3 = "llh.constant"() <{value = 6 : i64}> : () -> i64
  %4 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %5 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %6 = "llh.constant"() <{value = dense<0.000000e+00> : tensor<1xf32>}> : () -> tensor<1xf32>
  %7 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer1.weight.npy"}> : () -> tensor<10x3x5x5xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer1.bias.npy"}> : () -> tensor<10xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer2.weight.npy"}> : () -> tensor<3x10x5x5xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer2.bias.npy"}> : () -> tensor<3xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___cf.weight.npy"}> : () -> tensor<2x110xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___cf.bias.npy"}> : () -> tensor<2xf32>
  %14 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %15 = "llh.torch_symbolic_int"() <{sym_name = "s1"}> : () -> i64
  %16 = "llh.dim"(%arg0, %7) : (tensor<?x?x224x224xf32>, i64) -> i64
  %17 = "llh.dim"(%arg0, %5) : (tensor<?x?x224x224xf32>, i64) -> i64
  %18 = "llh.reshape"(%arg0, %4, %3, %16, %17) : (tensor<?x?x224x224xf32>, i64, i64, i64, i64) -> tensor<1x?x224x224xf32>
  %19 = "llh.reshape"(%18, %7, %5, %2, %2) : (tensor<1x?x224x224xf32>, i64, i64, i64, i64) -> tensor<2x?x224x224xf32>
  %20 = "llh.conv_bias"(%19, %8, %9) <{dilation = array<i64: 5, 5>, group = 1 : i64, kernel_shape = array<i64: 5, 5>, layout = #llh.Layout<NCHW>, pad = array<i64: 2, 2, 2, 2>, stride = array<i64: 2, 2>}> : (tensor<2x?x224x224xf32>, tensor<10x3x5x5xf32>, tensor<10xf32>) -> tensor<2x10x104x104xf32>
  %21 = "llh.add"(%20, %20) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  %22 = "llh.div"(%20, %0) : (tensor<2x10x104x104xf32>, tensor<1xf32>) -> tensor<2x10x104x104xf32>
  %23 = "llh.add"(%22, %21) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  %24 = "llh.mul"(%22, %22) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  %25 = "llh.add"(%23, %24) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  %26 = "llh.add"(%25, %21) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  %27 = "llh.conv_bias"(%26, %10, %11) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 5, 5>, layout = #llh.Layout<NCHW>, pad = array<i64: 5, 5, 5, 5>, stride = array<i64: 1, 1>}> : (tensor<2x10x104x104xf32>, tensor<3x10x5x5xf32>, tensor<3xf32>) -> tensor<2x3x110x110xf32>
  %28 = "llh.mul"(%27, %27) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  %29 = "llh.add"(%27, %28) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  %30 = "llh.div"(%27, %6) : (tensor<2x3x110x110xf32>, tensor<1xf32>) -> tensor<2x3x110x110xf32>
  %31 = "llh.add"(%29, %30) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  %32 = "llh.transpose"(%12) <{perms = array<i64: 1, 0>}> : (tensor<2x110xf32>) -> tensor<110x2xf32>
  %33 = "llh.matmul"(%31, %32) : (tensor<2x3x110x110xf32>, tensor<110x2xf32>) -> tensor<2x3x110x2xf32>
  %34 = "llh.add"(%33, %13) : (tensor<2x3x110x2xf32>, tensor<2xf32>) -> tensor<2x3x110x2xf32>
  return %34 : tensor<2x3x110x2xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.torch_symbolic_int'(0x561dcc207780) {
  %15 = "llh.torch_symbolic_int"() <{sym_name = "s1"}> : () -> i64


  * Pattern {anonymous}::replaceTorchSymbolicIntOp : 'llh.torch_symbolic_int -> ()' {
Trying to match "{anonymous}::replaceTorchSymbolicIntOp"
    ** Erase   : 'llh.torch_symbolic_int'(0x561dcc207780)
"{anonymous}::replaceTorchSymbolicIntOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x?x224x224xf32>) -> tensor<2x3x110x2xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = dense<5.33333302> : tensor<1xf32>}> : () -> tensor<1xf32>
  %1 = "llh.constant"() <{value = 5.33333302 : f32}> : () -> f32
  %2 = "llh.constant"() <{value = 224 : i64}> : () -> i64
  %3 = "llh.constant"() <{value = 6 : i64}> : () -> i64
  %4 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %5 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %6 = "llh.constant"() <{value = dense<0.000000e+00> : tensor<1xf32>}> : () -> tensor<1xf32>
  %7 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer1.weight.npy"}> : () -> tensor<10x3x5x5xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer1.bias.npy"}> : () -> tensor<10xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer2.weight.npy"}> : () -> tensor<3x10x5x5xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer2.bias.npy"}> : () -> tensor<3xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___cf.weight.npy"}> : () -> tensor<2x110xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___cf.bias.npy"}> : () -> tensor<2xf32>
  %14 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64
  %15 = "llh.dim"(%arg0, %7) : (tensor<?x?x224x224xf32>, i64) -> i64
  %16 = "llh.dim"(%arg0, %5) : (tensor<?x?x224x224xf32>, i64) -> i64
  %17 = "llh.reshape"(%arg0, %4, %3, %15, %16) : (tensor<?x?x224x224xf32>, i64, i64, i64, i64) -> tensor<1x?x224x224xf32>
  %18 = "llh.reshape"(%17, %7, %5, %2, %2) : (tensor<1x?x224x224xf32>, i64, i64, i64, i64) -> tensor<2x?x224x224xf32>
  %19 = "llh.conv_bias"(%18, %8, %9) <{dilation = array<i64: 5, 5>, group = 1 : i64, kernel_shape = array<i64: 5, 5>, layout = #llh.Layout<NCHW>, pad = array<i64: 2, 2, 2, 2>, stride = array<i64: 2, 2>}> : (tensor<2x?x224x224xf32>, tensor<10x3x5x5xf32>, tensor<10xf32>) -> tensor<2x10x104x104xf32>
  %20 = "llh.add"(%19, %19) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  %21 = "llh.div"(%19, %0) : (tensor<2x10x104x104xf32>, tensor<1xf32>) -> tensor<2x10x104x104xf32>
  %22 = "llh.add"(%21, %20) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  %23 = "llh.mul"(%21, %21) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  %24 = "llh.add"(%22, %23) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  %25 = "llh.add"(%24, %20) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  %26 = "llh.conv_bias"(%25, %10, %11) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 5, 5>, layout = #llh.Layout<NCHW>, pad = array<i64: 5, 5, 5, 5>, stride = array<i64: 1, 1>}> : (tensor<2x10x104x104xf32>, tensor<3x10x5x5xf32>, tensor<3xf32>) -> tensor<2x3x110x110xf32>
  %27 = "llh.mul"(%26, %26) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  %28 = "llh.add"(%26, %27) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  %29 = "llh.div"(%26, %6) : (tensor<2x3x110x110xf32>, tensor<1xf32>) -> tensor<2x3x110x110xf32>
  %30 = "llh.add"(%28, %29) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  %31 = "llh.transpose"(%12) <{perms = array<i64: 1, 0>}> : (tensor<2x110xf32>) -> tensor<110x2xf32>
  %32 = "llh.matmul"(%30, %31) : (tensor<2x3x110x110xf32>, tensor<110x2xf32>) -> tensor<2x3x110x2xf32>
  %33 = "llh.add"(%32, %13) : (tensor<2x3x110x2xf32>, tensor<2xf32>) -> tensor<2x3x110x2xf32>
  return %33 : tensor<2x3x110x2xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.torch_symbolic_int'(0x561dcc207240) {
  %14 = "llh.torch_symbolic_int"() <{sym_name = "s0"}> : () -> i64


  * Pattern {anonymous}::replaceTorchSymbolicIntOp : 'llh.torch_symbolic_int -> ()' {
Trying to match "{anonymous}::replaceTorchSymbolicIntOp"
    ** Erase   : 'llh.torch_symbolic_int'(0x561dcc207240)
"{anonymous}::replaceTorchSymbolicIntOp" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: tensor<?x?x224x224xf32>) -> tensor<2x3x110x2xf32> attributes {entrance} {
  %0 = "llh.constant"() <{value = dense<5.33333302> : tensor<1xf32>}> : () -> tensor<1xf32>
  %1 = "llh.constant"() <{value = 5.33333302 : f32}> : () -> f32
  %2 = "llh.constant"() <{value = 224 : i64}> : () -> i64
  %3 = "llh.constant"() <{value = 6 : i64}> : () -> i64
  %4 = "llh.constant"() <{value = 1 : i64}> : () -> i64
  %5 = "llh.constant"() <{value = 3 : i64}> : () -> i64
  %6 = "llh.constant"() <{value = dense<0.000000e+00> : tensor<1xf32>}> : () -> tensor<1xf32>
  %7 = "llh.constant"() <{value = 2 : i64}> : () -> i64
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer1.weight.npy"}> : () -> tensor<10x3x5x5xf32>
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer1.bias.npy"}> : () -> tensor<10xf32>
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer2.weight.npy"}> : () -> tensor<3x10x5x5xf32>
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer2.bias.npy"}> : () -> tensor<3xf32>
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___cf.weight.npy"}> : () -> tensor<2x110xf32>
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___cf.bias.npy"}> : () -> tensor<2xf32>
  %14 = "llh.dim"(%arg0, %7) : (tensor<?x?x224x224xf32>, i64) -> i64
  %15 = "llh.dim"(%arg0, %5) : (tensor<?x?x224x224xf32>, i64) -> i64
  %16 = "llh.reshape"(%arg0, %4, %3, %14, %15) : (tensor<?x?x224x224xf32>, i64, i64, i64, i64) -> tensor<1x?x224x224xf32>
  %17 = "llh.reshape"(%16, %7, %5, %2, %2) : (tensor<1x?x224x224xf32>, i64, i64, i64, i64) -> tensor<2x?x224x224xf32>
  %18 = "llh.conv_bias"(%17, %8, %9) <{dilation = array<i64: 5, 5>, group = 1 : i64, kernel_shape = array<i64: 5, 5>, layout = #llh.Layout<NCHW>, pad = array<i64: 2, 2, 2, 2>, stride = array<i64: 2, 2>}> : (tensor<2x?x224x224xf32>, tensor<10x3x5x5xf32>, tensor<10xf32>) -> tensor<2x10x104x104xf32>
  %19 = "llh.add"(%18, %18) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  %20 = "llh.div"(%18, %0) : (tensor<2x10x104x104xf32>, tensor<1xf32>) -> tensor<2x10x104x104xf32>
  %21 = "llh.add"(%20, %19) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  %22 = "llh.mul"(%20, %20) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  %23 = "llh.add"(%21, %22) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  %24 = "llh.add"(%23, %19) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>
  %25 = "llh.conv_bias"(%24, %10, %11) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 5, 5>, layout = #llh.Layout<NCHW>, pad = array<i64: 5, 5, 5, 5>, stride = array<i64: 1, 1>}> : (tensor<2x10x104x104xf32>, tensor<3x10x5x5xf32>, tensor<3xf32>) -> tensor<2x3x110x110xf32>
  %26 = "llh.mul"(%25, %25) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  %27 = "llh.add"(%25, %26) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  %28 = "llh.div"(%25, %6) : (tensor<2x3x110x110xf32>, tensor<1xf32>) -> tensor<2x3x110x110xf32>
  %29 = "llh.add"(%27, %28) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>
  %30 = "llh.transpose"(%12) <{perms = array<i64: 1, 0>}> : (tensor<2x110xf32>) -> tensor<110x2xf32>
  %31 = "llh.matmul"(%29, %30) : (tensor<2x3x110x110xf32>, tensor<110x2xf32>) -> tensor<2x3x110x2xf32>
  %32 = "llh.add"(%31, %13) : (tensor<2x3x110x2xf32>, tensor<2xf32>) -> tensor<2x3x110x2xf32>
  return %32 : tensor<2x3x110x2xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x561dcc1d5330) {
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___cf.bias.npy"}> : () -> tensor<2xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x561dcc1ef900) {
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___cf.weight.npy"}> : () -> tensor<2x110xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x561dcc1f0f80) {
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer2.bias.npy"}> : () -> tensor<3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x561dcc1f1150) {
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer2.weight.npy"}> : () -> tensor<3x10x5x5xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x561dcc1fe8d0) {
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer1.bias.npy"}> : () -> tensor<10xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'func.func'(0x561dcc20f910) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x561dcc1feaa0) {
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer1.weight.npy"}> : () -> tensor<10x3x5x5xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'func.return'(0x561dcc20f890) {
  "func.return"(%32) : (tensor<2x3x110x2xf32>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x561dcc20e680) {
  %32 = "llh.add"(%31, %13) : (tensor<2x3x110x2xf32>, tensor<2xf32>) -> tensor<2x3x110x2xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.matmul'(0x561dcc20e590) {
  %31 = "llh.matmul"(%29, %30) : (tensor<2x3x110x110xf32>, tensor<110x2xf32>) -> tensor<2x3x110x2xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.transpose'(0x561dcc201c90) {
  %30 = "llh.transpose"(%12) <{perms = array<i64: 1, 0>}> : (tensor<2x110xf32>) -> tensor<110x2xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x561dcc20e380) {
  %29 = "llh.add"(%27, %28) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.div'(0x561dcc20e1f0) {
  %28 = "llh.div"(%25, %6) : (tensor<2x3x110x110xf32>, tensor<1xf32>) -> tensor<2x3x110x110xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x561dcc20dfa0) {
  %27 = "llh.add"(%25, %26) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.mul'(0x561dcc20de30) {
  %26 = "llh.mul"(%25, %25) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv_bias'(0x561dcc20d7f0) {
  %25 = "llh.conv_bias"(%24, %10, %11) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 5, 5>, layout = #llh.Layout<NCHW>, pad = array<i64: 5, 5, 5, 5>, stride = array<i64: 1, 1>}> : (tensor<2x10x104x104xf32>, tensor<3x10x5x5xf32>, tensor<3xf32>) -> tensor<2x3x110x110xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x561dcc20cd20) {
  %24 = "llh.add"(%23, %19) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x561dcc20cb90) {
  %23 = "llh.add"(%21, %22) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.mul'(0x561dcc20ca00) {
  %22 = "llh.mul"(%20, %20) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x561dcc20c870) {
  %21 = "llh.add"(%20, %19) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.div'(0x561dcc20c0a0) {
  %20 = "llh.div"(%18, %0) : (tensor<2x10x104x104xf32>, tensor<1xf32>) -> tensor<2x10x104x104xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x561dcc20b9f0) {
  %19 = "llh.add"(%18, %18) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv_bias'(0x561dcc1f2f30) {
  %18 = "llh.conv_bias"(%17, %8, %9) <{dilation = array<i64: 5, 5>, group = 1 : i64, kernel_shape = array<i64: 5, 5>, layout = #llh.Layout<NCHW>, pad = array<i64: 2, 2, 2, 2>, stride = array<i64: 2, 2>}> : (tensor<2x?x224x224xf32>, tensor<10x3x5x5xf32>, tensor<10xf32>) -> tensor<2x10x104x104xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.reshape'(0x561dcc1d5480) {
  %17 = "llh.reshape"(%16, %7, %5, %2, %2) : (tensor<1x?x224x224xf32>, i64, i64, i64, i64) -> tensor<2x?x224x224xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.reshape'(0x561dcc1efa50) {
  %16 = "llh.reshape"(%arg0, %4, %3, %14, %15) : (tensor<?x?x224x224xf32>, i64, i64, i64, i64) -> tensor<1x?x224x224xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.dim'(0x561dcc208d90) {
  %15 = "llh.dim"(%arg0, %5) : (tensor<?x?x224x224xf32>, i64) -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.dim'(0x561dcc208bc0) {
  %14 = "llh.dim"(%arg0, %7) : (tensor<?x?x224x224xf32>, i64) -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x561dcc1d5330) {
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___cf.bias.npy"}> : () -> tensor<2xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x561dcc1ef900) {
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___cf.weight.npy"}> : () -> tensor<2x110xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x561dcc1f0f80) {
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer2.bias.npy"}> : () -> tensor<3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x561dcc1f1150) {
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer2.weight.npy"}> : () -> tensor<3x10x5x5xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x561dcc1fe8d0) {
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer1.bias.npy"}> : () -> tensor<10xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x561dcc1feaa0) {
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer1.weight.npy"}> : () -> tensor<10x3x5x5xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.constant'(0x561dcc208b00) {
  %7 = "llh.constant"() <{value = 2 : i64}> : () -> i64


  * Pattern {anonymous}::BraodcastableScalarToTensor : 'llh.constant -> ()' {
Trying to match "{anonymous}::BraodcastableScalarToTensor"
"{anonymous}::BraodcastableScalarToTensor" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.constant'(0x561dcc20e2a0) {
  %6 = "llh.constant"() <{value = dense<0.000000e+00> : tensor<1xf32>}> : () -> tensor<1xf32>


  * Pattern {anonymous}::BraodcastableScalarToTensor : 'llh.constant -> ()' {
Trying to match "{anonymous}::BraodcastableScalarToTensor"
"{anonymous}::BraodcastableScalarToTensor" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.constant'(0x561dcc208cd0) {
  %5 = "llh.constant"() <{value = 3 : i64}> : () -> i64


  * Pattern {anonymous}::BraodcastableScalarToTensor : 'llh.constant -> ()' {
Trying to match "{anonymous}::BraodcastableScalarToTensor"
"{anonymous}::BraodcastableScalarToTensor" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.constant'(0x561dcc1fe670) {
  %4 = "llh.constant"() <{value = 1 : i64}> : () -> i64


  * Pattern {anonymous}::BraodcastableScalarToTensor : 'llh.constant -> ()' {
Trying to match "{anonymous}::BraodcastableScalarToTensor"
"{anonymous}::BraodcastableScalarToTensor" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.constant'(0x561dcc209a50) {
  %3 = "llh.constant"() <{value = 6 : i64}> : () -> i64


  * Pattern {anonymous}::BraodcastableScalarToTensor : 'llh.constant -> ()' {
Trying to match "{anonymous}::BraodcastableScalarToTensor"
"{anonymous}::BraodcastableScalarToTensor" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.constant'(0x561dcc20a220) {
  %2 = "llh.constant"() <{value = 224 : i64}> : () -> i64


  * Pattern {anonymous}::BraodcastableScalarToTensor : 'llh.constant -> ()' {
Trying to match "{anonymous}::BraodcastableScalarToTensor"
"{anonymous}::BraodcastableScalarToTensor" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.constant'(0x561dcc20c000) {
  %1 = "llh.constant"() <{value = 5.33333302 : f32}> : () -> f32


  * Pattern {anonymous}::BraodcastableScalarToTensor : 'llh.constant -> ()' {
Trying to match "{anonymous}::BraodcastableScalarToTensor"
"{anonymous}::BraodcastableScalarToTensor" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'func.func'(0x561dcc20f910) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.constant'(0x561dcc208b60) {
  %0 = "llh.constant"() <{value = dense<5.33333302> : tensor<1xf32>}> : () -> tensor<1xf32>


  * Pattern {anonymous}::BraodcastableScalarToTensor : 'llh.constant -> ()' {
Trying to match "{anonymous}::BraodcastableScalarToTensor"
"{anonymous}::BraodcastableScalarToTensor" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//
[2024-09-30 05:21:30.280] [info] ----- run out pass: Operationlegalization -----
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::PreservedAnalyses::AllAnalysesType)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::CallGraph)

//===-------------------------------------------===//
Processing operation : 'llh.constant'(0x561dcc208b60) {
  %0 = "llh.constant"() <{value = dense<5.33333302> : tensor<1xf32>}> : () -> tensor<1xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.constant'(0x561dcc20c000) {
  %1 = "llh.constant"() <{value = 5.33333302 : f32}> : () -> f32

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.constant'(0x561dcc20a220) {
  %2 = "llh.constant"() <{value = 224 : i64}> : () -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.constant'(0x561dcc209a50) {
  %3 = "llh.constant"() <{value = 6 : i64}> : () -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.constant'(0x561dcc1fe670) {
  %4 = "llh.constant"() <{value = 1 : i64}> : () -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.constant'(0x561dcc208cd0) {
  %5 = "llh.constant"() <{value = 3 : i64}> : () -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.constant'(0x561dcc20e2a0) {
  %6 = "llh.constant"() <{value = dense<0.000000e+00> : tensor<1xf32>}> : () -> tensor<1xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.constant'(0x561dcc208b00) {
  %7 = "llh.constant"() <{value = 2 : i64}> : () -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x561dcc1feaa0) {
  %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer1.weight.npy"}> : () -> tensor<10x3x5x5xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x561dcc1fe8d0) {
  %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer1.bias.npy"}> : () -> tensor<10xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x561dcc1f1150) {
  %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer2.weight.npy"}> : () -> tensor<3x10x5x5xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x561dcc1f0f80) {
  %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___conv_layer2.bias.npy"}> : () -> tensor<3xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x561dcc1ef900) {
  %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___cf.weight.npy"}> : () -> tensor<2x110xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.weight'(0x561dcc1d5330) {
  %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-09-29T23:48:45.486700+08:00/L__self___cf.bias.npy"}> : () -> tensor<2xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.dim'(0x561dcc208bc0) {
  %14 = "llh.dim"(%arg0, %7) : (tensor<?x?x224x224xf32>, i64) -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.dim'(0x561dcc208d90) {
  %15 = "llh.dim"(%arg0, %5) : (tensor<?x?x224x224xf32>, i64) -> i64

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.reshape'(0x561dcc1efa50) {
  %16 = "llh.reshape"(%arg0, %4, %3, %14, %15) : (tensor<?x?x224x224xf32>, i64, i64, i64, i64) -> tensor<1x?x224x224xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.reshape'(0x561dcc1d5480) {
  %17 = "llh.reshape"(%16, %7, %5, %2, %2) : (tensor<1x?x224x224xf32>, i64, i64, i64, i64) -> tensor<2x?x224x224xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv_bias'(0x561dcc1f2f30) {
  %18 = "llh.conv_bias"(%17, %8, %9) <{dilation = array<i64: 5, 5>, group = 1 : i64, kernel_shape = array<i64: 5, 5>, layout = #llh.Layout<NCHW>, pad = array<i64: 2, 2, 2, 2>, stride = array<i64: 2, 2>}> : (tensor<2x?x224x224xf32>, tensor<10x3x5x5xf32>, tensor<10xf32>) -> tensor<2x10x104x104xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x561dcc20b9f0) {
  %19 = "llh.add"(%18, %18) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.div'(0x561dcc20c0a0) {
  %20 = "llh.div"(%18, %0) : (tensor<2x10x104x104xf32>, tensor<1xf32>) -> tensor<2x10x104x104xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x561dcc20c870) {
  %21 = "llh.add"(%20, %19) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.mul'(0x561dcc20ca00) {
  %22 = "llh.mul"(%20, %20) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x561dcc20cb90) {
  %23 = "llh.add"(%21, %22) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x561dcc20cd20) {
  %24 = "llh.add"(%23, %19) : (tensor<2x10x104x104xf32>, tensor<2x10x104x104xf32>) -> tensor<2x10x104x104xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.conv_bias'(0x561dcc20d7f0) {
  %25 = "llh.conv_bias"(%24, %10, %11) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 5, 5>, layout = #llh.Layout<NCHW>, pad = array<i64: 5, 5, 5, 5>, stride = array<i64: 1, 1>}> : (tensor<2x10x104x104xf32>, tensor<3x10x5x5xf32>, tensor<3xf32>) -> tensor<2x3x110x110xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.mul'(0x561dcc20de30) {
  %26 = "llh.mul"(%25, %25) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x561dcc20dfa0) {
  %27 = "llh.add"(%25, %26) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.div'(0x561dcc20e1f0) {
  %28 = "llh.div"(%25, %6) : (tensor<2x3x110x110xf32>, tensor<1xf32>) -> tensor<2x3x110x110xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x561dcc20e380) {
  %29 = "llh.add"(%27, %28) : (tensor<2x3x110x110xf32>, tensor<2x3x110x110xf32>) -> tensor<2x3x110x110xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.transpose'(0x561dcc201c90) {
  %30 = "llh.transpose"(%12) <{perms = array<i64: 1, 0>}> : (tensor<2x110xf32>) -> tensor<110x2xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.matmul'(0x561dcc20e590) {
  %31 = "llh.matmul"(%29, %30) : (tensor<2x3x110x110xf32>, tensor<110x2xf32>) -> tensor<2x3x110x2xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'llh.add'(0x561dcc20e680) {
  %32 = "llh.add"(%31, %13) : (tensor<2x3x110x2xf32>, tensor<2xf32>) -> tensor<2x3x110x2xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'func.return'(0x561dcc20f890) {
  "func.return"(%32) : (tensor<2x3x110x2xf32>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//
* Inliner: Initial calls in SCC are: {
}
* Inliner: Initial calls in SCC are: {
}
[2024-09-30 05:21:30.284] [info] ----- run in pass: InferSymbolShape -----
ImplicitTypeIDRegistry::lookupOrInsert(mlir::llh::detail::SymbolicIntOpGenericAdaptorBase::Properties)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::VerifiableTensorEncoding)
<unknown>:0: error: invalid tensor dimension size
llc-opt: /home/lfr/LLCompiler/third_party/llvm-project/mlir/include/mlir/IR/StorageUniquerSupport.h:179: static ConcreteT mlir::detail::StorageUserBase<ConcreteT, BaseT, StorageT, UniquerT, Traits>::get(mlir::MLIRContext*, Args&& ...) [with Args = {llvm::ArrayRef<long int>&, mlir::Type&, mlir::Attribute&}; ConcreteT = mlir::RankedTensorType; BaseT = mlir::TensorType; StorageT = mlir::detail::RankedTensorTypeStorage; UniquerT = mlir::detail::TypeUniquer; Traits = {mlir::ShapedType::Trait, mlir::ValueSemantics}]: Assertion `succeeded( ConcreteT::verifyInvariants(getDefaultDiagnosticEmitFn(ctx), args...))' failed.
PLEASE submit a bug report to https://github.com/llvm/llvm-project/issues/ and include the crash backtrace.
Stack dump:
0.	Program arguments: /home/lfr/LLCompiler/build/bin/llc-opt --dump-pass-pipeline -o=/home/lfr/LLCompiler/out.mlir --log-lever=debug --log-root=C:codingLLCompilerlog --mlir-print-ir-tree-dir=/home/lfr/LLCompiler/ir_tree --mlir-print-ir-after-all -basic-pipeline /home/lfr/LLCompiler/test/model_ir/Base.mlir --debug
Stack dump without symbol names (ensure you have llvm-symbolizer in your PATH or set the environment var `LLVM_SYMBOLIZER_PATH` to point to it):
0  libLLVMSupport.so.20.0git 0x00007fcaf2121800 llvm::sys::PrintStackTrace(llvm::raw_ostream&, int) + 240
1  libLLVMSupport.so.20.0git 0x00007fcaf211ed6a llvm::sys::RunSignalHandlers() + 58
2  libLLVMSupport.so.20.0git 0x00007fcaf211efd5
3  libc.so.6                 0x00007fcaf1af7520
4  libc.so.6                 0x00007fcaf1b4b9fc pthread_kill + 300
5  libc.so.6                 0x00007fcaf1af7476 raise + 22
6  libc.so.6                 0x00007fcaf1add7f3 abort + 211
7  libc.so.6                 0x00007fcaf1add71b
8  libc.so.6                 0x00007fcaf1aeee96
9  libMLIRIR.so.20.0git      0x00007fcaf231054f
10 libMLIRIR.so.20.0git      0x00007fcaf231068d mlir::RankedTensorType::get(llvm::ArrayRef<long>, mlir::Type, mlir::Attribute) + 61
11 libMLIRLLHDialect.so      0x00007fcaf3bcf042
12 libMLIRLLHDialect.so      0x00007fcaf3bd01d3 mlir::llh::ConvBiasOp::inferSymbolicShape() + 19
13 libMLIRLLHDialect.so      0x00007fcaf3b90164 mlir::detail::SymbolicInferShapeOpInterfaceInterfaceTraits::Model<mlir::llh::ConvBiasOp>::inferSymbolicShape(mlir::detail::SymbolicInferShapeOpInterfaceInterfaceTraits::Concept const*, mlir::Operation*) + 36
14 libMLIRLLHUtils.so        0x00007fcaf12b05cf mlir::llh::checkAndInferSymbol(mlir::Operation*) + 559
15 libMLIRLLHTransforms.so   0x00007fcaf3c2d624
16 libMLIRLLHTransforms.so   0x00007fcaf3c2dc47
17 libMLIRPass.so.20.0git    0x00007fcaf24963d9 mlir::detail::OpToOpPassAdaptor::run(mlir::Pass*, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int) + 1193
18 libMLIRPass.so.20.0git    0x00007fcaf2496891 mlir::detail::OpToOpPassAdaptor::runPipeline(mlir::OpPassManager&, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int, mlir::PassInstrumentor*, mlir::PassInstrumentation::PipelineParentInfo const*) + 321
19 libMLIRPass.so.20.0git    0x00007fcaf24978e5 mlir::PassManager::run(mlir::Operation*) + 1445
20 libMLIROptLib.so.20.0git  0x00007fcaf3ca92b7
21 libMLIROptLib.so.20.0git  0x00007fcaf3ca9ccc
22 libMLIROptLib.so.20.0git  0x00007fcaf3ca9e2d
23 libMLIRSupport.so.20.0git 0x00007fcaf15628de mlir::splitAndProcessBuffer(std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::function_ref<llvm::LogicalResult (std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::raw_ostream&)>, llvm::raw_ostream&, llvm::StringRef, llvm::StringRef) + 174
24 libMLIROptLib.so.20.0git  0x00007fcaf3ca04bc mlir::MlirOptMain(llvm::raw_ostream&, std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, mlir::DialectRegistry&, mlir::MlirOptMainConfig const&) + 220
25 libMLIROptLib.so.20.0git  0x00007fcaf3ca9f90 mlir::MlirOptMain(int, char**, llvm::StringRef, llvm::StringRef, mlir::DialectRegistry&) + 304
26 libMLIROptLib.so.20.0git  0x00007fcaf3caa4b7 mlir::MlirOptMain(int, char**, llvm::StringRef, mlir::DialectRegistry&) + 391
27 llc-opt                   0x0000561dcada0a7b
28 libc.so.6                 0x00007fcaf1aded90
29 libc.so.6                 0x00007fcaf1adee40 __libc_start_main + 128
30 llc-opt                   0x0000561dcada0b25
