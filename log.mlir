Args: /home/lfr/LLCompiler/build/bin/llc-opt /home/lfr/LLCompiler/ir_tree/inference/fx/resnet18/builtin_module_no-symbol-name/3_infer-symbol-shape.mlir --infer-symbol-shape --debug 
Load new dialect in Context builtin
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ShapedType)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::MemRefLayoutAttrInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::TypedAttr)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ElementsAttr)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DistinctAttr)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::BytecodeOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SymbolOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpAsmOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::RegionKindInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ConditionallySpeculatable)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::MemoryEffectOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ResourceBlobManagerDialectInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpAsmDialectInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::BytecodeDialectInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::AffineBinaryOpExprStorage)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::AffineConstantExprStorage)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::AffineDimExprStorage)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::AffineMapStorage)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::IntegerSetStorage)
Load new dialect in Context builtin
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::ZeroOperands<mlir::TypeID::get<mlir::OpTrait::ZeroOperands>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneRegion<mlir::TypeID::get<mlir::OpTrait::OneRegion>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::ZeroResults<mlir::TypeID::get<mlir::OpTrait::ZeroResults>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::ZeroSuccessors<mlir::TypeID::get<mlir::OpTrait::ZeroSuccessors>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::NoRegionArguments<mlir::TypeID::get<mlir::OpTrait::NoRegionArguments>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::NoTerminator<mlir::TypeID::get<mlir::OpTrait::NoTerminator>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SingleBlock<mlir::TypeID::get<mlir::OpTrait::SingleBlock>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OpInvariants<mlir::TypeID::get<mlir::OpTrait::OpInvariants>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::BytecodeOpInterface::Trait<mlir::TypeID::get<mlir::BytecodeOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::AffineScope<mlir::TypeID::get<mlir::OpTrait::AffineScope>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::IsIsolatedFromAbove<mlir::TypeID::get<mlir::OpTrait::IsIsolatedFromAbove>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SymbolTable<mlir::TypeID::get<mlir::OpTrait::SymbolTable>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SymbolOpInterface::Trait<mlir::TypeID::get<mlir::SymbolOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpAsmOpInterface::Trait<mlir::TypeID::get<mlir::OpAsmOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::RegionKindInterface::Trait<mlir::TypeID::get<mlir::RegionKindInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::HasOnlyGraphRegion<mlir::TypeID::get<mlir::OpTrait::HasOnlyGraphRegion>()::Empty>)
Load new dialect in Context llh
Load new dialect in Context mlir_ex
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SymbolicInferShapeOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::BraodcastableOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::InferTypeOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SymbolUserOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::CastOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DialectInlinerInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::LLVMTranslationDialectInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::ZeroRegions<mlir::TypeID::get<mlir::OpTrait::ZeroRegions>()::Empty>)
Load new dialect in Context func
ImplicitTypeIDRegistry::lookupOrInsert(mlir::CallOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::CallableOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::FunctionOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::RegionBranchTerminatorOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ConvertToLLVMPatternInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::bufferization::BufferizableOpInterface)
Load new dialect in Context cf
Load new dialect in Context arith
ImplicitTypeIDRegistry::lookupOrInsert(mlir::arith::ArithFastMathInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::VectorUnrollOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::InferIntRangeInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::arith::ArithIntegerOverflowFlagsInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::arith::ArithRoundingModeInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SelectLikeOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::bufferization::BufferDeallocationOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ValueBoundsOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::BranchOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::AutomaticAllocationScope<mlir::TypeID::get<mlir::OpTrait::AutomaticAllocationScope>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::CallableOpInterface::Trait<mlir::TypeID::get<mlir::CallableOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::FunctionOpInterface::Trait<mlir::TypeID::get<mlir::FunctionOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::VerifiableTensorEncoding)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneResult<mlir::TypeID::get<mlir::OpTrait::OneResult>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneTypedResult<mlir::Type>::Impl<mlir::TypeID::get<mlir::OpTrait::OneTypedResult<mlir::Type>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::ConstantLike<mlir::TypeID::get<mlir::OpTrait::ConstantLike>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SymbolicInferShapeOpInterface::Trait<mlir::TypeID::get<mlir::SymbolicInferShapeOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::VariadicOperands<mlir::TypeID::get<mlir::OpTrait::VariadicOperands>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::HasParent<mlir::func::FuncOp>::Impl<mlir::TypeID::get<mlir::OpTrait::HasParent<mlir::func::FuncOp>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ConditionallySpeculatable::Trait<mlir::TypeID::get<mlir::ConditionallySpeculatable::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::AlwaysSpeculatableImplTrait<mlir::TypeID::get<mlir::OpTrait::AlwaysSpeculatableImplTrait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::MemoryEffectOpInterface::Trait<mlir::TypeID::get<mlir::MemoryEffectOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::MemRefsNormalizable<mlir::TypeID::get<mlir::OpTrait::MemRefsNormalizable>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::RegionBranchTerminatorOpInterface::Trait<mlir::TypeID::get<mlir::RegionBranchTerminatorOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::ReturnLike<mlir::TypeID::get<mlir::OpTrait::ReturnLike>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::IsTerminator<mlir::TypeID::get<mlir::OpTrait::IsTerminator>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DataLayoutSpecInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneOperand<mlir::TypeID::get<mlir::OpTrait::OneOperand>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::NOperands<2>::Impl<mlir::TypeID::get<mlir::OpTrait::NOperands<2>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::NOperands<5>::Impl<mlir::TypeID::get<mlir::OpTrait::NOperands<5>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SameOperandsAndResultType<mlir::TypeID::get<mlir::OpTrait::SameOperandsAndResultType>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SameOperandsAndResultRank<mlir::TypeID::get<mlir::OpTrait::SameOperandsAndResultRank>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::InferTypeOpInterface::Trait<mlir::TypeID::get<mlir::InferTypeOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::ResultsBroadcastableShape<mlir::TypeID::get<mlir::OpTrait::ResultsBroadcastableShape>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::BraodcastableOpInterface::Trait<mlir::TypeID::get<mlir::BraodcastableOpInterface::Trait>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneTypedResult<mlir::IntegerType>::Impl<mlir::TypeID::get<mlir::OpTrait::OneTypedResult<mlir::IntegerType>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::AtLeastNOperands<1>::Impl<mlir::TypeID::get<mlir::OpTrait::AtLeastNOperands<1>::Impl>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::OpToOpPassAdaptor)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::PreservedAnalyses::AllAnalysesType)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::AttributeTrait::IsLocation<mlir::TypeID::get<mlir::AttributeTrait::IsLocation>()::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::TypedAttr::Trait<mlir::TypeID::get<mlir::TypedAttr::Trait>()::Empty>)
module attributes {builtin.gloabal_layout = "NCHW"} {
  "llh.symbolic_int"() <{sym_name = "s2"}> : () -> ()
  "llh.symbolic_int"() <{sym_name = "s0"}> : () -> ()
  "llh.symbolic_int"() <{sym_name = "c3"}> : () -> ()
  "llh.symbolic_int"() <{sym_name = "c2"}> : () -> ()
  "llh.symbolic_int"() <{sym_name = "c1"}> : () -> ()
  "llh.symbolic_int"() <{sym_name = "c0"}> : () -> ()
  func.func @main(%arg0: tensor<?x3x?x?xf32, #llh.encoding<shapes = @s0, @c3, @s2, @s2>>) -> tensor<?x1000xf32> attributes {entrance} {
    %0 = "llh.constant"() <{value = 3 : i64}> : () -> i64
    %1 = "llh.constant"() <{value = 2 : i64}> : () -> i64
    %2 = "llh.constant"() <{value = 0 : i64}> : () -> i64
    %3 = "llh.constant"() <{value = 1 : i64}> : () -> i64
    %4 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/L__self___conv1.weight.npy"}> : () -> tensor<64x3x7x7xf32>
    %5 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/L__self___bn1.weight.npy"}> : () -> tensor<64xf32>
    %6 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/L__self___bn1.bias.npy"}> : () -> tensor<64xf32>
    %7 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer1___0___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
    %8 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer1___0___bn1.weight.npy"}> : () -> tensor<64xf32>
    %9 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer1___0___bn1.bias.npy"}> : () -> tensor<64xf32>
    %10 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer1___0___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
    %11 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer1___0___bn2.weight.npy"}> : () -> tensor<64xf32>
    %12 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer1___0___bn2.bias.npy"}> : () -> tensor<64xf32>
    %13 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer1___1___conv1.weight.npy"}> : () -> tensor<64x64x3x3xf32>
    %14 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer1___1___bn1.weight.npy"}> : () -> tensor<64xf32>
    %15 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer1___1___bn1.bias.npy"}> : () -> tensor<64xf32>
    %16 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer1___1___conv2.weight.npy"}> : () -> tensor<64x64x3x3xf32>
    %17 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer1___1___bn2.weight.npy"}> : () -> tensor<64xf32>
    %18 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer1___1___bn2.bias.npy"}> : () -> tensor<64xf32>
    %19 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer2___0___conv1.weight.npy"}> : () -> tensor<128x64x3x3xf32>
    %20 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer2___0___bn1.weight.npy"}> : () -> tensor<128xf32>
    %21 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer2___0___bn1.bias.npy"}> : () -> tensor<128xf32>
    %22 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer2___0___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
    %23 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer2___0___bn2.weight.npy"}> : () -> tensor<128xf32>
    %24 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer2___0___bn2.bias.npy"}> : () -> tensor<128xf32>
    %25 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer2___0___downsample_0.weight.npy"}> : () -> tensor<128x64x1x1xf32>
    %26 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer2___0___downsample_1.weight.npy"}> : () -> tensor<128xf32>
    %27 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer2___0___downsample_1.bias.npy"}> : () -> tensor<128xf32>
    %28 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer2___1___conv1.weight.npy"}> : () -> tensor<128x128x3x3xf32>
    %29 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer2___1___bn1.weight.npy"}> : () -> tensor<128xf32>
    %30 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer2___1___bn1.bias.npy"}> : () -> tensor<128xf32>
    %31 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer2___1___conv2.weight.npy"}> : () -> tensor<128x128x3x3xf32>
    %32 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer2___1___bn2.weight.npy"}> : () -> tensor<128xf32>
    %33 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer2___1___bn2.bias.npy"}> : () -> tensor<128xf32>
    %34 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer3___0___conv1.weight.npy"}> : () -> tensor<256x128x3x3xf32>
    %35 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer3___0___bn1.weight.npy"}> : () -> tensor<256xf32>
    %36 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer3___0___bn1.bias.npy"}> : () -> tensor<256xf32>
    %37 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer3___0___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
    %38 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer3___0___bn2.weight.npy"}> : () -> tensor<256xf32>
    %39 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer3___0___bn2.bias.npy"}> : () -> tensor<256xf32>
    %40 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer3___0___downsample_0.weight.npy"}> : () -> tensor<256x128x1x1xf32>
    %41 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer3___0___downsample_1.weight.npy"}> : () -> tensor<256xf32>
    %42 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer3___0___downsample_1.bias.npy"}> : () -> tensor<256xf32>
    %43 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer3___1___conv1.weight.npy"}> : () -> tensor<256x256x3x3xf32>
    %44 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer3___1___bn1.weight.npy"}> : () -> tensor<256xf32>
    %45 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer3___1___bn1.bias.npy"}> : () -> tensor<256xf32>
    %46 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer3___1___conv2.weight.npy"}> : () -> tensor<256x256x3x3xf32>
    %47 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer3___1___bn2.weight.npy"}> : () -> tensor<256xf32>
    %48 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer3___1___bn2.bias.npy"}> : () -> tensor<256xf32>
    %49 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer4___0___conv1.weight.npy"}> : () -> tensor<512x256x3x3xf32>
    %50 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer4___0___bn1.weight.npy"}> : () -> tensor<512xf32>
    %51 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer4___0___bn1.bias.npy"}> : () -> tensor<512xf32>
    %52 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer4___0___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
    %53 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer4___0___bn2.weight.npy"}> : () -> tensor<512xf32>
    %54 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer4___0___bn2.bias.npy"}> : () -> tensor<512xf32>
    %55 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer4___0___downsample_0.weight.npy"}> : () -> tensor<512x256x1x1xf32>
    %56 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer4___0___downsample_1.weight.npy"}> : () -> tensor<512xf32>
    %57 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer4___0___downsample_1.bias.npy"}> : () -> tensor<512xf32>
    %58 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer4___1___conv1.weight.npy"}> : () -> tensor<512x512x3x3xf32>
    %59 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer4___1___bn1.weight.npy"}> : () -> tensor<512xf32>
    %60 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer4___1___bn1.bias.npy"}> : () -> tensor<512xf32>
    %61 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer4___1___conv2.weight.npy"}> : () -> tensor<512x512x3x3xf32>
    %62 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer4___1___bn2.weight.npy"}> : () -> tensor<512xf32>
    %63 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer4___1___bn2.bias.npy"}> : () -> tensor<512xf32>
    %64 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/L__self___fc.weight.npy"}> : () -> tensor<1000x512xf32>
    %65 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/L__self___fc.bias.npy"}> : () -> tensor<1000xf32>
    %66 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/L__self___bn1.running_mean.npy"}> : () -> tensor<64xf32>
    %67 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/L__self___bn1.running_var.npy"}> : () -> tensor<64xf32>
    %68 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/L__self___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
    %69 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer1___0___bn1.running_mean.npy"}> : () -> tensor<64xf32>
    %70 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer1___0___bn1.running_var.npy"}> : () -> tensor<64xf32>
    %71 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer1___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
    %72 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer1___0___bn2.running_mean.npy"}> : () -> tensor<64xf32>
    %73 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer1___0___bn2.running_var.npy"}> : () -> tensor<64xf32>
    %74 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer1___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
    %75 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer1___1___bn1.running_mean.npy"}> : () -> tensor<64xf32>
    %76 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer1___1___bn1.running_var.npy"}> : () -> tensor<64xf32>
    %77 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer1___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
    %78 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer1___1___bn2.running_mean.npy"}> : () -> tensor<64xf32>
    %79 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer1___1___bn2.running_var.npy"}> : () -> tensor<64xf32>
    %80 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer1___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
    %81 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer2___0___bn1.running_mean.npy"}> : () -> tensor<128xf32>
    %82 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer2___0___bn1.running_var.npy"}> : () -> tensor<128xf32>
    %83 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer2___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
    %84 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer2___0___bn2.running_mean.npy"}> : () -> tensor<128xf32>
    %85 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer2___0___bn2.running_var.npy"}> : () -> tensor<128xf32>
    %86 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer2___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
    %87 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer2___0___downsample_1.running_mean.npy"}> : () -> tensor<128xf32>
    %88 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer2___0___downsample_1.running_var.npy"}> : () -> tensor<128xf32>
    %89 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer2___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
    %90 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer2___1___bn1.running_mean.npy"}> : () -> tensor<128xf32>
    %91 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer2___1___bn1.running_var.npy"}> : () -> tensor<128xf32>
    %92 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer2___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
    %93 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer2___1___bn2.running_mean.npy"}> : () -> tensor<128xf32>
    %94 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer2___1___bn2.running_var.npy"}> : () -> tensor<128xf32>
    %95 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer2___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
    %96 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer3___0___bn1.running_mean.npy"}> : () -> tensor<256xf32>
    %97 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer3___0___bn1.running_var.npy"}> : () -> tensor<256xf32>
    %98 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer3___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
    %99 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer3___0___bn2.running_mean.npy"}> : () -> tensor<256xf32>
    %100 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer3___0___bn2.running_var.npy"}> : () -> tensor<256xf32>
    %101 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer3___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
    %102 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer3___0___downsample_1.running_mean.npy"}> : () -> tensor<256xf32>
    %103 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer3___0___downsample_1.running_var.npy"}> : () -> tensor<256xf32>
    %104 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer3___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
    %105 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer3___1___bn1.running_mean.npy"}> : () -> tensor<256xf32>
    %106 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer3___1___bn1.running_var.npy"}> : () -> tensor<256xf32>
    %107 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer3___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
    %108 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer3___1___bn2.running_mean.npy"}> : () -> tensor<256xf32>
    %109 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer3___1___bn2.running_var.npy"}> : () -> tensor<256xf32>
    %110 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer3___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
    %111 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer4___0___bn1.running_mean.npy"}> : () -> tensor<512xf32>
    %112 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer4___0___bn1.running_var.npy"}> : () -> tensor<512xf32>
    %113 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer4___0___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
    %114 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer4___0___bn2.running_mean.npy"}> : () -> tensor<512xf32>
    %115 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer4___0___bn2.running_var.npy"}> : () -> tensor<512xf32>
    %116 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer4___0___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
    %117 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer4___0___downsample_1.running_mean.npy"}> : () -> tensor<512xf32>
    %118 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer4___0___downsample_1.running_var.npy"}> : () -> tensor<512xf32>
    %119 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer4___0___downsample_1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
    %120 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer4___1___bn1.running_mean.npy"}> : () -> tensor<512xf32>
    %121 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer4___1___bn1.running_var.npy"}> : () -> tensor<512xf32>
    %122 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer4___1___bn1.num_batches_tracked.npy"}> : () -> tensor<1xi64>
    %123 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer4___1___bn2.running_mean.npy"}> : () -> tensor<512xf32>
    %124 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer4___1___bn2.running_var.npy"}> : () -> tensor<512xf32>
    %125 = "llh.weight"() <{weight_file = "/home/lfr/LLCompiler/llcompiler/importer/LLcompiler_weight_temp/2024-10-17T02:11:56.476597+08:00/getattr_L__self___layer4___1___bn2.num_batches_tracked.npy"}> : () -> tensor<1xi64>
    "llh.symbol_bind"(%2) <{symbol = @c0}> : (i64) -> ()
    "llh.symbol_bind"(%1) <{symbol = @c2}> : (i64) -> ()
    %126 = "llh.conv"(%arg0, %4) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 7, 7>, layout = #llh.Layout<NCHW>, pad = array<i64: 3, 3, 3, 3>, stride = array<i64: 2, 2>}> : (tensor<?x3x?x?xf32, #llh.encoding<shapes = @s0, @c3, @s2, @s2>>, tensor<64x3x7x7xf32>) -> tensor<?x64x?x?xf32>
    %127 = "llh.batch_norm"(%126, %5, %6, %66, %67) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
    %128 = "llh.relu"(%127) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
    %129 = "llh.max_pool"(%128) <{ceil_mode = false, dilation = array<i64: 1, 1>, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
    %130 = "llh.conv"(%129, %7) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
    %131 = "llh.batch_norm"(%130, %8, %9, %69, %70) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
    %132 = "llh.relu"(%131) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
    %133 = "llh.conv"(%132, %10) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
    %134 = "llh.batch_norm"(%133, %11, %12, %72, %73) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
    %135 = "llh.add"(%134, %129) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
    %136 = "llh.relu"(%135) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
    %137 = "llh.conv"(%136, %13) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
    %138 = "llh.batch_norm"(%137, %14, %15, %75, %76) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
    %139 = "llh.relu"(%138) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
    %140 = "llh.conv"(%139, %16) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x64x?x?xf32>, tensor<64x64x3x3xf32>) -> tensor<?x64x?x?xf32>
    %141 = "llh.batch_norm"(%140, %17, %18, %78, %79) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x64x?x?xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>) -> tensor<?x64x?x?xf32>
    %142 = "llh.add"(%141, %136) : (tensor<?x64x?x?xf32>, tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
    %143 = "llh.relu"(%142) : (tensor<?x64x?x?xf32>) -> tensor<?x64x?x?xf32>
    %144 = "llh.conv"(%143, %19) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x3x3xf32>) -> tensor<?x128x?x?xf32>
    %145 = "llh.batch_norm"(%144, %20, %21, %81, %82) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
    %146 = "llh.relu"(%145) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
    %147 = "llh.conv"(%146, %22) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
    %148 = "llh.batch_norm"(%147, %23, %24, %84, %85) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
    %149 = "llh.conv"(%143, %25) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x64x?x?xf32>, tensor<128x64x1x1xf32>) -> tensor<?x128x?x?xf32>
    %150 = "llh.batch_norm"(%149, %26, %27, %87, %88) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
    %151 = "llh.add"(%148, %150) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
    %152 = "llh.relu"(%151) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
    %153 = "llh.conv"(%152, %28) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
    %154 = "llh.batch_norm"(%153, %29, %30, %90, %91) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
    %155 = "llh.relu"(%154) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
    %156 = "llh.conv"(%155, %31) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x128x?x?xf32>, tensor<128x128x3x3xf32>) -> tensor<?x128x?x?xf32>
    %157 = "llh.batch_norm"(%156, %32, %33, %93, %94) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x128x?x?xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128xf32>) -> tensor<?x128x?x?xf32>
    %158 = "llh.add"(%157, %152) : (tensor<?x128x?x?xf32>, tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
    %159 = "llh.relu"(%158) : (tensor<?x128x?x?xf32>) -> tensor<?x128x?x?xf32>
    %160 = "llh.conv"(%159, %34) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x3x3xf32>) -> tensor<?x256x?x?xf32>
    %161 = "llh.batch_norm"(%160, %35, %36, %96, %97) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
    %162 = "llh.relu"(%161) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
    %163 = "llh.conv"(%162, %37) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
    %164 = "llh.batch_norm"(%163, %38, %39, %99, %100) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
    %165 = "llh.conv"(%159, %40) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x128x?x?xf32>, tensor<256x128x1x1xf32>) -> tensor<?x256x?x?xf32>
    %166 = "llh.batch_norm"(%165, %41, %42, %102, %103) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
    %167 = "llh.add"(%164, %166) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
    %168 = "llh.relu"(%167) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
    %169 = "llh.conv"(%168, %43) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
    %170 = "llh.batch_norm"(%169, %44, %45, %105, %106) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
    %171 = "llh.relu"(%170) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
    %172 = "llh.conv"(%171, %46) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x256x?x?xf32>, tensor<256x256x3x3xf32>) -> tensor<?x256x?x?xf32>
    %173 = "llh.batch_norm"(%172, %47, %48, %108, %109) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x256x?x?xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>, tensor<256xf32>) -> tensor<?x256x?x?xf32>
    %174 = "llh.add"(%173, %168) : (tensor<?x256x?x?xf32>, tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
    %175 = "llh.relu"(%174) : (tensor<?x256x?x?xf32>) -> tensor<?x256x?x?xf32>
    %176 = "llh.conv"(%175, %49) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x3x3xf32>) -> tensor<?x512x?x?xf32>
    %177 = "llh.batch_norm"(%176, %50, %51, %111, %112) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
    %178 = "llh.relu"(%177) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
    %179 = "llh.conv"(%178, %52) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
    %180 = "llh.batch_norm"(%179, %53, %54, %114, %115) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
    %181 = "llh.conv"(%175, %55) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 1, 1>, layout = #llh.Layout<NCHW>, pad = array<i64: 0, 0, 0, 0>, stride = array<i64: 2, 2>}> : (tensor<?x256x?x?xf32>, tensor<512x256x1x1xf32>) -> tensor<?x512x?x?xf32>
    %182 = "llh.batch_norm"(%181, %56, %57, %117, %118) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
    %183 = "llh.add"(%180, %182) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
    %184 = "llh.relu"(%183) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
    %185 = "llh.conv"(%184, %58) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
    %186 = "llh.batch_norm"(%185, %59, %60, %120, %121) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
    %187 = "llh.relu"(%186) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
    %188 = "llh.conv"(%187, %61) <{dilation = array<i64: 1, 1>, group = 1 : i64, kernel_shape = array<i64: 3, 3>, layout = #llh.Layout<NCHW>, pad = array<i64: 1, 1, 1, 1>, stride = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>, tensor<512x512x3x3xf32>) -> tensor<?x512x?x?xf32>
    %189 = "llh.batch_norm"(%188, %62, %63, %123, %124) <{epsilon = 1.000000e-05 : f64, momentum = 1.000000e-01 : f64}> : (tensor<?x512x?x?xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>, tensor<512xf32>) -> tensor<?x512x?x?xf32>
    %190 = "llh.add"(%189, %184) : (tensor<?x512x?x?xf32>, tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
    %191 = "llh.relu"(%190) : (tensor<?x512x?x?xf32>) -> tensor<?x512x?x?xf32>
    %192 = "llh.adaptive_average_pool"(%191) <{out_size = array<i64: 1, 1>}> : (tensor<?x512x?x?xf32>) -> tensor<?x512x1x1xf32>
    "llh.symbol_bind"(%2) <{symbol = @c0}> : (i64) -> ()
    %193 = "llh.dim"(%192, %2) : (tensor<?x512x1x1xf32>, i64) -> i64
    "llh.symbol_bind"(%3) <{symbol = @c1}> : (i64) -> ()
    %194 = "llh.dim"(%192, %3) : (tensor<?x512x1x1xf32>, i64) -> i64
    "llh.symbol_bind"(%1) <{symbol = @c2}> : (i64) -> ()
    %195 = "llh.dim"(%192, %1) : (tensor<?x512x1x1xf32>, i64) -> i64
    "llh.symbol_bind"(%0) <{symbol = @c3}> : (i64) -> ()
    %196 = "llh.dim"(%192, %0) : (tensor<?x512x1x1xf32>, i64) -> i64
    %197 = "llh.mul"(%194, %195) : (i64, i64) -> i64
    %198 = "llh.mul"(%197, %196) : (i64, i64) -> i64
    %199 = "llh.reshape"(%192, %193, %198) : (tensor<?x512x1x1xf32>, i64, i64) -> tensor<?x512xf32>
    %200 = "llh.transpose"(%64) <{perms = array<i64: 1, 0>}> : (tensor<1000x512xf32>) -> tensor<512x1000xf32>
    %201 = "llh.matmul"(%199, %200) : (tensor<?x512xf32>, tensor<512x1000xf32>) -> tensor<?x1000xf32>
    %202 = "llh.add"(%201, %65) : (tensor<?x1000xf32>, tensor<1000xf32>) -> tensor<?x1000xf32>
    return %202 : tensor<?x1000xf32>
  }
}

